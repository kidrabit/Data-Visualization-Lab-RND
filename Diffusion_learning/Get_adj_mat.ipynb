{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_node_signal (135, 106, 7)\n",
      "node_loc (106, 3)\n",
      "-118.45 139.457\n",
      "-31.3102 21.6857\n",
      "-563.119 91.0359\n",
      "-0.0160272 0.000982589\n",
      "-0.0147581 0.0163793\n",
      "-0.00474041 0.0034676\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "from pandas import HDFStore \n",
    "import argparse\n",
    "\n",
    "###################################################################################\n",
    "#location\n",
    "node_ids_filename = 'data/node_locate.txt'\n",
    "with open(node_ids_filename) as f:\n",
    "    _node_ids = f.read().strip()\n",
    "    _node_ids = _node_ids.replace('\\n', ' ')\n",
    "    _node_ids = _node_ids.split(' ')\n",
    "\n",
    "node_id = []\n",
    "node_ids = []\n",
    "node_name = []\n",
    "node_loc = []\n",
    "for i in range(len(_node_ids)):\n",
    "    if(_node_ids[i] == ''):\n",
    "        continue\n",
    "    node_id.append(_node_ids[i])\n",
    "\n",
    "for i in range(len(node_id)):\n",
    "    if(i <= 4):\n",
    "        continue\n",
    "    if(node_id[i] == 'C'):\n",
    "        continue\n",
    "    node_ids.append(node_id[i])\n",
    "for i in range(len(node_ids)):\n",
    "    if(i % 4 == 0):\n",
    "        line = []\n",
    "        node_name.append(node_ids[i])\n",
    "        line.append(node_ids[i+1])\n",
    "        line.append(node_ids[i+2])\n",
    "        line.append(node_ids[i+3])\n",
    "        node_loc.append(line)\n",
    "node_loc=np.array(node_loc).astype('float32')\n",
    "print(\"node_loc\",node_loc.shape)\n",
    "\n",
    "###################################################################################\n",
    "#save to npy file\n",
    "np.save('data/node_signal', _node_signal)\n",
    "np.save('data/node_loc', node_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "normalized_k=0.1\n",
    "output_pkl_filename='data/sensor_graph/adj_mat.pkl'\n",
    "########################################\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "#getting distance matrix\n",
    "node_loc=np.load('data/node_loc.npy')\n",
    "n_nodes=node_loc.shape[0]\n",
    "node_id = [str(i) for i in range(1,1+n_nodes)]\n",
    "node_id_to_ind = {}\n",
    "for i, node in enumerate(node_id, 1):\n",
    "    node_id_to_ind[node] = i\n",
    "num_node = len(node_id)\n",
    "dist_mx = np.zeros((num_node, num_node), dtype=np.float32)\n",
    "dist_mx[:] = np.inf\n",
    "link_mx = np.zeros((num_node, num_node), dtype=np.float32)\n",
    "for i in range(num_node):\n",
    "    for j in range(num_node):\n",
    "        x = float(node_loc[i][0]) - float(node_loc[j][0])\n",
    "        y = float(node_loc[i][1]) - float(node_loc[j][1])\n",
    "        z = float(node_loc[i][2]) - float(node_loc[j][2])\n",
    "        x = math.pow(x,2)\n",
    "        y = math.pow(y,2)\n",
    "        z = math.pow(z,2)\n",
    "        dis = math.sqrt(x+y+z)\n",
    "        dist_mx[i, j] = dis\n",
    "\n",
    "####################################################################################\n",
    "#getting adj matrix\n",
    "sensor_ids=node_id\n",
    "\n",
    "# Builds sensor id to index map.\n",
    "sensor_id_to_ind = {}\n",
    "for i, sensor_id in enumerate(sensor_ids):\n",
    "    sensor_id_to_ind[sensor_id] = i\n",
    "\n",
    "# Calculates the standard deviation as theta.\n",
    "distances = dist_mx[~np.isinf(dist_mx)].flatten()\n",
    "std = distances.std()\n",
    "adj_mx = np.exp(-np.square(dist_mx / std))\n",
    "# Make the adjacent matrix symmetric by taking the max.\n",
    "# adj_mx = np.maximum.reduce([adj_mx, adj_mx.T])\n",
    "\n",
    "# Sets entries that lower than a threshold, i.e., k, to zero for sparsity.\n",
    "adj_mx[adj_mx < normalized_k] = 0\n",
    "#return sensor_ids, sensor_id_to_ind, adj_mx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
