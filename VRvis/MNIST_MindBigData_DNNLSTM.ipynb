{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential, Model \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import  BatchNormalization,Dense, Conv2D, Convolution2D, MaxPooling2D, Dropout, Flatten, TimeDistributed, InputLayer, LSTM\n",
    "from keras.layers import Input, Reshape, Activation, add, Add\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import f1_score \n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"mindbigdata.txt\",\"r\")\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in file.readlines():\n",
    "    data.append(line.replace(\"\\t\",\",\").split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eeg=eeg.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG=eeg.drop(eeg.columns[[0,1,2,5]],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#번호별로 data 분리\n",
    "EEG_0=EEG[EEG[4].isin(['0'])]\n",
    "EEG_1=EEG[EEG[4].isin(['1'])]\n",
    "EEG_2=EEG[EEG[4].isin(['2'])]\n",
    "EEG_3=EEG[EEG[4].isin(['3'])]\n",
    "EEG_4=EEG[EEG[4].isin(['4'])]\n",
    "EEG_5=EEG[EEG[4].isin(['5'])]\n",
    "EEG_6=EEG[EEG[4].isin(['6'])]\n",
    "EEG_7=EEG[EEG[4].isin(['7'])]\n",
    "EEG_8=EEG[EEG[4].isin(['8'])]\n",
    "EEG_9=EEG[EEG[4].isin(['9'])]\n",
    "EEG__1=EEG[EEG[4].isin(['-1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_0=pd.DataFrame(EEG_0.values)\n",
    "EEG_1=pd.DataFrame(EEG_1.values)\n",
    "EEG_2=pd.DataFrame(EEG_2.values)\n",
    "EEG_3=pd.DataFrame(EEG_3.values)\n",
    "EEG_4=pd.DataFrame(EEG_4.values)\n",
    "EEG_5=pd.DataFrame(EEG_5.values)\n",
    "EEG_6=pd.DataFrame(EEG_6.values)\n",
    "EEG_7=pd.DataFrame(EEG_7.values)\n",
    "EEG_8=pd.DataFrame(EEG_8.values)\n",
    "EEG_9=pd.DataFrame(EEG_9.values)\n",
    "EEG__1=pd.DataFrame(EEG__1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_0=EEG_0.drop(EEG_0.columns[[0,1]],axis='columns')\n",
    "EEG_1=EEG_1.drop(EEG_1.columns[[0,1]],axis='columns')\n",
    "EEG_2=EEG_2.drop(EEG_2.columns[[0,1]],axis='columns')\n",
    "EEG_3=EEG_3.drop(EEG_3.columns[[0,1]],axis='columns')\n",
    "EEG_4=EEG_4.drop(EEG_4.columns[[0,1]],axis='columns')\n",
    "EEG_5=EEG_5.drop(EEG_5.columns[[0,1]],axis='columns')\n",
    "EEG_6=EEG_6.drop(EEG_6.columns[[0,1]],axis='columns')\n",
    "EEG_7=EEG_7.drop(EEG_7.columns[[0,1]],axis='columns')\n",
    "EEG_8=EEG_8.drop(EEG_8.columns[[0,1]],axis='columns')\n",
    "EEG_9=EEG_9.drop(EEG_9.columns[[0,1]],axis='columns')\n",
    "EEG__1=EEG__1.drop(EEG__1.columns[[0,1]],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_0=EEG_0.values\n",
    "eeg_1=EEG_1.values\n",
    "eeg_2=EEG_2.values\n",
    "eeg_3=EEG_3.values\n",
    "eeg_4=EEG_4.values\n",
    "eeg_5=EEG_5.values\n",
    "eeg_6=EEG_6.values\n",
    "eeg_7=EEG_7.values\n",
    "eeg_8=EEG_8.values\n",
    "eeg_9=EEG_9.values\n",
    "eeg__1=EEG__1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "eeg_0[:]=scaler.fit_transform(eeg_0[:])*255\n",
    "eeg_1[:]=scaler.fit_transform(eeg_1[:])*255\n",
    "eeg_2[:]=scaler.fit_transform(eeg_2[:])*255\n",
    "eeg_3[:]=scaler.fit_transform(eeg_3[:])*255\n",
    "eeg_4[:]=scaler.fit_transform(eeg_4[:])*255\n",
    "eeg_5[:]=scaler.fit_transform(eeg_5[:])*255\n",
    "eeg_6[:]=scaler.fit_transform(eeg_6[:])*255\n",
    "eeg_7[:]=scaler.fit_transform(eeg_7[:])*255\n",
    "eeg_8[:]=scaler.fit_transform(eeg_8[:])*255\n",
    "eeg_9[:]=scaler.fit_transform(eeg_9[:])*255\n",
    "eeg__1[:]=scaler.fit_transform(eeg__1[:])*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeLinearData(eeg):\n",
    "    data=[]\n",
    "    data=np.r_[eeg[0],eeg[1]]\n",
    "    for i in range(2,len(eeg)):\n",
    "        data=np.r_[data,eeg[i]]\n",
    "    return data\n",
    "\n",
    "def convertT(eeg) :\n",
    "    data=[]\n",
    "    for i in range(len(eeg)) :\n",
    "        data.append(eeg[i].T)\n",
    "    data=np.asarray(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0=eeg_0.reshape(-1,14,136)\n",
    "data_1=eeg_1.reshape(-1,14,136)\n",
    "data_2=eeg_2.reshape(-1,14,136)\n",
    "data_3=eeg_3.reshape(-1,14,136)\n",
    "data_4=eeg_4.reshape(-1,14,136)\n",
    "data_5=eeg_5.reshape(-1,14,136)\n",
    "data_6=eeg_6.reshape(-1,14,136)\n",
    "data_7=eeg_7.reshape(-1,14,136)\n",
    "data_8=eeg_8.reshape(-1,14,136)\n",
    "data_9=eeg_9.reshape(-1,14,136)\n",
    "data__1=eeg__1.reshape(-1,14,136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_0=convertT(data_0)\n",
    "eeg_1=convertT(data_1)\n",
    "eeg_2=convertT(data_2)\n",
    "eeg_3=convertT(data_3)\n",
    "eeg_4=convertT(data_4)\n",
    "eeg_5=convertT(data_5)\n",
    "eeg_6=convertT(data_6)\n",
    "eeg_7=convertT(data_7)\n",
    "eeg_8=convertT(data_8)\n",
    "eeg_9=convertT(data_9)\n",
    "eeg__1=convertT(data__1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "finish\n",
      "finish\n",
      "finish\n",
      "finish\n",
      "finish\n",
      "finish\n",
      "finish\n",
      "finish\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "eeg_0=reshapeLinearData(eeg_0)\n",
    "print(\"finish\")\n",
    "eeg_1=reshapeLinearData(eeg_1)\n",
    "print(\"finish\")\n",
    "eeg_2=reshapeLinearData(eeg_2)\n",
    "print(\"finish\")\n",
    "eeg_3=reshapeLinearData(eeg_3)\n",
    "print(\"finish\")\n",
    "eeg_4=reshapeLinearData(eeg_4)\n",
    "print(\"finish\")\n",
    "eeg_5=reshapeLinearData(eeg_5)\n",
    "print(\"finish\")\n",
    "eeg_6=reshapeLinearData(eeg_6)\n",
    "print(\"finish\")\n",
    "eeg_7=reshapeLinearData(eeg_7)\n",
    "print(\"finish\")\n",
    "eeg_8=reshapeLinearData(eeg_8)\n",
    "print(\"finish\")\n",
    "eeg_9=reshapeLinearData(eeg_9)\n",
    "print(\"finish\")\n",
    "eeg__1=reshapeLinearData(eeg__1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(886176, 14) (863736, 14) (883320, 14) (900048, 14) (863464, 14) (893656, 14) (887128, 14) (861832, 14) (891072, 14) (892568, 14) (21624, 14)\n"
     ]
    }
   ],
   "source": [
    "print(eeg_0.shape,eeg_1.shape,eeg_2.shape,eeg_3.shape,eeg_4.shape,eeg_5.shape,eeg_6.shape,eeg_7.shape,eeg_8.shape,eeg_9.shape,eeg__1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0=np.zeros((len(eeg_0),1))\n",
    "label_1=np.ones((len(eeg_1),1))\n",
    "label_2=np.full((len(eeg_2),1),2)\n",
    "label_3=np.full((len(eeg_3),1),2)\n",
    "label_4=np.full((len(eeg_4),1),2)\n",
    "label_5=np.full((len(eeg_5),1),2)\n",
    "label_6=np.full((len(eeg_6),1),2)\n",
    "label_7=np.full((len(eeg_7),1),2)\n",
    "label_8=np.full((len(eeg_8),1),2)\n",
    "label_9=np.full((len(eeg_9),1),2)\n",
    "label__1=np.full((len(eeg__1),1),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8844624, 14)\n"
     ]
    }
   ],
   "source": [
    "data=np.r_[eeg_0,eeg_1]\n",
    "data=np.r_[data,eeg_2]\n",
    "data=np.r_[data,eeg_3]\n",
    "data=np.r_[data,eeg_4]\n",
    "data=np.r_[data,eeg_5]\n",
    "data=np.r_[data,eeg_6]\n",
    "data=np.r_[data,eeg_7]\n",
    "data=np.r_[data,eeg_8]\n",
    "data=np.r_[data,eeg_9]\n",
    "data=np.r_[data,eeg__1]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8844624, 1)\n"
     ]
    }
   ],
   "source": [
    "label=np.r_[label_0,label_1]\n",
    "label=np.r_[label,label_2]\n",
    "label=np.r_[label,label_3]\n",
    "label=np.r_[label,label_4]\n",
    "label=np.r_[label,label_5]\n",
    "label=np.r_[label,label_6]\n",
    "label=np.r_[label,label_7]\n",
    "label=np.r_[label,label_8]\n",
    "label=np.r_[label,label_9]\n",
    "label=np.r_[label,label__1]\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=None, shuffle=True, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6191236, 14) (2653388, 14) (6191236, 11) (2653388, 11)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 11)\n",
    "y_test = to_categorical(y_test, 11)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               2250      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 11)                2211      \n",
      "=================================================================\n",
      "Total params: 34,661\n",
      "Trainable params: 34,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_create(eeg_data):\n",
    "    eeg_input=Input(shape=(14,)) #입력 정의\n",
    "    \n",
    "    eeg_output = Dense(50, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(150, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(150, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(200, activation='relu')(eeg_output)\n",
    "    \n",
    "    model = Dense(11, activation='sigmoid')(eeg_output)\n",
    "    \n",
    "    model = keras.models.Model(inputs=eeg_input, outputs=model) \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    \n",
    "    return model \n",
    "\n",
    "model=model_create(data)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 14, 50)            10400     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 11)                2728      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 13,128\n",
      "Trainable params: 13,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train.reshape(X_train.shape+ (1,))\n",
    "#X_test = X_test.reshape(X_test.shape + (1,))\n",
    "\n",
    "def lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape = (14,1), return_sequences = True))\n",
    "    model.add(LSTM(11, return_sequences = False))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = lstm_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6191236 samples, validate on 2653388 samples\n",
      "Epoch 1/20\n",
      "3791260/6191236 [=================>............] - ETA: 1:13:06 - loss: 0.3494 - accuracy: 0.9651"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b520f9549ba5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, y_train, epochs=20, batch_size=10, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-d42bd558c2a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0macc_ax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwinx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results)\n",
    "\n",
    "_loss, _acc, _precision, _recall, _f1score = model.evaluate(X_test, y_test)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, rec_ax = plt.subplots()\n",
    "\n",
    "pre_ax = rec_ax.twinx()\n",
    "\n",
    "rec_ax.plot(hist.history['recall'], 'y', label='train recall')\n",
    "rec_ax.plot(hist.history['val_recall'], 'r', label='val recall')\n",
    "\n",
    "pre_ax.plot(hist.history['precision'], 'b', label='train precision')\n",
    "pre_ax.plot(hist.history['val_precision'], 'g', label='val precision')\n",
    "\n",
    "rec_ax.set_xlabel('epoch')\n",
    "rec_ax.set_ylabel('recall')\n",
    "pre_ax.set_ylabel('precision')\n",
    "\n",
    "rec_ax.legend(loc='upper left')\n",
    "pre_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
