{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2990,
     "status": "ok",
     "timestamp": 1630956134659,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "xCEi4wueLgkw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Input,Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as kb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import autokeras as ak\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1630956134660,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "IS_hMwJjL-WK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13424,
     "status": "ok",
     "timestamp": 1630956148081,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "HPtB2hKwL_UO",
    "outputId": "37d7fc27-8803-4551-95e1-6001b291ca25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject', 'rest', 'test'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def txtToDataframe(filename, flag1, flag2):\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    datas = []\n",
    "    for line in lines:\n",
    "        txt = line.replace('   ', ' ').lstrip().rstrip().replace(' ', ',')\n",
    "        data = txt.split(',')\n",
    "        datas.append(data)\n",
    "    df = pd.DataFrame(datas)\n",
    "    df.columns = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'F8', 'AF4']\n",
    "    df['label1']=flag1\n",
    "    df['label2']=flag2\n",
    "    return df\n",
    "\n",
    "\n",
    "def getData(src) :\n",
    "    file_list = os.listdir(src)\n",
    "    \n",
    "    rating = pd.DataFrame(pd.read_csv(src+'ratings.txt'))\n",
    "    file_list.remove('ratings.txt')\n",
    "    \n",
    "    dataList=[]\n",
    "    highList=[]\n",
    "    lowList=[]\n",
    "    \n",
    "    print(rating.columns)\n",
    "    j=0\n",
    "    for i in rating['subject']:\n",
    "        if i<10:\n",
    "            num = str(0)+str(i)\n",
    "        else:\n",
    "            num = str(i)\n",
    "        dataList.append(txtToDataframe(src+'sub'+num+'_hi.txt', 1,rating['test'][j]))\n",
    "        dataList.append(txtToDataframe(src+'sub'+num+'_lo.txt', 0,rating['rest'][j]))\n",
    "        highList.append(txtToDataframe(src+'sub'+num+'_hi.txt', 1,rating['test'][j]))\n",
    "        lowList.append(txtToDataframe(src+'sub'+num+'_lo.txt', 0,rating['rest'][j]))\n",
    "        j+=1\n",
    "    return dataList, highList, lowList\n",
    "\n",
    "src = './STEW Dataset/'\n",
    "originalData, highData, lowData = getData(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 55280,
     "status": "ok",
     "timestamp": 1630956203359,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "79KwWryLMkbG",
    "outputId": "3e330fbb-090c-4f52-8200-d1b38e1326e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4584.62</td>\n",
       "      <td>3902.05</td>\n",
       "      <td>4571.79</td>\n",
       "      <td>4589.23</td>\n",
       "      <td>4124.62</td>\n",
       "      <td>3825.13</td>\n",
       "      <td>4152.82</td>\n",
       "      <td>4579.49</td>\n",
       "      <td>4690.77</td>\n",
       "      <td>4260.00</td>\n",
       "      <td>4027.18</td>\n",
       "      <td>4385.13</td>\n",
       "      <td>4480.51</td>\n",
       "      <td>4230.77</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4584.10</td>\n",
       "      <td>3895.90</td>\n",
       "      <td>4574.87</td>\n",
       "      <td>4567.69</td>\n",
       "      <td>4124.10</td>\n",
       "      <td>3827.18</td>\n",
       "      <td>4157.95</td>\n",
       "      <td>4585.13</td>\n",
       "      <td>4695.38</td>\n",
       "      <td>4268.21</td>\n",
       "      <td>4034.36</td>\n",
       "      <td>4380.00</td>\n",
       "      <td>4501.54</td>\n",
       "      <td>4197.44</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4574.36</td>\n",
       "      <td>3893.85</td>\n",
       "      <td>4576.92</td>\n",
       "      <td>4572.82</td>\n",
       "      <td>4123.59</td>\n",
       "      <td>3829.23</td>\n",
       "      <td>4165.13</td>\n",
       "      <td>4590.26</td>\n",
       "      <td>4702.56</td>\n",
       "      <td>4281.54</td>\n",
       "      <td>4030.77</td>\n",
       "      <td>4366.67</td>\n",
       "      <td>4521.03</td>\n",
       "      <td>4176.41</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4573.85</td>\n",
       "      <td>3906.15</td>\n",
       "      <td>4572.82</td>\n",
       "      <td>4612.31</td>\n",
       "      <td>4137.95</td>\n",
       "      <td>3830.77</td>\n",
       "      <td>4167.18</td>\n",
       "      <td>4596.92</td>\n",
       "      <td>4706.15</td>\n",
       "      <td>4285.64</td>\n",
       "      <td>4038.46</td>\n",
       "      <td>4376.41</td>\n",
       "      <td>4518.97</td>\n",
       "      <td>4207.18</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4583.59</td>\n",
       "      <td>3911.28</td>\n",
       "      <td>4570.26</td>\n",
       "      <td>4621.03</td>\n",
       "      <td>4150.77</td>\n",
       "      <td>3833.85</td>\n",
       "      <td>4166.15</td>\n",
       "      <td>4597.44</td>\n",
       "      <td>4705.13</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4051.79</td>\n",
       "      <td>4387.18</td>\n",
       "      <td>4520.51</td>\n",
       "      <td>4220.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727995</th>\n",
       "      <td>4168.21</td>\n",
       "      <td>4124.62</td>\n",
       "      <td>4123.08</td>\n",
       "      <td>4181.54</td>\n",
       "      <td>4621.03</td>\n",
       "      <td>4051.79</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4333.85</td>\n",
       "      <td>4434.87</td>\n",
       "      <td>4038.97</td>\n",
       "      <td>4557.44</td>\n",
       "      <td>4714.87</td>\n",
       "      <td>4711.79</td>\n",
       "      <td>4698.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727996</th>\n",
       "      <td>4166.15</td>\n",
       "      <td>4123.08</td>\n",
       "      <td>4124.10</td>\n",
       "      <td>4180.51</td>\n",
       "      <td>4625.13</td>\n",
       "      <td>4053.85</td>\n",
       "      <td>4294.87</td>\n",
       "      <td>4326.15</td>\n",
       "      <td>4429.23</td>\n",
       "      <td>4035.90</td>\n",
       "      <td>4556.92</td>\n",
       "      <td>4716.92</td>\n",
       "      <td>4706.67</td>\n",
       "      <td>4693.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727997</th>\n",
       "      <td>4167.69</td>\n",
       "      <td>4120.51</td>\n",
       "      <td>4122.05</td>\n",
       "      <td>4178.97</td>\n",
       "      <td>4622.05</td>\n",
       "      <td>4051.79</td>\n",
       "      <td>4289.74</td>\n",
       "      <td>4311.28</td>\n",
       "      <td>4420.00</td>\n",
       "      <td>4024.62</td>\n",
       "      <td>4553.33</td>\n",
       "      <td>4712.82</td>\n",
       "      <td>4699.49</td>\n",
       "      <td>4688.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727998</th>\n",
       "      <td>4170.26</td>\n",
       "      <td>4120.00</td>\n",
       "      <td>4121.54</td>\n",
       "      <td>4181.03</td>\n",
       "      <td>4616.92</td>\n",
       "      <td>4050.77</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4312.31</td>\n",
       "      <td>4421.54</td>\n",
       "      <td>4024.10</td>\n",
       "      <td>4553.85</td>\n",
       "      <td>4712.31</td>\n",
       "      <td>4703.08</td>\n",
       "      <td>4693.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727999</th>\n",
       "      <td>4170.26</td>\n",
       "      <td>4119.49</td>\n",
       "      <td>4122.56</td>\n",
       "      <td>4182.56</td>\n",
       "      <td>4622.05</td>\n",
       "      <td>4057.95</td>\n",
       "      <td>4294.36</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>4427.69</td>\n",
       "      <td>4030.77</td>\n",
       "      <td>4553.33</td>\n",
       "      <td>4713.85</td>\n",
       "      <td>4701.54</td>\n",
       "      <td>4695.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AF3       F7       F3      FC5       T7       O1       O2  \\\n",
       "0        4584.62  3902.05  4571.79  4589.23  4124.62  3825.13  4152.82   \n",
       "1        4584.10  3895.90  4574.87  4567.69  4124.10  3827.18  4157.95   \n",
       "2        4574.36  3893.85  4576.92  4572.82  4123.59  3829.23  4165.13   \n",
       "3        4573.85  3906.15  4572.82  4612.31  4137.95  3830.77  4167.18   \n",
       "4        4583.59  3911.28  4570.26  4621.03  4150.77  3833.85  4166.15   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1727995  4168.21  4124.62  4123.08  4181.54  4621.03  4051.79  4295.38   \n",
       "1727996  4166.15  4123.08  4124.10  4180.51  4625.13  4053.85  4294.87   \n",
       "1727997  4167.69  4120.51  4122.05  4178.97  4622.05  4051.79  4289.74   \n",
       "1727998  4170.26  4120.00  4121.54  4181.03  4616.92  4050.77  4288.21   \n",
       "1727999  4170.26  4119.49  4122.56  4182.56  4622.05  4057.95  4294.36   \n",
       "\n",
       "              P8       T8      FC6       F4       F8       F8      AF4  \\\n",
       "0        4579.49  4690.77  4260.00  4027.18  4385.13  4480.51  4230.77   \n",
       "1        4585.13  4695.38  4268.21  4034.36  4380.00  4501.54  4197.44   \n",
       "2        4590.26  4702.56  4281.54  4030.77  4366.67  4521.03  4176.41   \n",
       "3        4596.92  4706.15  4285.64  4038.46  4376.41  4518.97  4207.18   \n",
       "4        4597.44  4705.13  4282.05  4051.79  4387.18  4520.51  4220.00   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1727995  4333.85  4434.87  4038.97  4557.44  4714.87  4711.79  4698.46   \n",
       "1727996  4326.15  4429.23  4035.90  4556.92  4716.92  4706.67  4693.85   \n",
       "1727997  4311.28  4420.00  4024.62  4553.33  4712.82  4699.49  4688.72   \n",
       "1727998  4312.31  4421.54  4024.10  4553.85  4712.31  4703.08  4693.85   \n",
       "1727999  4320.00  4427.69  4030.77  4553.33  4713.85  4701.54  4695.90   \n",
       "\n",
       "         label1  label2  \n",
       "0             1       8  \n",
       "1             1       8  \n",
       "2             1       8  \n",
       "3             1       8  \n",
       "4             1       8  \n",
       "...         ...     ...  \n",
       "1727995       0       1  \n",
       "1727996       0       1  \n",
       "1727997       0       1  \n",
       "1727998       0       1  \n",
       "1727999       0       1  \n",
       "\n",
       "[1728000 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedData = pd.concat([originalData[0],originalData[1]],ignore_index=True)\n",
    "for i in range(2,len(originalData)):\n",
    "    mergedData = pd.concat([mergedData,originalData[i]],ignore_index=True)\n",
    "mergedData = mergedData.apply(pd.to_numeric)\n",
    "mergedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1630956203360,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "J9-m1dXhMbqW"
   },
   "outputs": [],
   "source": [
    "label=mergedData['label1']\n",
    "label2=mergedData['label2']\n",
    "data=mergedData.drop(['label1','label2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.558932</td>\n",
       "      <td>0.452258</td>\n",
       "      <td>0.539627</td>\n",
       "      <td>0.553295</td>\n",
       "      <td>0.479273</td>\n",
       "      <td>0.449631</td>\n",
       "      <td>0.482450</td>\n",
       "      <td>0.542340</td>\n",
       "      <td>0.558323</td>\n",
       "      <td>0.505813</td>\n",
       "      <td>0.479338</td>\n",
       "      <td>0.521798</td>\n",
       "      <td>0.533296</td>\n",
       "      <td>0.494656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558867</td>\n",
       "      <td>0.451482</td>\n",
       "      <td>0.540022</td>\n",
       "      <td>0.550698</td>\n",
       "      <td>0.479207</td>\n",
       "      <td>0.449895</td>\n",
       "      <td>0.483076</td>\n",
       "      <td>0.543015</td>\n",
       "      <td>0.558871</td>\n",
       "      <td>0.506793</td>\n",
       "      <td>0.480193</td>\n",
       "      <td>0.521187</td>\n",
       "      <td>0.535799</td>\n",
       "      <td>0.490618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.557644</td>\n",
       "      <td>0.451223</td>\n",
       "      <td>0.540286</td>\n",
       "      <td>0.551317</td>\n",
       "      <td>0.479142</td>\n",
       "      <td>0.450158</td>\n",
       "      <td>0.483952</td>\n",
       "      <td>0.543629</td>\n",
       "      <td>0.559726</td>\n",
       "      <td>0.508383</td>\n",
       "      <td>0.479766</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>0.488070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.557580</td>\n",
       "      <td>0.452775</td>\n",
       "      <td>0.539759</td>\n",
       "      <td>0.556078</td>\n",
       "      <td>0.480956</td>\n",
       "      <td>0.450357</td>\n",
       "      <td>0.484202</td>\n",
       "      <td>0.544427</td>\n",
       "      <td>0.560153</td>\n",
       "      <td>0.508873</td>\n",
       "      <td>0.480681</td>\n",
       "      <td>0.520759</td>\n",
       "      <td>0.537874</td>\n",
       "      <td>0.491798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558803</td>\n",
       "      <td>0.453422</td>\n",
       "      <td>0.539430</td>\n",
       "      <td>0.557129</td>\n",
       "      <td>0.482576</td>\n",
       "      <td>0.450753</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>0.544489</td>\n",
       "      <td>0.560032</td>\n",
       "      <td>0.508444</td>\n",
       "      <td>0.482268</td>\n",
       "      <td>0.522042</td>\n",
       "      <td>0.538057</td>\n",
       "      <td>0.493351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727995</th>\n",
       "      <td>0.506663</td>\n",
       "      <td>0.480335</td>\n",
       "      <td>0.481982</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>0.541975</td>\n",
       "      <td>0.478809</td>\n",
       "      <td>0.499843</td>\n",
       "      <td>0.512926</td>\n",
       "      <td>0.527864</td>\n",
       "      <td>0.479439</td>\n",
       "      <td>0.542453</td>\n",
       "      <td>0.561057</td>\n",
       "      <td>0.560825</td>\n",
       "      <td>0.551323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727996</th>\n",
       "      <td>0.506404</td>\n",
       "      <td>0.480140</td>\n",
       "      <td>0.482113</td>\n",
       "      <td>0.504018</td>\n",
       "      <td>0.542493</td>\n",
       "      <td>0.479074</td>\n",
       "      <td>0.499781</td>\n",
       "      <td>0.512004</td>\n",
       "      <td>0.527193</td>\n",
       "      <td>0.479073</td>\n",
       "      <td>0.542391</td>\n",
       "      <td>0.561301</td>\n",
       "      <td>0.560215</td>\n",
       "      <td>0.550765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727997</th>\n",
       "      <td>0.506598</td>\n",
       "      <td>0.479816</td>\n",
       "      <td>0.481850</td>\n",
       "      <td>0.503833</td>\n",
       "      <td>0.542104</td>\n",
       "      <td>0.478809</td>\n",
       "      <td>0.499155</td>\n",
       "      <td>0.510224</td>\n",
       "      <td>0.526094</td>\n",
       "      <td>0.477727</td>\n",
       "      <td>0.541964</td>\n",
       "      <td>0.560813</td>\n",
       "      <td>0.559361</td>\n",
       "      <td>0.550143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727998</th>\n",
       "      <td>0.506920</td>\n",
       "      <td>0.479752</td>\n",
       "      <td>0.481785</td>\n",
       "      <td>0.504081</td>\n",
       "      <td>0.541456</td>\n",
       "      <td>0.478677</td>\n",
       "      <td>0.498968</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.526277</td>\n",
       "      <td>0.477665</td>\n",
       "      <td>0.542026</td>\n",
       "      <td>0.560752</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>0.550765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727999</th>\n",
       "      <td>0.506920</td>\n",
       "      <td>0.479687</td>\n",
       "      <td>0.481916</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.542104</td>\n",
       "      <td>0.479602</td>\n",
       "      <td>0.499719</td>\n",
       "      <td>0.511268</td>\n",
       "      <td>0.527009</td>\n",
       "      <td>0.478460</td>\n",
       "      <td>0.541964</td>\n",
       "      <td>0.560936</td>\n",
       "      <td>0.559605</td>\n",
       "      <td>0.551013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AF3        F7        F3       FC5        T7        O1        O2  \\\n",
       "0        0.558932  0.452258  0.539627  0.553295  0.479273  0.449631  0.482450   \n",
       "1        0.558867  0.451482  0.540022  0.550698  0.479207  0.449895  0.483076   \n",
       "2        0.557644  0.451223  0.540286  0.551317  0.479142  0.450158  0.483952   \n",
       "3        0.557580  0.452775  0.539759  0.556078  0.480956  0.450357  0.484202   \n",
       "4        0.558803  0.453422  0.539430  0.557129  0.482576  0.450753  0.484076   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1727995  0.506663  0.480335  0.481982  0.504143  0.541975  0.478809  0.499843   \n",
       "1727996  0.506404  0.480140  0.482113  0.504018  0.542493  0.479074  0.499781   \n",
       "1727997  0.506598  0.479816  0.481850  0.503833  0.542104  0.478809  0.499155   \n",
       "1727998  0.506920  0.479752  0.481785  0.504081  0.541456  0.478677  0.498968   \n",
       "1727999  0.506920  0.479687  0.481916  0.504266  0.542104  0.479602  0.499719   \n",
       "\n",
       "               P8        T8       FC6        F4        F8        F8       AF4  \n",
       "0        0.542340  0.558323  0.505813  0.479338  0.521798  0.533296  0.494656  \n",
       "1        0.543015  0.558871  0.506793  0.480193  0.521187  0.535799  0.490618  \n",
       "2        0.543629  0.559726  0.508383  0.479766  0.519600  0.538119  0.488070  \n",
       "3        0.544427  0.560153  0.508873  0.480681  0.520759  0.537874  0.491798  \n",
       "4        0.544489  0.560032  0.508444  0.482268  0.522042  0.538057  0.493351  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "1727995  0.512926  0.527864  0.479439  0.542453  0.561057  0.560825  0.551323  \n",
       "1727996  0.512004  0.527193  0.479073  0.542391  0.561301  0.560215  0.550765  \n",
       "1727997  0.510224  0.526094  0.477727  0.541964  0.560813  0.559361  0.550143  \n",
       "1727998  0.510347  0.526277  0.477665  0.542026  0.560752  0.559788  0.550765  \n",
       "1727999  0.511268  0.527009  0.478460  0.541964  0.560936  0.559605  0.551013  \n",
       "\n",
       "[1728000 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(scaled, columns = data.columns, index=data.index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728000, 14) (1728000,) (17280, 10, 14) (17280,)\n"
     ]
    }
   ],
   "source": [
    "def windowing_dataset(data, label, window_size):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(0,len(data)//window_size,window_size):\n",
    "        data_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i]))\n",
    "    return np.array(data_list), np.array(label_list)\n",
    "\n",
    "dataList, labelList = windowing_dataset(data,label,10)\n",
    "#labelList = to_categorical(labelList,9)\n",
    "print(data.shape, label.shape, dataList.shape, labelList.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12096, 10, 14) (5184, 10, 14) (12096, 9) (5184, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataList,labelList, train_size=0.7, random_state=True ,stratify = labelList)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1209600, 14) (518400, 14) (1209600,) (518400,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data,label, train_size=0.7, random_state=True ,stratify = label)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 22m 32s]\n",
      "val_loss: 0.32987186312675476\n",
      "\n",
      "Best val_loss So Far: 0.12271249294281006\n",
      "Total elapsed time: 00h 23m 01s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "image_block_1/b...|efficient         |vanilla           \n",
      "image_block_1/n...|True              |True              \n",
      "image_block_1/a...|True              |False             \n",
      "image_block_1/i...|True              |None              \n",
      "image_block_1/i...|False             |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0.1               |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/e...|True              |None              \n",
      "image_block_1/e...|b7                |None              \n",
      "image_block_1/e...|True              |None              \n",
      "image_block_1/e...|True              |None              \n",
      "classification_...|global_avg        |flatten           \n",
      "classification_...|0                 |0.5               \n",
      "optimizer         |adam              |adam              \n",
      "learning_rate     |2e-05             |0.001             \n",
      "\n",
      "Epoch 1/20\n",
      "Not enough memory, reduce batch size to 16.\n",
      "Epoch 1/20\n",
      "      2/Unknown - 2s 776ms/step - loss: 2.2051 - accuracy: 0.0938Not enough memory, reduce batch size to 8.\n",
      "Epoch 1/20\n",
      "1212/1212 [==============================] - 624s 514ms/step - loss: 0.8843 - accuracy: 0.6437 - val_loss: 2.3127 - val_accuracy: 0.2221\n",
      "Epoch 2/20\n",
      "1212/1212 [==============================] - 627s 518ms/step - loss: 0.5258 - accuracy: 0.7749 - val_loss: 2.5985 - val_accuracy: 0.2221\n",
      "Epoch 3/20\n",
      "1212/1212 [==============================] - 633s 522ms/step - loss: 0.4347 - accuracy: 0.8208 - val_loss: 52.4192 - val_accuracy: 0.5742\n",
      "Epoch 4/20\n",
      "1212/1212 [==============================] - 657s 542ms/step - loss: 0.3692 - accuracy: 0.8501 - val_loss: 11.6359 - val_accuracy: 0.7692\n",
      "Epoch 5/20\n",
      "1212/1212 [==============================] - 635s 524ms/step - loss: 0.3261 - accuracy: 0.8698 - val_loss: 11.9394 - val_accuracy: 0.6296\n",
      "Epoch 6/20\n",
      "1212/1212 [==============================] - 611s 504ms/step - loss: 0.2874 - accuracy: 0.8863 - val_loss: 1.4767 - val_accuracy: 0.5033\n",
      "Epoch 7/20\n",
      "1212/1212 [==============================] - 612s 505ms/step - loss: 0.2704 - accuracy: 0.8970 - val_loss: 149.5233 - val_accuracy: 0.5875\n",
      "Epoch 8/20\n",
      "1212/1212 [==============================] - 611s 504ms/step - loss: 0.2373 - accuracy: 0.9082 - val_loss: 3.8255 - val_accuracy: 0.5654\n",
      "Epoch 9/20\n",
      "1212/1212 [==============================] - 619s 510ms/step - loss: 0.2127 - accuracy: 0.9183 - val_loss: 3.6552 - val_accuracy: 0.2171\n",
      "Epoch 10/20\n",
      "1212/1212 [==============================] - 664s 547ms/step - loss: 0.2131 - accuracy: 0.9169 - val_loss: 4.6500 - val_accuracy: 0.4196\n",
      "Epoch 11/20\n",
      "1212/1212 [==============================] - 660s 545ms/step - loss: 0.1877 - accuracy: 0.9280 - val_loss: 0.6876 - val_accuracy: 0.8196\n",
      "Epoch 12/20\n",
      "1212/1212 [==============================] - 674s 556ms/step - loss: 0.1753 - accuracy: 0.9333 - val_loss: 20.8109 - val_accuracy: 0.2129\n",
      "Epoch 13/20\n",
      "1212/1212 [==============================] - 658s 543ms/step - loss: 0.1626 - accuracy: 0.9406 - val_loss: 6.6130 - val_accuracy: 0.1958\n",
      "Epoch 14/20\n",
      "1212/1212 [==============================] - 654s 540ms/step - loss: 0.1578 - accuracy: 0.9370 - val_loss: 1.2022 - val_accuracy: 0.8204\n",
      "Epoch 15/20\n",
      "1212/1212 [==============================] - 652s 538ms/step - loss: 0.1450 - accuracy: 0.9446 - val_loss: 50.4781 - val_accuracy: 0.2113\n",
      "Epoch 16/20\n",
      "1212/1212 [==============================] - 638s 526ms/step - loss: 0.1340 - accuracy: 0.9508 - val_loss: 13.6842 - val_accuracy: 0.7650\n",
      "Epoch 17/20\n",
      "1212/1212 [==============================] - 677s 558ms/step - loss: 0.1230 - accuracy: 0.9538 - val_loss: 18.5355 - val_accuracy: 0.2042\n",
      "Epoch 18/20\n",
      "1212/1212 [==============================] - 651s 537ms/step - loss: 0.1300 - accuracy: 0.9497 - val_loss: 0.6377 - val_accuracy: 0.7650\n",
      "Epoch 19/20\n",
      " 352/1212 [=======>......................] - ETA: 6:53 - loss: 0.1065 - accuracy: 0.9553"
     ]
    }
   ],
   "source": [
    "trials=[20] #3,5,10, \n",
    "for trial in trials:\n",
    "    clf_ = ak.ImageClassifier(overwrite=True, max_trials=trial)\n",
    "    clf_.fit(x=X_train, y=Y_train, epochs=20)\n",
    "\n",
    "    predicted_y = clf_.predict(X_test)\n",
    "    print(predicted_y)\n",
    "    loss, acc = clf_.evaluate(X_test, Y_test)\n",
    "    print(clf_.evaluate(X_test, Y_test))\n",
    "    print('Loss: %.3f   Accuracy: %.3f' % (loss,acc))\n",
    "\n",
    "    model = clf_.export_model()\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True)\n",
    "    tmp = int(acc*100)\n",
    "    print(tmp)\n",
    "    model.save('model/WindowingLabel2AutoKeras_'+\n",
    "                str(datetime.now().strftime('%Y-%m-%d %H-%M-%S'))+' ACC_'+str(tmp)+'try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1 + (Model2-1 + Model2-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing_dataset(data, label, window_size):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(0,len(data)//window_size,window_size):\n",
    "        data_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i]))\n",
    "    return np.array(data_list), np.array(label_list)\n",
    "\n",
    "dataList, labelList = windowing_dataset(data,label,10)\n",
    "#labelList = to_categorical(labelList,9)\n",
    "print(data.shape, label.shape, dataList.shape, labelList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('_.h5')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataList,labelList, train_size=0.7, random_state=True ,stratify = labelList)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "if model.predict_classes():\n",
    "    \n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataList,labelList, train_size=0.7, random_state=True ,stratify = labelList)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "clf = ak.ImageClassifier(overwrite=True)\n",
    "clf.fit(x=X_train, y=Y_train, epochs=30)\n",
    "\n",
    "predicted_y = clf.predict(X_test)\n",
    "print(predicted_y)\n",
    "loss, acc = clf.evaluate(X_test, Y_test)\n",
    "print('Loss: %.3f   Accuracy: %.3f' % (loss,acc, v))\n",
    "\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True)\n",
    "tmp = int(acc*100)\n",
    "model.save('model/WindowingAutoKeras_'+\n",
    "            str(datetime.now().strftime('%Y-%m-%d %H-%M-%S'))+' ACC_'+str(tmp)+'try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in trials:\n",
    "    clf = ak.StructuredDataClassifier(max_trials=trial)\n",
    "    clf.fit(x=x_train, y=y_train)\n",
    "\n",
    "    predicted_y = clf.predict(x_test)\n",
    "    print(predicted_y)\n",
    "    loss, acc = clf.evaluate(x_test, y_test)\n",
    "    print('Loss: %.3f   Accuracy: %.3f' % (loss,acc))\n",
    "\n",
    "    model = clf.export_model()\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True)\n",
    "    model.save('model/autoKeras_'+str(trial)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=[10, 15, 20]\n",
    "\n",
    "for trial in trials:\n",
    "    for epoch in epochs:\n",
    "        clf = ak.ImageClassifier(max_trials=trial)\n",
    "        clf.fit(x=X_train, y=Y_train, epochs=epoch)\n",
    "\n",
    "        predicted_y = clf.predict(X_test)\n",
    "        print(predicted_y)\n",
    "        loss, acc = clf.evaluate(X_test, Y_test)\n",
    "        print('Loss: %.3f   Accuracy: %.3f' % (loss,acc))\n",
    "\n",
    "        model = clf.export_model()\n",
    "        model.summary()\n",
    "        plot_model(model, show_shapes=True)\n",
    "        model.save('model/WindowingAutoKeras_'+str(trial)+'_'+str(epoch)+'.h5')\n",
    "        \n",
    "        clf = ak.StructuredDataClassifier(max_trials=trial)\n",
    "        clf.fit(x=x_train, y=y_train, epochs=30)\n",
    "\n",
    "        predicted_y = clf.predict(x_test)\n",
    "        print(predicted_y)\n",
    "        loss, acc = clf.evaluate(x_test, y_test)\n",
    "        print('Loss: %.3f   Accuracy: %.3f' % (loss,acc))\n",
    "\n",
    "        model = clf.export_model()\n",
    "        model.summary()\n",
    "        plot_model(model, show_shapes=True)\n",
    "        model.save('model/autoKeras_'+str(trial)+'_'+str(epoch)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1630956343175,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "CjAL4I6jONa1"
   },
   "outputs": [],
   "source": [
    "#epochs = [x for x in range(10, 101, 10)]\n",
    "epochs = [10, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1630956343176,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "2RlynNQAOOP-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1630956343176,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "-bYb6obYS8vv"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1630956343176,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "feGz2dnkUQ3m"
   },
   "outputs": [],
   "source": [
    "def lossAcc(hist):\n",
    "  fig, loss_ax = plt.subplots()\n",
    "\n",
    "  acc_ax = loss_ax.twinx()\n",
    "\n",
    "  loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "  acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "  loss_ax.set_xlabel('epoch')\n",
    "  loss_ax.set_ylabel('loss')\n",
    "  acc_ax.set_ylabel('accuray')\n",
    "\n",
    "  loss_ax.legend(loc='upper left')\n",
    "  acc_ax.legend(loc='lower left')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  _loss, _acc, _precision, _recall, _f1score = model.evaluate(x_test, y_test)\n",
    "  print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1630956343177,
     "user": {
      "displayName": "잉슝빙",
      "photoUrl": "",
      "userId": "01566298293687163523"
     },
     "user_tz": -540
    },
    "id": "d9Aqdp6NURD2"
   },
   "outputs": [],
   "source": [
    "def recallAndPrecision(hist):\n",
    "  fig, rec_ax = plt.subplots()\n",
    "\n",
    "  pre_ax = rec_ax.twinx()\n",
    "\n",
    "  rec_ax.plot(hist.history['recall'], 'y', label='recall')\n",
    "\n",
    "  pre_ax.plot(hist.history['precision'], 'b', label='precision')\n",
    "\n",
    "  rec_ax.set_xlabel('epoch')\n",
    "  rec_ax.set_ylabel('recall')\n",
    "  pre_ax.set_ylabel('precision')\n",
    "\n",
    "  rec_ax.legend(loc='upper left')\n",
    "  pre_ax.legend(loc='lower left')\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBrLQuJUORIt",
    "outputId": "df692aba-3492-4e0e-d658-c28f1153cb9a"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(10, 14)))\n",
    "model.add(Conv1D(32, 1, activation='tanh', padding='same'))\n",
    "model.add(MaxPooling1D(1, padding='same'))\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(10, 14)))\n",
    "    model.add(Conv1D(32, 1, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(1, padding='same'))\n",
    "    model.add(LSTM(64, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Esn7bXI-OX72"
   },
   "outputs": [],
   "source": [
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(10, 14)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3fpwPqfOXwd"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(10,14), return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1))\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    odel.add(LSTM(64, input_shape=(10,14), return_sequences=True))\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VF8cx_5iZdZ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(10, 14)))\n",
    "model.add(Conv1D(32, 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(1, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1))\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(10, 14)))\n",
    "    model.add(Conv1D(32, 1, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(1, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vr8E9KAFiy5A"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, input_shape=(10,14), return_sequences=True))\n",
    "model.add(SimpleRNN(50, return_sequences=False))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1))\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, input_shape=(10,14), return_sequences=True))\n",
    "    model.add(SimpleRNN(50, return_sequences=False))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqCQa4AmjKIx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(50, return_sequences=True, input_shape=(10,7)))\n",
    "model.add(GRU(60, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1))\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, return_sequences=True, input_shape=(10,14)))\n",
    "    model.add(GRU(60, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezWMFFjFjTHQ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(10, 14)))\n",
    "model.add(Conv1D(32, 1, activation='tanh', padding='same'))\n",
    "model.add(MaxPooling1D(1, padding='same'))\n",
    "model.add(SimpleRNN(64, activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(10, 7)))\n",
    "    model.add(Conv1D(32, 1, activation='tanh', padding='same'))\n",
    "    model.add(MaxPooling1D(1, padding='same'))\n",
    "    model.add(SimpleRNN(64, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJOPtIQ6je5y"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(10, 14)))\n",
    "model.add(Conv1D(32, 1, activation='tanh', padding='same'))\n",
    "model.add(MaxPooling1D(1, padding='same'))\n",
    "model.add(GRU(64, activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(epoch)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(10, 14)))\n",
    "    model.add(Conv1D(32, 1, activation='tanh', padding='same'))\n",
    "    model.add(MaxPooling1D(1, padding='same'))\n",
    "    model.add(GRU(64, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy', precision, recall, f1score])\n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=64)\n",
    "    lossAcc(hist)\n",
    "    recallAndPrecision(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XCOOarcj7B_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyODloEOYr/hQ7PNUaVi2887",
   "collapsed_sections": [],
   "name": "eeg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
