{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2093,
     "status": "error",
     "timestamp": 1591417794490,
     "user": {
      "displayName": "KALAIVAANI.N 17ITR044",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64",
      "userId": "06629915513144874112"
     },
     "user_tz": -330
    },
    "id": "WixtMeQsck25",
    "outputId": "ab1d8469-d36b-4a38-d7c0-777d866e2472"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "import scipy.stats as sp\n",
    "from spectrum import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7502,
     "status": "ok",
     "timestamp": 1591527510390,
     "user": {
      "displayName": "KALAIVAANI.N 17ITR044",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64",
      "userId": "06629915513144874112"
     },
     "user_tz": -330
    },
    "id": "BMUxL35fdDaU",
    "outputId": "32d81c38-dc68-4be3-b15d-981fa410d698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyedflib in /usr/local/lib/python3.6/dist-packages (0.1.17)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from pyedflib) (1.18.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyedflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14605,
     "status": "ok",
     "timestamp": 1591527523224,
     "user": {
      "displayName": "KALAIVAANI.N 17ITR044",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64",
      "userId": "06629915513144874112"
     },
     "user_tz": -330
    },
    "id": "pOetOATcdPhC",
    "outputId": "756f946e-6e51-421d-b444-1fa1b43bc0fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nitime\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/28/3cb014175d93fd01f2b13250afcace3c19e5abfe36790943f3cc6519a8e2/nitime-0.8.1.tar.gz (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1MB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.18.4)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from nitime) (0.29.19)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nitime) (3.2.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from nitime) (2.4)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from nitime) (3.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.4.7)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->nitime) (4.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->nitime) (1.12.0)\n",
      "Building wheels for collected packages: nitime\n",
      "  Building wheel for nitime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nitime: filename=nitime-0.8.1-cp36-cp36m-linux_x86_64.whl size=4038230 sha256=c616361cc861cf5641807ef5f8e9f1adeeff42bf99ca744ff3bae4a84a47a59d\n",
      "  Stored in directory: /root/.cache/pip/wheels/74/02/c5/677c895b41dcaf4fd7c4ff436fbdf8a5d846ed90a0a3276073\n",
      "Successfully built nitime\n",
      "Installing collected packages: nitime\n",
      "Successfully installed nitime-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nitime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8789,
     "status": "ok",
     "timestamp": 1591527531623,
     "user": {
      "displayName": "KALAIVAANI.N 17ITR044",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64",
      "userId": "06629915513144874112"
     },
     "user_tz": -330
    },
    "id": "vhIYq_7Gdguu",
    "outputId": "3c6dab10-be7e-4e38-f429-8f67a7016e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spectrum\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/40/1923c4ab434024f1eb9b9ab3b2b0693ddacb21ace92ea280461b37605c0e/spectrum-0.7.6.tar.gz (227kB)\n",
      "\r",
      "\u001b[K     |█▍                              | 10kB 17.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 40kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 51kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 61kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 71kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 81kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 92kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 143kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 153kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 163kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 174kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 184kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 194kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 204kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 215kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 225kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 235kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectrum) (1.18.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spectrum) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from spectrum) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->spectrum) (1.12.0)\n",
      "Building wheels for collected packages: spectrum\n",
      "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for spectrum: filename=spectrum-0.7.6-cp36-cp36m-linux_x86_64.whl size=234246 sha256=4e5e25168e0f7519a2b29ebf4c0b6159da63694d9f6633997ba59ad33dae7717\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/a1/1f/16e3bd0418dc16201a4f2e696ab00de3e3c95549cba7df5d13\n",
      "Successfully built spectrum\n",
      "Installing collected packages: spectrum\n",
      "Successfully installed spectrum-0.7.6\n"
     ]
    }
   ],
   "source": [
    "!pip install spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5D31DSudxWH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "import scipy.stats as sp\n",
    "from spectrum import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsPa--1ud2DL"
   },
   "outputs": [],
   "source": [
    "names = ['Activity','Mobility','Complexity','Kurtosis','2nd Difference Mean','2nd Difference Max','Coeffiecient of Variation','Skewness','1st Difference Mean','1st Difference Max',\n",
    "          'Wavelet Approximate Mean','Wavelet Approximate Std Deviation','Wavelet Detailed Mean','Wavelet Detailed Std Deviation','Wavelet Approximate Energy','Wavelet Detailed Energy',\n",
    "          'Wavelet Approximate Entropy','Wavelet Detailed Entropy','Variance','Mean of Vertex to Vertex Slope','FFT Delta MaxPower','FFT Theta MaxPower','FFT Alpha MaxPower','FFT Beta MaxPower',\n",
    "          'Autro Regressive Mode Order 3 Coefficients for each channel ->']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYTWyqVkeATA"
   },
   "outputs": [],
   "source": [
    "def hjorth(input):                                             # function for hjorth \n",
    "    realinput = input\n",
    "    hjorth_activity = np.zeros(len(realinput))\n",
    "    hjorth_mobility = np.zeros(len(realinput))\n",
    "    hjorth_diffmobility = np.zeros(len(realinput))\n",
    "    hjorth_complexity = np.zeros(len(realinput))\n",
    "    diff_input = np.diff(realinput)\n",
    "    diff_diffinput = np.diff(diff_input)\n",
    "    k = 0\n",
    "    for j in realinput:\n",
    "        hjorth_activity[k] = np.var(j)\n",
    "        hjorth_mobility[k] = np.sqrt(np.var(diff_input[k])/hjorth_activity[k])\n",
    "        hjorth_diffmobility[k] = np.sqrt(np.var(diff_diffinput[k])/np.var(diff_input[k]))\n",
    "        hjorth_complexity[k] = hjorth_diffmobility[k]/hjorth_mobility[k]\n",
    "        k = k+1\n",
    "    return np.sum(hjorth_activity)/14, np.sum(hjorth_mobility)/14, np.sum(hjorth_complexity)/14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8WEpZqheC5y"
   },
   "outputs": [],
   "source": [
    "def my_kurtosis(a):\n",
    "    b = a # Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    k = 0; # For counting the current row no.\n",
    "    for i in b:\n",
    "        mean_i = np.mean(i) # Saving the mean of array i\n",
    "        std_i = np.std(i) # Saving the standard deviation of array i\n",
    "        t = 0.0\n",
    "        for j in i:\n",
    "            t += (pow((j-mean_i)/std_i,4)-3)\n",
    "        kurtosis_i = t/len(i) # Formula: (1/N)*(summation(x_i-mean)/standard_deviation)^4-3\n",
    "        output[k] = kurtosis_i # Saving the kurtosis in the array created\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "##----------------------------------------- End Kurtosis Function ----------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMean(Absolute difference) Function ------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] --------------- ##\n",
    "##-------------------  -- [ Output: 1D array (2ndDiffMean values for each channel)] ----------##\n",
    "\n",
    "def secDiffMean(a):\n",
    "    b = a # Extracting the data of the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    for i in b:\n",
    "        t = 0.0\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "        for j in range(len(i)-2):\n",
    "            t += abs(temp1[j+1]-temp1[j]) # Summing the 2nd Diffs\n",
    "        output[k] = t/(len(i)-2) # Calculating the mean of the 2nd Diffs\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "##------------------------------------- End 2ndDiffMean Function----- -------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMax Function(Absolute difference) --------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] -----------------##\n",
    "##--------------------- [ Output: 1D array (2ndDiffMax values for each channel)] --------------##\n",
    "\n",
    "def secDiffMax(a):\n",
    "    b = a # Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    t = 0.0\n",
    "    for i in b:\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "        t = temp1[1] - temp1[0]\n",
    "        for j in range(len(i)-2):\n",
    "            if abs(temp1[j+1]-temp1[j]) > t :\n",
    "            \tt = temp1[j+1]-temp1[j] # Comparing current Diff with the last updated Diff Max\n",
    "\n",
    "        output[k] = t # Storing the 2nd Diff Max for channel k\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "\n",
    "\n",
    "def wrapper1(a):\n",
    "    kurtosis =  my_kurtosis(a)\n",
    "    sec_diff_mean = secDiffMean(a)\n",
    "    sec_diff_max  = secDiffMax(a)\n",
    "    return kurtosis,sec_diff_mean,sec_diff_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjZ5FLv_eabz"
   },
   "outputs": [],
   "source": [
    "def coeff_var(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        mean_i = np.mean(i) #Saving the mean of array i\n",
    "        std_i = np.std(i) #Saving the standard deviation of array i\n",
    "        output[k] = std_i/mean_i #computing coefficient of variation\n",
    "        k=k+1\n",
    "    return np.sum(output)/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQ_Q5xYpgpmR"
   },
   "outputs": [],
   "source": [
    "def skewness(arr):\n",
    "    data = arr \n",
    "    skew_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        skew_array[index]=sp.stats.skew(i,axis=0,bias=True)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(skew_array)/14\n",
    "\n",
    "\n",
    "def first_diff_mean(arr):\n",
    "    data = arr \n",
    "    diff_mean_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        sum=0.0#initializing the sum at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            sum += abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "           \n",
    "        diff_mean_array[index]=sum/(len(i)-1)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_mean_array)/14\n",
    "\n",
    "\n",
    "def first_diff_max(arr):\n",
    "    data = arr \n",
    "    diff_max_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    first_diff = np.zeros(len(data[0])-1)#Initialinling the array as all 0s \n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        max=0.0#initializing at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            first_diff[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "            if first_diff[j]>max: \n",
    "                max=first_diff[j] # finding the maximum of the first differences\n",
    "        diff_max_array[index]=max\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_max_array)/14\n",
    "\n",
    "\n",
    "def wrapper2(arr):\n",
    "    skew   = skewness(arr)\n",
    "    fdmean = first_diff_mean(arr)\n",
    "    fdmax  = first_diff_max(arr)\n",
    "    return skew,fdmean,fdmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HE9NPTF3gz2u"
   },
   "outputs": [],
   "source": [
    "def wavelet_features(epoch):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy =[]\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    for i in range(14):\n",
    "        cA,cD=pywt.dwt(epoch[i,:],'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
    "    for x in range(14):   \n",
    "        cA_mean.append(np.mean(cA_values[x]))\n",
    "        cA_std.append(np.std(cA_values[x]))\n",
    "        cA_Energy.append(np.sum(np.square(cA_values[x])))\n",
    "        cD_mean.append(np.mean(cD_values[x]))\t\t# mean and standard deviation values of coefficents of each channel is stored .\n",
    "        cD_std.append(np.std(cD_values[x]))\n",
    "        cD_Energy.append(np.sum(np.square(cD_values[x])))\n",
    "        Entropy_D.append(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x]))))\n",
    "        Entropy_A.append(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))\n",
    "    return np.sum(cA_mean)/14,np.sum(cA_std)/14,np.sum(cD_mean)/14,np.sum(cD_std)/14,np.sum(cA_Energy)/14,np.sum(cD_Energy)/14,np.sum(Entropy_A)/14,np.sum(Entropy_D)/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TXVQ0sgPhDti"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def first_diff(i):\n",
    "    b=i\n",
    "    \n",
    "    \n",
    "    out = np.zeros(len(b))\n",
    "    \n",
    "    for j in range(len(i)):\n",
    "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
    "        \n",
    "        j=j+1\n",
    "        c=out[1:len(out)]\n",
    "    return c\n",
    "\n",
    "#first_diff(s)\n",
    "\n",
    "def slope_mean(p):\n",
    "    b = p #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]\n",
    "        t_max = argrelextrema(x, np.greater)[0]\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]\n",
    "        t_min = argrelextrema(x, np.less)[0]\n",
    "        t = np.concatenate((t_max,t_min),axis=0)\n",
    "        t.sort()#sort on the basis of time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q]         \n",
    "        output[k] = np.mean(res) \n",
    "        k=k+1\n",
    "    return np.sum(output)/14\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def first_diff(i):\n",
    "    b=i\n",
    "    \n",
    "    \n",
    "    out = np.zeros(len(b))\n",
    "    \n",
    "    for j in range(len(i)):\n",
    "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
    "        \n",
    "        j=j+1\n",
    "        c=out[1:len(out)]\n",
    "    return c #returns first diff\n",
    "\n",
    "\n",
    "def slope_var(p):\n",
    "    b = p #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]#storing maxima value\n",
    "        t_max = argrelextrema(x, np.greater)[0]#storing time for maxima\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]#storing minima value\n",
    "        t_min = argrelextrema(x, np.less)[0]#storing time for minima value\n",
    "        t = np.concatenate((t_max,t_min),axis=0) #making a single matrix of all matrix\n",
    "        t.sort() #sorting according to time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q] #calculating slope        \n",
    "    \n",
    "        output[k] = np.var(res) \n",
    "        k=k+1#counting k\n",
    "    return np.sum(output)/14\n",
    "\n",
    "def wrapper3(epoch):\n",
    "    var1 = slope_mean(epoch)\n",
    "    var2 = slope_var(epoch)\n",
    "    return var1,var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpo-bR-QhS7b"
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def maxPwelch(data_win,Fs):\n",
    " \n",
    "    \n",
    "    BandF = [0.1, 3, 7, 12, 30]\n",
    "    PMax = np.zeros([14,(len(BandF)-1)]);\n",
    "    \n",
    "    for j in range(14):\n",
    "        f,Psd = signal.welch(data_win[j,:], Fs)\n",
    "        \n",
    "        for i in range(len(BandF)-1):\n",
    "            fr = np.where((f>BandF[i]) & (f<=BandF[i+1]))\n",
    "            PMax[j,i] = np.max(Psd[fr])\n",
    "    \n",
    "    return np.sum(PMax[:,0])/14,np.sum(PMax[:,1])/14,np.sum(PMax[:,2])/14,np.sum(PMax[:,3])/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-Zc4Oxmha20"
   },
   "outputs": [],
   "source": [
    "def entropy(labels): # Shanon Entropy\n",
    "    \"\"\" Computes entropy of 0-1 vector. \"\"\"\n",
    "    n_labels = len(labels)\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts[np.nonzero(counts)] / n_labels\n",
    "    n_classes = len(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "    return - np.sum(probs * np.log(probs)) / np.log(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmDxrYrJhkqe"
   },
   "outputs": [],
   "source": [
    "def autogressiveModelParameters(labels):\n",
    "    b_labels = len(labels)\n",
    "    feature = []\n",
    "    for i in range(14):\n",
    "        coeff, sig = alg.AR_est_YW(labels[i,:], 11,)\n",
    "        feature.append(coeff)\n",
    "    a = []     \n",
    "    for i in range(11):\n",
    "        a.append(np.sum(feature[:][i])/14)\n",
    "     \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qzz3XmKuhoQd"
   },
   "outputs": [],
   "source": [
    "def autogressiveModelParametersBurg(labels):\n",
    "    feature = []\n",
    "    feature1 = []\n",
    "    model_order = 3\n",
    "    for i in range(14):\n",
    "        AR, rho, ref = arburg(labels[i], model_order)\n",
    "        feature.append(AR);\n",
    "    for j in range(14):\n",
    "        for i in range(model_order):\n",
    "            feature1.append(feature[j][i])\n",
    "\n",
    "    return feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjbvHaZdhtWY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Data/Low/S01-01-25.09.2016.10.52.46.edf\n"
     ]
    }
   ],
   "source": [
    "lowfiles  = [f for f in listdir('Training-Data/Low') if isfile(join('Training-Data/Low', f))] \n",
    "highfiles = [f for f in listdir('Training-Data/High') if isfile(join('Training-Data/High', f))]\n",
    "files = []\n",
    "\n",
    "for i in lowfiles:\n",
    "    files.append([i,'Training-Data/Low'])\n",
    "    \n",
    "for i in highfiles:\n",
    "    files.append([i,'Training-Data/High'])\n",
    "    \n",
    "#mypath = 'Training-Data/'\n",
    "csvfile = \"Features/features.csv\"\n",
    "\n",
    "with open(csvfile, \"a\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(names) \n",
    "    for counter in range(len(files)):\n",
    "        subfolder =  files[counter][1]\n",
    "        tag = files[counter][1] \n",
    "        data_path = subfolder +'/'+files[counter][0] #mypath + subfolder +'/'+files[counter][0]\n",
    "        print(data_path)\n",
    "        f = pyedflib.EdfReader(data_path)\n",
    "        n = f.signals_in_file\n",
    "        signal_labels = f.getSignalLabels()\n",
    "        sigbufs = np.zeros((14, f.getNSamples()[3]))\n",
    "        for i in np.arange(14):\n",
    "            sigbufs[i,:] = f.readSignal(i+2)\n",
    "        for i in np.arange(5,185,3):\n",
    "            features = []\n",
    "            epoch = sigbufs[:,i*128:(i+3)*128]\n",
    "            if len(epoch[0]) == 0:\n",
    "                break\n",
    "            \n",
    "            # Hjorth Parameters\n",
    "            feature_list = hjorth(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "        \n",
    "            #Kurtosis , 2nd Diff Mean, 2nd Diff Max\n",
    "            feature_list = wrapper1(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "            \n",
    "            #Coeffeicient of Variation\n",
    "            feat = coeff_var(epoch)\n",
    "            features.append(feat)\n",
    "            \n",
    "            #Skewness , 1st Difference Mean, 1st Difference Max\n",
    "            feature_list = wrapper2(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "            \n",
    "            \n",
    "            # wavelet transform features \n",
    "            feature_list = wavelet_features(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "        \n",
    "        \n",
    "            # Variance and mean of Vertex to Vertex Slope\n",
    "            feature_list = wrapper3(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "            \n",
    "            \n",
    "            #Fast Fourier Transform features(Max Power)\n",
    "            feature_list  =  maxPwelch(epoch,128)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat)\n",
    "        \n",
    "            #Autoregressive model Coefficients\n",
    "            feature_list = autogressiveModelParametersBurg(epoch)\n",
    "            for feat in feature_list:\n",
    "                features.append(feat.real)\n",
    "            \n",
    "            features.append(tag);\n",
    "        \n",
    "            writer.writerow(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8X7lrHnh8ym"
   },
   "outputs": [],
   "source": [
    "r = csv.reader(open('Features/features.csv')) # Here your csv file\n",
    "lines = [l for l in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1591527633286,
     "user": {
      "displayName": "KALAIVAANI.N 17ITR044",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64",
      "userId": "06629915513144874112"
     },
     "user_tz": -330
    },
    "id": "7OU9NB5TiBeX",
    "outputId": "3fca226e-4dd3-4d9b-dcd1-5804907f8d93"
   },
   "outputs": [],
   "source": [
    "for i in range(len(lines[1])-1):  \n",
    "    columns = []\n",
    "    for j in range(1,len(lines)):\n",
    "        try:\n",
    "            columns.append(float(lines[j][i]))\n",
    "        except ValueError:\n",
    "            break\n",
    "\n",
    "    mean = np.mean(columns,axis = 0)\n",
    "    std_dev  = np.std(columns,axis = 0)\n",
    "    \n",
    "    for j in range(1,len(lines)):\n",
    "        try:\n",
    "           lines[j][i] = (float(lines[j][i])-mean)/std_dev\n",
    "        except ValueError:\n",
    "           break\n",
    "\n",
    "writer = csv.writer(open('Features/Normalizedfeatures.csv', 'w')) # This file will store the normalized features\n",
    "writer.writerows(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNxolltxJtD5gjMItzNcPPF",
   "mount_file_id": "1MBF7G6cEtClE7cTFqa7J9iMZPo8cDUtS",
   "name": "EEG Feature Extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
