{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "EEG = genfromtxt(\"Confusion during MOOC/EEG_data.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6의 raw데이터에 이상이 있으므로 6을 제외하고 분석\n",
    "EEG=EEG[1:,:]\n",
    "EEG=pd.DataFrame(EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12811, 15) (1275,)\n"
     ]
    }
   ],
   "source": [
    "remove_6=EEG[EEG[0]==6].index\n",
    "print(EEG.shape, remove_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11536, 15)\n"
     ]
    }
   ],
   "source": [
    "EEG=EEG.drop(remove_6)\n",
    "print(EEG.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_EEG=EEG[EEG[14]==0].index\n",
    "nc_EEG=EEG[EEG[14]==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusedEEG=EEG.drop(c_EEG)\n",
    "NonConfusedEEG=EEG.drop(nc_EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusedEEG=ConfusedEEG.values\n",
    "NonConfusedEEG=NonConfusedEEG.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index=[]\n",
    "for i in range(7) :\n",
    "    index.append(random.randint(0,5606))\n",
    "    \n",
    "NonConfusedEEG=pd.DataFrame(NonConfusedEEG)\n",
    "NonConfusedEEG=NonConfusedEEG.drop(index)\n",
    "NonConfusedEEG=NonConfusedEEG.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "for i in range(29) :\n",
    "    index.append(random.randint(0,5928))\n",
    "    \n",
    "ConfusedEEG=pd.DataFrame(ConfusedEEG)\n",
    "ConfusedEEG=ConfusedEEG.drop(index)\n",
    "ConfusedEEG=ConfusedEEG.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 15) (5600, 15)\n"
     ]
    }
   ],
   "source": [
    "X=ConfusedEEG\n",
    "NX=NonConfusedEEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동영상, raw, 주파수 data 사용\n",
    "X1=pd.DataFrame(X)\n",
    "X1=X1.drop(X1.columns[[0,2,3,13,14]], axis='columns')\n",
    "#사람 정보, raw, 주파수 data 사용\n",
    "X2=pd.DataFrame(X)\n",
    "X2=X2.drop(X2.columns[[1,2,3,13,14]], axis='columns')\n",
    "#동영상, raw, 주파수 data 사용\n",
    "X3=pd.DataFrame(X)\n",
    "X3=X3.drop(X3.columns[[0,2,3,4,13,14]], axis='columns')\n",
    "#사람 정보, 주파수 data 사용\n",
    "X4=pd.DataFrame(X)\n",
    "X4=X4.drop(X4.columns[[1,2,3,4,13,14]], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동영상, raw, 주파수 data 사용\n",
    "NX1=pd.DataFrame(NX)\n",
    "NX1=NX1.drop(NX1.columns[[0,2,3,13,14]], axis='columns')\n",
    "#사람 정보, raw, 주파수 data 사용\n",
    "NX2=pd.DataFrame(NX)\n",
    "NX2=NX2.drop(NX2.columns[[1,2,3,13,14]], axis='columns')\n",
    "#동영상, raw, 주파수 data 사용\n",
    "NX3=pd.DataFrame(NX)\n",
    "NX3=NX3.drop(NX3.columns[[0,2,3,4,13,14]], axis='columns')\n",
    "#사람 정보, 주파수 data 사용\n",
    "NX4=pd.DataFrame(NX)\n",
    "NX4=NX4.drop(NX4.columns[[1,2,3,4,13,14]], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 10) (5900, 10) (5900, 9) (5900, 9)\n",
      "(5600, 10) (5600, 10) (5600, 9) (5600, 9)\n"
     ]
    }
   ],
   "source": [
    "X1=X1.values\n",
    "X2=X2.values\n",
    "X3=X3.values\n",
    "X4=X4.values\n",
    "\n",
    "NX1=NX1.values\n",
    "NX2=NX2.values\n",
    "NX3=NX3.values\n",
    "NX4=NX4.values\n",
    "\n",
    "print(X1.shape, X2.shape, X3.shape, X4.shape)\n",
    "print(NX1.shape, NX2.shape, NX3.shape, NX4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 10) (5600, 10)\n"
     ]
    }
   ],
   "source": [
    "#X=X1\n",
    "X=X2\n",
    "#X=X3\n",
    "#X=X4\n",
    "\n",
    "#NX=NX1\n",
    "NX=NX2\n",
    "#NX=NX3\n",
    "#NX=NX4\n",
    "\n",
    "print(X.shape, NX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X[:]=scaler.fit_transform(X[:])\n",
    "NX[:]=scaler.fit_transform(NX[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(590,10, 10)\n",
    "NX = NX.reshape(560,10, 10)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150, 1)\n"
     ]
    }
   ],
   "source": [
    "label_X= np.zeros((590,1))\n",
    "label_NX=np.ones((560,1))\n",
    "label=np.r_[label_X,label_NX]\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "data=np.r_[X,NX]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.4, random_state=115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 2) (460, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils as np_utils\n",
    "#one-hot encoding\n",
    "y_train      = np_utils.to_categorical(y_train)\n",
    "y_test       = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 10, 10, 1) (460, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2],1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import  BatchNormalization,Dense, Conv2D, Convolution2D, MaxPooling2D, Dropout, Flatten, TimeDistributed, InputLayer, LSTM\n",
    "from keras.layers import Input, Reshape, Activation, add, Add\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 50)        250       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 10, 10, 50)        10050     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 5, 5, 50)          10050     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 5, 5, 50)          10050     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1250)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                62550     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 93,052\n",
      "Trainable params: 93,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def basic_cnn():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]), filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # prior layer should be flattend to be connected to dense layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    \n",
    "    # final layer with 10 neurons to classify the instances\n",
    "    model.add(Dense(50, activation = 'relu'))\n",
    "    \n",
    "    # final layer with 10 neurons to classify the instances\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = basic_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 690 samples, validate on 460 samples\n",
      "Epoch 1/300\n",
      "690/690 [==============================] - 0s 410us/step - loss: 0.6902 - accuracy: 0.5246 - val_loss: 0.6979 - val_accuracy: 0.4783\n",
      "Epoch 2/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 0.6727 - accuracy: 0.5522 - val_loss: 0.6933 - val_accuracy: 0.4783\n",
      "Epoch 3/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 0.6405 - accuracy: 0.6232 - val_loss: 0.6445 - val_accuracy: 0.6326\n",
      "Epoch 4/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 0.6033 - accuracy: 0.6623 - val_loss: 0.5872 - val_accuracy: 0.6826\n",
      "Epoch 5/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 0.4592 - accuracy: 0.8058 - val_loss: 0.3703 - val_accuracy: 0.8630\n",
      "Epoch 6/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.3099 - accuracy: 0.8812 - val_loss: 0.2318 - val_accuracy: 0.9043\n",
      "Epoch 7/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 0.2298 - accuracy: 0.9217 - val_loss: 0.1634 - val_accuracy: 0.9457\n",
      "Epoch 8/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 0.1711 - accuracy: 0.9449 - val_loss: 0.1318 - val_accuracy: 0.9457\n",
      "Epoch 9/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 0.1421 - accuracy: 0.9435 - val_loss: 0.1329 - val_accuracy: 0.9543\n",
      "Epoch 10/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 0.1156 - accuracy: 0.9623 - val_loss: 0.1122 - val_accuracy: 0.9587\n",
      "Epoch 11/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 0.1022 - accuracy: 0.9652 - val_loss: 0.1194 - val_accuracy: 0.9609\n",
      "Epoch 12/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.1437 - accuracy: 0.9406 - val_loss: 0.1145 - val_accuracy: 0.9630\n",
      "Epoch 13/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 0.1060 - accuracy: 0.9652 - val_loss: 0.1118 - val_accuracy: 0.9630\n",
      "Epoch 14/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 0.0919 - accuracy: 0.9739 - val_loss: 0.0879 - val_accuracy: 0.9674\n",
      "Epoch 15/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 0.0680 - accuracy: 0.9725 - val_loss: 0.0885 - val_accuracy: 0.9674\n",
      "Epoch 16/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 0.0623 - accuracy: 0.9783 - val_loss: 0.0863 - val_accuracy: 0.9652\n",
      "Epoch 17/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 0.0553 - accuracy: 0.9797 - val_loss: 0.0877 - val_accuracy: 0.9630\n",
      "Epoch 18/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0458 - accuracy: 0.9826 - val_loss: 0.1088 - val_accuracy: 0.9500\n",
      "Epoch 19/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 0.0437 - accuracy: 0.9841 - val_loss: 0.0768 - val_accuracy: 0.9739\n",
      "Epoch 20/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 0.0782 - val_accuracy: 0.9674\n",
      "Epoch 21/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 0.0257 - accuracy: 0.9899 - val_loss: 0.0778 - val_accuracy: 0.9717\n",
      "Epoch 22/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.0853 - val_accuracy: 0.9717\n",
      "Epoch 23/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0781 - val_accuracy: 0.9717\n",
      "Epoch 24/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0785 - val_accuracy: 0.9696\n",
      "Epoch 25/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 0.0181 - accuracy: 0.9913 - val_loss: 0.0869 - val_accuracy: 0.9761\n",
      "Epoch 26/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.0941 - val_accuracy: 0.9630\n",
      "Epoch 27/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0200 - accuracy: 0.9913 - val_loss: 0.0954 - val_accuracy: 0.9630\n",
      "Epoch 28/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 0.0919 - val_accuracy: 0.9696\n",
      "Epoch 29/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 0.0217 - accuracy: 0.9913 - val_loss: 0.1040 - val_accuracy: 0.9652\n",
      "Epoch 30/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.1248 - val_accuracy: 0.9543\n",
      "Epoch 31/300\n",
      "690/690 [==============================] - 0s 165us/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.0899 - val_accuracy: 0.9717\n",
      "Epoch 32/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0931 - val_accuracy: 0.9739\n",
      "Epoch 33/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.1038 - val_accuracy: 0.9761\n",
      "Epoch 34/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9696\n",
      "Epoch 35/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9674\n",
      "Epoch 36/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1040 - val_accuracy: 0.9739\n",
      "Epoch 37/300\n",
      "690/690 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 146us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9652\n",
      "Epoch 38/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9739\n",
      "Epoch 39/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9717\n",
      "Epoch 40/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9761\n",
      "Epoch 41/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9761\n",
      "Epoch 42/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9761\n",
      "Epoch 43/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9739\n",
      "Epoch 44/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9761\n",
      "Epoch 45/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9761\n",
      "Epoch 46/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9761\n",
      "Epoch 47/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 8.9222e-04 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9761\n",
      "Epoch 48/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 8.7761e-04 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9761\n",
      "Epoch 49/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 8.1954e-04 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9761\n",
      "Epoch 50/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 7.6789e-04 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9739\n",
      "Epoch 51/300\n",
      "690/690 [==============================] - 0s 156us/step - loss: 7.1274e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9761\n",
      "Epoch 52/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 7.2267e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9761\n",
      "Epoch 53/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 6.2249e-04 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9761\n",
      "Epoch 54/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 6.2952e-04 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9761\n",
      "Epoch 55/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.7925e-04 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9761\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 142us/step - loss: 5.6956e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9739\n",
      "Epoch 57/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.3556e-04 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9761\n",
      "Epoch 58/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.0706e-04 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9761\n",
      "Epoch 59/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.3843e-04 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9761\n",
      "Epoch 60/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 4.3993e-04 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9739\n",
      "Epoch 61/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 4.8818e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9761\n",
      "Epoch 62/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 4.1996e-04 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9761\n",
      "Epoch 63/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 4.0627e-04 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9761\n",
      "Epoch 64/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 3.8643e-04 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9761\n",
      "Epoch 65/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 3.6693e-04 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9761\n",
      "Epoch 66/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 3.5612e-04 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9761\n",
      "Epoch 67/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 3.4465e-04 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9761\n",
      "Epoch 68/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 3.2741e-04 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9761\n",
      "Epoch 69/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 3.2062e-04 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9761\n",
      "Epoch 70/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 3.0685e-04 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9761\n",
      "Epoch 71/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 2.9287e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9761\n",
      "Epoch 72/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.8973e-04 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9761\n",
      "Epoch 73/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 2.8002e-04 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9761\n",
      "Epoch 74/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 2.6518e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9761\n",
      "Epoch 75/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 2.5724e-04 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9761\n",
      "Epoch 76/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 2.5359e-04 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9739\n",
      "Epoch 77/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 2.3819e-04 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9761\n",
      "Epoch 78/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 2.3459e-04 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9739\n",
      "Epoch 79/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 2.1752e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9761\n",
      "Epoch 80/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.1220e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9739\n",
      "Epoch 81/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 2.0508e-04 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9739\n",
      "Epoch 82/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.9867e-04 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9739\n",
      "Epoch 83/300\n",
      "690/690 [==============================] - 0s 158us/step - loss: 1.9144e-04 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9739\n",
      "Epoch 84/300\n",
      "690/690 [==============================] - 0s 165us/step - loss: 2.0803e-04 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9761\n",
      "Epoch 85/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.8327e-04 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9739\n",
      "Epoch 86/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.7569e-04 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9739\n",
      "Epoch 87/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.7080e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9739\n",
      "Epoch 88/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.6297e-04 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9739\n",
      "Epoch 89/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 1.5864e-04 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9739\n",
      "Epoch 90/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.5440e-04 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9739\n",
      "Epoch 91/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.5409e-04 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9739\n",
      "Epoch 92/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 1.4352e-04 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9739\n",
      "Epoch 93/300\n",
      "690/690 [==============================] - ETA: 0s - loss: 1.3304e-04 - accuracy: 1.00 - 0s 136us/step - loss: 1.4341e-04 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9739\n",
      "Epoch 94/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.4080e-04 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9739\n",
      "Epoch 95/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.3331e-04 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9739\n",
      "Epoch 96/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.3126e-04 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9739\n",
      "Epoch 97/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 1.2560e-04 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9739\n",
      "Epoch 98/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 1.2332e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9739\n",
      "Epoch 99/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 1.1860e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9739\n",
      "Epoch 100/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 1.1534e-04 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9739\n",
      "Epoch 101/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.1239e-04 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9739\n",
      "Epoch 102/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 1.0887e-04 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9739\n",
      "Epoch 103/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.0594e-04 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9739\n",
      "Epoch 104/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.0356e-04 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9739\n",
      "Epoch 105/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 1.0287e-04 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9739\n",
      "Epoch 106/300\n",
      "690/690 [==============================] - 0s 158us/step - loss: 1.0072e-04 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9739\n",
      "Epoch 107/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 9.7182e-05 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9739\n",
      "Epoch 108/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 9.3903e-05 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 0.9739\n",
      "Epoch 109/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 9.2425e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9739\n",
      "Epoch 110/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 140us/step - loss: 8.9201e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9739\n",
      "Epoch 111/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 8.7865e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9739\n",
      "Epoch 112/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 8.6784e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9739\n",
      "Epoch 113/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 9.2399e-05 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9739\n",
      "Epoch 114/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 8.7336e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9739\n",
      "Epoch 115/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 8.0618e-05 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9739\n",
      "Epoch 116/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 8.0160e-05 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9739\n",
      "Epoch 117/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 7.5418e-05 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9739\n",
      "Epoch 118/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 7.4548e-05 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9739\n",
      "Epoch 119/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 7.3237e-05 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9739\n",
      "Epoch 120/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 7.0438e-05 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9739\n",
      "Epoch 121/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 6.9785e-05 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9739\n",
      "Epoch 122/300\n",
      "690/690 [==============================] - 0s 156us/step - loss: 6.9445e-05 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9739\n",
      "Epoch 123/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 6.6448e-05 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9739\n",
      "Epoch 124/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 6.4333e-05 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9739\n",
      "Epoch 125/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 6.3580e-05 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9739\n",
      "Epoch 126/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 6.3510e-05 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9739\n",
      "Epoch 127/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 6.0701e-05 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9739\n",
      "Epoch 128/300\n",
      "690/690 [==============================] - 0s 155us/step - loss: 6.0233e-05 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9739\n",
      "Epoch 129/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 5.9715e-05 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9739\n",
      "Epoch 130/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 5.6561e-05 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9739\n",
      "Epoch 131/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 5.4990e-05 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9739\n",
      "Epoch 132/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.4999e-05 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9739\n",
      "Epoch 133/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 5.2584e-05 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9739\n",
      "Epoch 134/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 5.1530e-05 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9739\n",
      "Epoch 135/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 5.0475e-05 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9739\n",
      "Epoch 136/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 5.0499e-05 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9739\n",
      "Epoch 137/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 5.0075e-05 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9739\n",
      "Epoch 138/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 4.8704e-05 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9717\n",
      "Epoch 139/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 4.7363e-05 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9739\n",
      "Epoch 140/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 4.6278e-05 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9739\n",
      "Epoch 141/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 4.5435e-05 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9739\n",
      "Epoch 142/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 4.5246e-05 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9739\n",
      "Epoch 143/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 4.3614e-05 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9739\n",
      "Epoch 144/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 4.2326e-05 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9739\n",
      "Epoch 145/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 4.2170e-05 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9717\n",
      "Epoch 146/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 4.0842e-05 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9739\n",
      "Epoch 147/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 3.9646e-05 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9739\n",
      "Epoch 148/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 3.9368e-05 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9739\n",
      "Epoch 149/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 3.8890e-05 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9739\n",
      "Epoch 150/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 3.7722e-05 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9739\n",
      "Epoch 151/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 3.7448e-05 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9739\n",
      "Epoch 152/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 3.7216e-05 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9739\n",
      "Epoch 153/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 3.5739e-05 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9717\n",
      "Epoch 154/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 3.5545e-05 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9717\n",
      "Epoch 155/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.4218e-05 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9739\n",
      "Epoch 156/300\n",
      "690/690 [==============================] - 0s 212us/step - loss: 3.4345e-05 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9739\n",
      "Epoch 157/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 3.3582e-05 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9717\n",
      "Epoch 158/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 3.2939e-05 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9717\n",
      "Epoch 159/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 3.3554e-05 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9739\n",
      "Epoch 160/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 3.1603e-05 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9717\n",
      "Epoch 161/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 3.1649e-05 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9717\n",
      "Epoch 162/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 3.0917e-05 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9739\n",
      "Epoch 163/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 3.0500e-05 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9717\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 143us/step - loss: 2.9392e-05 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9739\n",
      "Epoch 165/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 2.9041e-05 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9739\n",
      "Epoch 166/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 2.8397e-05 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9717\n",
      "Epoch 167/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 2.7950e-05 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9717\n",
      "Epoch 168/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 2.7813e-05 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9739\n",
      "Epoch 169/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 2.7092e-05 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9717\n",
      "Epoch 170/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 2.6960e-05 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9717\n",
      "Epoch 171/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 2.6639e-05 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9739\n",
      "Epoch 172/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 2.5810e-05 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9717\n",
      "Epoch 173/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 2.5432e-05 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9717\n",
      "Epoch 174/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 2.5454e-05 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9739\n",
      "Epoch 175/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 2.4849e-05 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9717\n",
      "Epoch 176/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 2.4536e-05 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9739\n",
      "Epoch 177/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 2.3755e-05 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9717\n",
      "Epoch 178/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 2.3466e-05 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9717\n",
      "Epoch 179/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 2.2906e-05 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9717\n",
      "Epoch 180/300\n",
      "690/690 [==============================] - 0s 233us/step - loss: 2.2925e-05 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9717\n",
      "Epoch 181/300\n",
      "690/690 [==============================] - 0s 264us/step - loss: 2.2335e-05 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9739\n",
      "Epoch 182/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 2.1876e-05 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9739\n",
      "Epoch 183/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 2.1645e-05 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9717\n",
      "Epoch 184/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 2.1654e-05 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9739\n",
      "Epoch 185/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 2.1206e-05 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9739\n",
      "Epoch 186/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.0386e-05 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9717\n",
      "Epoch 187/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 2.0298e-05 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9717\n",
      "Epoch 188/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.9906e-05 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9717\n",
      "Epoch 189/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 2.0204e-05 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9739\n",
      "Epoch 190/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.9233e-05 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9717\n",
      "Epoch 191/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 1.9353e-05 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9717\n",
      "Epoch 192/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.8914e-05 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9739\n",
      "Epoch 193/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.8771e-05 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9739\n",
      "Epoch 194/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.8435e-05 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9739\n",
      "Epoch 195/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 1.7927e-05 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9717\n",
      "Epoch 196/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.7659e-05 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9717\n",
      "Epoch 197/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.7354e-05 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9717\n",
      "Epoch 198/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.7159e-05 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9717\n",
      "Epoch 199/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.6953e-05 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9739\n",
      "Epoch 200/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.6710e-05 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9717\n",
      "Epoch 201/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.6446e-05 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9717\n",
      "Epoch 202/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.6493e-05 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9717\n",
      "Epoch 203/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.5896e-05 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9717\n",
      "Epoch 204/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.5668e-05 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9717\n",
      "Epoch 205/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.5853e-05 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9717\n",
      "Epoch 206/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.5792e-05 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9739\n",
      "Epoch 207/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.5362e-05 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9739\n",
      "Epoch 208/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.4627e-05 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9717\n",
      "Epoch 209/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.5031e-05 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9717\n",
      "Epoch 210/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.5176e-05 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9739\n",
      "Epoch 211/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.4447e-05 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9717\n",
      "Epoch 212/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.4034e-05 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9717\n",
      "Epoch 213/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.3881e-05 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9717\n",
      "Epoch 214/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.3616e-05 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9717\n",
      "Epoch 215/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.3670e-05 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9717\n",
      "Epoch 216/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.3337e-05 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9717\n",
      "Epoch 217/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.3102e-05 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9717\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 142us/step - loss: 1.2762e-05 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9739\n",
      "Epoch 219/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 1.2988e-05 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9739\n",
      "Epoch 220/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.2447e-05 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9717\n",
      "Epoch 221/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 1.2404e-05 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9717\n",
      "Epoch 222/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 1.2195e-05 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9717\n",
      "Epoch 223/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 1.1994e-05 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9739\n",
      "Epoch 224/300\n",
      "690/690 [==============================] - 0s 177us/step - loss: 1.2052e-05 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9739\n",
      "Epoch 225/300\n",
      "690/690 [==============================] - 0s 308us/step - loss: 1.1731e-05 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9717\n",
      "Epoch 226/300\n",
      "690/690 [==============================] - 0s 223us/step - loss: 1.1726e-05 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9717\n",
      "Epoch 227/300\n",
      "690/690 [==============================] - 0s 210us/step - loss: 1.1259e-05 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9717\n",
      "Epoch 228/300\n",
      "690/690 [==============================] - 0s 184us/step - loss: 1.1272e-05 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9739\n",
      "Epoch 229/300\n",
      "690/690 [==============================] - 0s 156us/step - loss: 1.1088e-05 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9717\n",
      "Epoch 230/300\n",
      "690/690 [==============================] - 0s 179us/step - loss: 1.1007e-05 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9717\n",
      "Epoch 231/300\n",
      "690/690 [==============================] - 0s 189us/step - loss: 1.0799e-05 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9717\n",
      "Epoch 232/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 1.0845e-05 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9717\n",
      "Epoch 233/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.0559e-05 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9717\n",
      "Epoch 234/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.0356e-05 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9717\n",
      "Epoch 235/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.0227e-05 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9717\n",
      "Epoch 236/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.0129e-05 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9717\n",
      "Epoch 237/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.0193e-05 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9717\n",
      "Epoch 238/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 9.9344e-06 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9739\n",
      "Epoch 239/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 9.6726e-06 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9717\n",
      "Epoch 240/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 9.6284e-06 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9717\n",
      "Epoch 241/300\n",
      "690/690 [==============================] - 0s 205us/step - loss: 9.4308e-06 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9717\n",
      "Epoch 242/300\n",
      "690/690 [==============================] - 0s 200us/step - loss: 9.3392e-06 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9717\n",
      "Epoch 243/300\n",
      "690/690 [==============================] - 0s 193us/step - loss: 9.2756e-06 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9717\n",
      "Epoch 244/300\n",
      "690/690 [==============================] - 0s 186us/step - loss: 9.4461e-06 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9717\n",
      "Epoch 245/300\n",
      "690/690 [==============================] - 0s 169us/step - loss: 9.0381e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9739\n",
      "Epoch 246/300\n",
      "690/690 [==============================] - 0s 156us/step - loss: 8.9136e-06 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9717\n",
      "Epoch 247/300\n",
      "690/690 [==============================] - 0s 173us/step - loss: 8.7632e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9717\n",
      "Epoch 248/300\n",
      "690/690 [==============================] - 0s 185us/step - loss: 8.6421e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9717\n",
      "Epoch 249/300\n",
      "690/690 [==============================] - 0s 267us/step - loss: 8.5110e-06 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9717\n",
      "Epoch 250/300\n",
      "690/690 [==============================] - 0s 191us/step - loss: 8.4593e-06 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9717\n",
      "Epoch 251/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 8.3114e-06 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9717\n",
      "Epoch 252/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 8.2124e-06 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9717\n",
      "Epoch 253/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 8.1412e-06 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9717\n",
      "Epoch 254/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 8.0188e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9717\n",
      "Epoch 255/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 7.9406e-06 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9717\n",
      "Epoch 256/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 7.8697e-06 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9717\n",
      "Epoch 257/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 8.1932e-06 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9717\n",
      "Epoch 258/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 7.6424e-06 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9717\n",
      "Epoch 259/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 7.5719e-06 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9717\n",
      "Epoch 260/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 7.7349e-06 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9717\n",
      "Epoch 261/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 7.4248e-06 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9717\n",
      "Epoch 262/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 7.4006e-06 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9717\n",
      "Epoch 263/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 7.2719e-06 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9717\n",
      "Epoch 264/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 7.0882e-06 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9717\n",
      "Epoch 265/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 7.0027e-06 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9717\n",
      "Epoch 266/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 7.1660e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9717\n",
      "Epoch 267/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 6.9266e-06 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9717\n",
      "Epoch 268/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 6.8251e-06 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9717\n",
      "Epoch 269/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 6.6738e-06 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9717\n",
      "Epoch 270/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 6.6080e-06 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9717\n",
      "Epoch 271/300\n",
      "690/690 [==============================] - 0s 188us/step - loss: 6.5389e-06 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9717\n",
      "Epoch 272/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 164us/step - loss: 6.5520e-06 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9717\n",
      "Epoch 273/300\n",
      "690/690 [==============================] - 0s 144us/step - loss: 6.3885e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9717\n",
      "Epoch 274/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 6.3757e-06 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9717\n",
      "Epoch 275/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 6.1947e-06 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9717\n",
      "Epoch 276/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 6.2302e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9717\n",
      "Epoch 277/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 6.1254e-06 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9717\n",
      "Epoch 278/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 5.9684e-06 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9717\n",
      "Epoch 279/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.9760e-06 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9717\n",
      "Epoch 280/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 5.8724e-06 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9717\n",
      "Epoch 281/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 5.8321e-06 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9717\n",
      "Epoch 282/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 5.8724e-06 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9717\n",
      "Epoch 283/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 5.8561e-06 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9717\n",
      "Epoch 284/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 5.5682e-06 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9717\n",
      "Epoch 285/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 5.5084e-06 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9717\n",
      "Epoch 286/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.4428e-06 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9717\n",
      "Epoch 287/300\n",
      "690/690 [==============================] - 0s 185us/step - loss: 5.4473e-06 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9717\n",
      "Epoch 288/300\n",
      "690/690 [==============================] - 0s 148us/step - loss: 5.3205e-06 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9717\n",
      "Epoch 289/300\n",
      "690/690 [==============================] - 0s 152us/step - loss: 5.3776e-06 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9717\n",
      "Epoch 290/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 5.1789e-06 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9717\n",
      "Epoch 291/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 5.2457e-06 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9717\n",
      "Epoch 292/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 5.1208e-06 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9717\n",
      "Epoch 293/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 5.0847e-06 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9717\n",
      "Epoch 294/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 5.0635e-06 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9717\n",
      "Epoch 295/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 4.9640e-06 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9717\n",
      "Epoch 296/300\n",
      "690/690 [==============================] - 0s 156us/step - loss: 4.8757e-06 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9717\n",
      "Epoch 297/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 4.8115e-06 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9717\n",
      "Epoch 298/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 4.8127e-06 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9717\n",
      "Epoch 299/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 4.7296e-06 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9717\n",
      "Epoch 300/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 4.7859e-06 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9717\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, y_train, epochs=300, batch_size=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXzU1dX48c+ZJXtCQlglyKLIDkGEYlXQtiporQtWcd/5WavV+tS61aq1rT4urXstWq279cG9Um1dsVZEQEBW2UtYw5KNJJNZzu+POwkhJGQCGTJhzvv1yisz813mfDOQk3Pv/d4rqooxxhiTSDxtHYAxxhjTkCUnY4wxCceSkzHGmIRjyckYY0zCseRkjDEm4fjaOoCW8ng8mp6e3tZhGGNMu1JZWamq2m4KknaXnNLT09mxY0dbh2GMMe2KiFS1dQwt0W6yqDHGmORhyckYY0zCseRkjDEm4bS7PqfGBINBioqKqK6ubutQ2q20tDQKCgrw+/1tHYoxxsQ3OYnIeOAhwAs8par3NNh+A3BevVgGAp1VdVtL3qeoqIjs7Gx69+6NiLRC5MlFVdm6dStFRUX06dOnrcMxxpj4NeuJiBd4DJgADALOEZFB9fdR1ftUtVBVC4GbgU9bmpgAqquryc/Pt8S0l0SE/Px8qzyNSWIi8rSIbBaRBU1sFxF5WESWi8h8ETk8nvHEs89pNLBcVVeqag3wCnDqHvY/B3h5b9/MEtO+sZ+fMUnvr8D4PWyfAPSLfk0G/hTPYOLZrNcDWFvveRHwncZ2FJEM3A/l6rhFEwzChg1QUACethsHMn06fPABDBkCGRkwc2abhbKbLVs60alTW0dhjGnK0UfDCSfE59yqOl1Eeu9hl1OB59StszRDRHJFpLuqbohHPPFMTo39Kd7U4lGnAJ831aQnIpNxmZqUlJS9i6a8HDZvdo8PPnjvztGEkpISXnrpJa666qq61yZOhKFD4Y47du731lvw4x+7PFmfiNL4j2t3qoorcuJR6VhmMiaR3XjjPiUnn4jMqvd8iqpOacHxjRUcPYB2l5yKgJ71nhcA65vYdxJ7aNKL/gCnAGRmZu7V6oiR3Cy0Uw7ezZuhSxdIS9ub0zSqqKiUm28+lLQ0uPRSWLQIXn8dPvoIbrghTGamlyuvhD//GUaMgA8/dNuqqmDSJPD5Yk80d9xxJ1lZWfziF79otfhrLV68hIEDB7b6eY0xCSGkqkfsw/EtKTj2WTzbt74C+olIHxFJwSWgtxvuJCIdgHHAW3GMhXC4gkB6mXtSU9Mq56yuhiuugCOPTKWs7AQuv7yKoUNnMnGie5+SEujf/wamTXOJqXPnV6iqOpz/+78pTJwI558Phx7amy1btrB69WoGDhzIFVdcweDBgznhhBOoqtrzbCNz585lzJgxDBs2jNNPP53t27cD8PDDDzNo0CCGDRvGpEmTAPj0008pLCyksLCQESNGUF5e3io/A2NM0mhJwbHP4lY5qWpIRK4G3scNJX9aVReKyJXR7U9Edz0d+KeqtsqEecuWXUdFxdxGtkSIBHfgqQaWpoMv9kvPyiqkX78H656rwq23wj//CXPmwJgxHVi16vdUVNzCihWjqaoCr/ddunQ5kaysP3DZZdCvX5gFCyYRDp/KqFGjmDhxIvn5+Q1iX8bLL7/Mk08+yVlnncVrr73G+eef32RcF154IY888gjjxo3j17/+NXfeeScPPvgg99xzD6tWrSI1NZWSkhIA7r//fh577DGOOuooKioqSGvFytEYkxTeBq4WkVdw4wdK49XfBHGeIUJVp6nqYap6iKr+LvraE/USE6r6V1WdFM84HA/UjkjTfatEP/oI7r7bVUZPPgkvvbSJ/PyXmDcP1qyBF174kjFjnuDll32sXu0KteOPf4JRo4YzZswY1q5dy7Jly3Y7b58+fSgsLARg5MiRrF69uskYSktLKSkpYdy4cQBcdNFFTJ8+HYBhw4Zx3nnn8cILL+CLJuGjjjqK66+/nocffpiSkpK6140xBkBEXga+APqLSJGIXCYiV9YWFMA0YCWwHHgSuKqJU7WKA+43VP0Kp6HKHd+SsbgMevSA7t336vyBAPz2t9CtGyxY4LquanNI377ue48eVeTmKuPGudF4CxbM4PHHX+aLL74gIyODY489ttF7ilJTU+see73eZpv1mvLuu+8yffp03n77be666y4WLlzITTfdxMknn8y0adMYM2YMH3zwAQMGDNir8xtjDjyqek4z2xX46X4KJ7nm1vP6MlEBbThcLkZr17oh4J98AjffvHNMRXZ2dpN9OMOGQWbmJvLy8sjIyGDJkiXMmDFjL69gpw4dOpCXl8dnn30GwPPPP8+4ceOIRCKsXbuW4447jnvvvZeSkhIqKipYsWIFQ4cO5cYbb+SII45gyZIl+xyDMcbEywFXOe2Jx5OB+oBQoMUDsT/6CCZPhuJieO89OPHEndvy8/M56qijGDJkCBMmTODkk0/e5djx48fzxBNPMGzYMPr378+YMWP2+VoAnn32Wa688koqKyvp27cvzzzzDOFwmPPPP5/S0lJUlZ///Ofk5uZy22238fHHH+P1ehk0aBATJkxolRiMMSYeRPex/2V/y8zM1IaLDS5evDimIdDh8A5YtBhJzcBz2KBm9995flcxHXwwvPgifPe7je83fc10Du5wML1zeze6fea6maT70hnadehu21ZtX8UbS94AYECnAfTr2I+/f/t3tMFIzYOyD2Jsr7FMXTSVUCRU93peWh4/POyHvLrwVQLhANkp2Zwx8Az+b9H/URmsjOk6N23aRNeuXQHwiIfTB5zO1xu/ZljXYSwqXkT//P70y+9Xt/+HKz+kU0YnhncbHtP5jTFtR0QqVTWzreOIVVIlp0gkSGTJPDyk4Bk0rNn9w2E38OHTT+Hzz91gh86d4Q9f/IHxh45nUOedCW5L5RYK/lDAGQPP4KWJL+1yHlXl/v/cz00f3kRBTgErf7aS91e8T0VNBZ0zOrOoeBF/nPFHVmxfUXdMqjeVQDjQaFxNbWv4+p7OEYva42u/Z6VkccbAM/CIh9LqUt5Y8gYp3hTOGnwWPs+BVYSf1v80VmxfwTebv9lt27hebhDKp2s+bfTYwZ0H8/MxP+dfK//FqwtfpU9uH248+ka+LPqSj1Z9xC+P+iXfbP6Gd5a+w/GHHM8L818gJzWHW4+5lY0VG3l23rNcf+T1VNRU8OdZf+Zn3/kZivLIl49w2oDTeHPJm1x++OV1fyiUVJfwu+m/o6S6hAuGX8A/lv2D4spiLh1xKd/t+V0CoQD3/ec+jiw4krG9xvLAFw+wdOtSAE7tfyqnDTgNcP9Op8yeQro/nQuGXbDblFZTF03l3WXvMrTLUK79zrW8v+J95m+az/8c+T/4vbvPZj9z3UyenP0kHdM7cuvYW8lJzWFR8SIe/vJh0nxp3HLMLXTJ7MKakjU8/tXjXD36anp26LnbeWqVBcq49/N7OX3A6Yw8aOQu2wKhAPf/536+U/AdftD3B02eI5lZcoqzfUlOqkro29l4a7x4ho5odv+PP4bvfc89vuoqeOwxKK0uJfd/cwG4uPBi5m+ajyB0SOvAR6s+4pC8Q1j+s+W7nOeGf97A/V/cz/Cuw5m3aR6vn/U6V027ikAogNfjZUvlFgDePfddvtvzu9zz73uYs2EOj5/8OF0yu+xyrr/M+QuvLX6NRyY8wiEdD6l7/c0lb/LYV49x7w/uZUT3EXyw8gPu/vfd3HnsnRx98NHNXivA0qVL6d+/PwBFZUX8dNpPObLgSGaum8nI7iP5euPXdb/UAE457BTWla9jzoY5MZ2/vdhRs4OtVVsB6JHdA6/HW7ctEAqwaccmALpmdiXVl7rLsRGNUFRWRN+8vqzavoq89Dy2VW2jV4deFJUVEdYwPXN6smnHJmrC7n677JRsqkJV5KfnU1FTwY7gDjpldKImXENZoIyO6R1RVbZXb697n+yU7LrktK5sHVurtpLuS6e8phyPeMhOyaYyWMmQLkPYVrWNNaVr8IiHXh16sapkFQU5BVSHqtlSuYXhXYfj9XipDFayZIvrixzcefAu1xaKhJi/aT4d0zuyrWobffP6snL7SgD65PYhLz1vt5/jgs0LSPOlsaNmB10yu9A9uztLt7h/P8FIkJzUHA7ucDArtq2gNFBKblouffP6Nvm5rC9fz8aKjaR6UxncZfAu27ZWbq27xuFdhx+wc0VePPxirvnONXt1rCWnONuX5AQQXP41vvIIMmJks/tedx08NGUr9z5cwuQf96VDB2HB5gUM/dPOZrkf9P0B5YFyvlz3Zd1rW3+5lQvfuJBDOx7Kg+MfpOAPBRze/XCmnjWV3g/2piZcU/fLD2Bgp4FcOuJSfvHd1p/1oSVa8nM8kAVCAe745A765ffjksJLdvlFF9EI9//nfgB+8d1f4JHdxxQ9O/dZpi6eSv/8/tx13F28u+xdnp//PD1zenLMwcfw8oKX6ZLZhRMPOZF/rfwXvznuNyzbuow/zPgDmf5Mfjzoxzw3/zn8Hj/nDj2X5+c/D8AFwy7gjcVvcNqA0/jbwr9RGigFIMWbws/H/JzD8g/j9o9vZ+KgiYzsPpJbPryFovIiPOLh7MFnM3PdTFZuX8mkIZM4d+i51IRruPOTO5m/eX5d7D/o8wOqQlV8vvbz3a5rRLcR3Db2Nl6Y/wKvL3mdAfkDGNp1KFMXTd2t+Rmge1Z37v7+3Xyz+Rse/vJhgpEgHdM78rvv/Y5NFZu45/N7qA5Vk5WSxXlDz+OF+S+wI9j07Y5+j58Lhl3Au8verfsDoZZHPJw16CxmrZ/F8u3LmzhD+zdx4EQuLrx4r4615BRn+5ycVs/Ht6UGGTly531P9ajCjBkwciT0PvJrNp18FBFvFaf2P5XnTn+Oz//7OSe9dBIAJ/c7mXfOeQeAlxe8TGl1KVdNu4rfHvdbfvXxrwCYdu40TnrpJH7/vd9z8zE3887Sd5j02iQ6Z3Rm045NVIeqWfGzFXv8i3F/seRkzIGrvSWnpBpKDoDP50bqhcONbr7+evju2GrOuPchNnznIjJ92dw+7nb+/u3fGfPUGGYUuWHgr531Gi+e8SIigohw7tBzOWeou03gN9N/Q1ZKFgdlH8QV71wBQP9OrrnslP6nsOiqRXxy8SecctgpjDpoVEIkJmOMSSQHVi92LHyu41ZDIaTBLAlLl8KDTxfBJWfwbvgr6JjOzw97gTuOPYOxvcZywvMncPe/78YjHk457JTdOoFz03I5rvdxfLz6Y64fcz0l1SU8MdtNhjGg084bXnvl9gLgudOf22XEnTHGGCcJk5NbckOD1UiD+eU+/XotXDEaUirI+vubVMw6lUmL3Lbv9fkeQ7sOZe7GuRyUfVCjo5MAPrroo7rHryx4hSdmP4FHPBySd8gu+2VlZVFRUbHb8U29bowxySTpmvXEH01Ood2HWD+07GeQVkq3af+hYpZbtLegYOf2UQeNAqBnTtPDXeurHXLcN6/vbqO6jDHGNC35klNtkgjtumzGV+u+YlHkTTJn30ZhdzcaLycHsrN37lOXnBrci3HjjTfy+OOP1z2/4447eOCBB8iWbDJ3ZLJlwRaGDh3KW2/FviqIqnLDDTcwZMgQhg4dyt/+9jcANmzYwNixYyksLGTIkCF89tlnhMNhLr744rp9//jHP8b8PsYYk4gOvGa9666DuY0tmeF4ImHYUYkn1Q8pO5v13ui7Enp6GTTnGAo8fwd+SEFoFRx7CRQWwoMPMqpH45XTpEmTuO666+pWwn311Vd57733SEtLY/Z1s8nPzYdKGDNmDD/60Y9iugfj9ddfZ+7cucybN48tW7YwatQoxo4dy0svvcSJJ57IrbfeSjgcprKykrlz57Ju3ToWLFgAULdMhjHGtFcHXnJqTu19KQ2G0L/VaSsp/z2SQVJBQWoxQN33WoM7D+aYg4/h+32+v8vrI0aMYPPmzaxfv57i4mLy8vI4+OCDCQaDPPL7R5g+fToej4d169axadMmunXr1myY//73vznnnHPwer107dqVcePG8dVXXzFq1CguvfRSgsEgp512GoWFhfTt25eVK1dyzTXXcPLJJ3PCPqzjbIwxieDAS04PNr1kBoCoonNmE87PwNd7EOvK1jH2mXGsLKmE6Wdy6NXj3Woal0PB6aPhL5/UHev3+pl+yfRGz3vmmWcydepUNm7cWLf67IsvvkhxcTGzZ8/G7/fTu3fvRpfKaExT95+NHTuW6dOn8+6773LBBRdwww03cOGFFzJv3jzef/99HnvsMV599VWefvrpmN7HGGMSUdL1OSGCeoCwG8K9sHghK0tWwNojYd5FDBiwcxBE/cEQzZk0aRKvvPIKU6dO5cwzzwTcgoBdunTB7/fz8ccfs2bNmpjPN3bsWP72t78RDocpLi5m+vTpjB49mjVr1tClSxeuuOIKLrvsMubMmcOWLVuIRCJMnDiRu+66izlzDqzphIwxyefAq5xi4fVAOAK4STMBePtJ/vD7XE47DWoXqe0Z26A8AAYPHkx5eTk9evSge3Qhw/POO49TTjmFI444gsLCwhYt7nf66afzxRdfMHy4myfs3nvvpVu3bjz77LPcd999+P1+srKyeO6551i3bh2XXHIJkYi7prvvvjv2wI0xJgEl3fRFAJGFc4l4wvgGjuTPs/7Mle9eCQ+so7r4IFJTXXfU88/DGWdAVlZrX0HisumLjDlwtbfpi5KyclKvBwmFdpnpuUtOLrWrpIvAhRe2YYDGGJPk4trnJCLjRWSpiCwXkZua2OdYEZkrIgtFpPEFclqb1wcRUA1RUl2CRFI4+KD0/fLWxhhjmhe3yklEvMBjwPFAEfCViLytqovq7ZMLPA6MV9X/ikiXxs/WPFWNeQ0X8XqjySnI9qrteAJ59Dr4wFz/JVbtrXnXGHNgi2flNBpYrqorVbUGeAU4tcE+5wKvq+p/AVR18968UVpaGlu3bo39F6zPh4RBNcz26u1EKnNbNPjhQKOqbN26lbQGcw0aY0xbiWefUw9gbb3nRcB3GuxzGOAXkU+AbOAhVX2u4YlEZDIwGSAlJWW3NyooKKCoqIji4uLdtjVGS7YipRVElnhYvWkdWplHaqdNLF68LabjD0RpaWkUtGTsvDHGxFE8k1Nj7WQNSxsfMBL4PpAOfCEiM1T1210OUp0CTAE3Wq/hSf1+P3369Ik5sKo/3ED6/9zPtoUvsiNcA9WdOeKIrgwc2DXmcxhjjImfeCanIqB+Y1kBsL6Rfbao6g5gh4hMB4YD3xJPuXkASOl2d59TdT+6Wl4yxpiEEc8+p6+AfiLSR0RSgEnA2w32eQs4RkR8IpKBa/ZbHMeYnA65AGhJKeXB7VCVR15e3N/VGGNMjOJWOalqSESuBt4HvMDTqrpQRK6Mbn9CVReLyHvAfCACPKWqC+IVUy1JzXAxBirZES6BaktOxhiTSOJ6E66qTgOmNXjtiQbP7wPui2ccDXmiS2WUByqIEIbqXEtOxhiTQJJv4lcAv7vhtiRQBoA3mEe63YNrjDEJIymTkyclmpxqygHI8uYR4/27xhhzwGpuVh8RyRORN0RkvojMFJEh8YolKZMTPtesV1pTAUBOSm5bRmOMMW2u3qw+E4BBwDkiMqjBbrcAc1V1GHAh8FC84knK5ORJcQMitgfd7OZ5adbhZIxJerHM6jMI+BBAVZcAvUUkLjfiJGVykmizXmmwEoCOGZacjDEHPJ+IzKr3NbnB9sZm9enRYJ95wBkAIjIa6IW7h7X1g43HSROd+P0AlIarAOicbc16xpgDXkhVj9jD9lhm9bkHeEhE5gLfAF8DoVaKbxdJmZzwucsuCQVAhS4dcto4IGOMaXPNzuqjqmXAJQDiloFYFf1qdUnZrFebnEpDAajOpWNecv4YjDGmnmZn9RGR3Og2gMuB6dGE1eqSunIqDkWgOpfcvV5FyhhjDgyxzOoDDASeE5EwsAi4LF7xJGdyivY5bQuHbV49Y4yJam5WH1X9Aui3P2JJzvasaOW0XSM2r54xxiSgpE5OZQShOpcOHdo4HmOMMbtI6uRU4amBqjwyMto4HmOMMbtIzuQU7XPa4a2B6lyb9NUYYxJMciYnr5eAF4LeEFTbjOTGGJNokjM5ibAtM/q4ypKTMcYkmuRMTsD2zOhMHdW51udkjDEJJmmT07bM6KVbs54xxiScpE1OO9KiD2qySEvb467GGGP2s7gmpxhWVTxWREpFZG7069fxjKe+kM9deorPZ6vgGmNMgonb9EX1VlU8Hjfb7Vci8raqLmqw62eq+sN4xdGUkM9lpFR/cs7gZIwxiSyelVMsqyq2mWA0OaWlWHIyxphEE8/kFMuqigBHisg8EfmHiAxu7EQiMrl29cZQqHXWtQpHm/VSLTkZY0zCiedv5lhWVZwD9FLVChE5CXiTRma8VdUpwBSAzMzMhufYK7V9TumplpyMMSbRxLNyimlVRVWtiD6eBvhFpFMcY6pT2+eUnuLdH29njDGmBeKZnGJZVbFbdKlfRGR0NJ6tcYypTm3llJZqyckYYxJN3Nq0YlxV8UzgJyISAqqASaraKs12zalLTik2jtwYYxJNXDtcYlhV8VHg0XjG0JSQN9rnlJK09yEbY0zCStrfzOHaPqc0q5yMMSbRJG1y2jlaz5KTMcYkmuRNTtFmvYy0/dLFZYwxpgWSNznVVU5tHIgxxpjdJG1yCnosORljTKJK2uRU4/EDkJ4WaeNIjDHGNJS0yalK/KBCRlq4rUMxxhjTQNImp2qPDyJeUlNr2joUY4wxDSRvchIfRHyWnIwxJgElbXIKiBciPtLSqts6FGOMMQ0kbXIKRiuntLRAW4dijDGmgaRNTrWVU2qqJSdjjAEQkfEislRElovITY1s7yAi70QXiF0oIpfEK5akTU5BEVAvPp8lJ2OMEREv8BgwARgEnCMigxrs9lNgkaoOB44FHoguidTqkjc5eQQiPrxe63MyxhhgNLBcVVeqag3wCnBqg30UyI6uw5cFbANC8QgmaZNTCCDis8rJGJMsfCIyq97X5AbbewBr6z0vir5W36PAQNyq5t8A16pqXGYyiOt6TolsZ+VkyckYkxRCqnrEHrY3tkRDw5mxTwTmAt8DDgH+JSKfqWpZK8VYJ2krp7AAER8i1qxnjDG4SqlnvecFuAqpvkuA19VZDqwCBsQjmKRNTiFRiHjxSVVbh2KMMYngK6CfiPSJDnKYBLzdYJ//At8HEJGuQH9gZTyCSdpmvVC0cvJqZVuHYowxbU5VQyJyNfA+4AWeVtWFInJldPsTwF3AX0XkG1wz4I2quiUe8cQ1OYnIeOAh3IU+par3NLHfKGAGcLaqTo1nTLVCRNyACCw5GWMMgKpOA6Y1eO2Jeo/XAyfsj1ji1qwX45j52v3+F5et95uwqFVOxhgTRyIyZG+PjWefUyxj5gGuAV4DNscxlt3UJicf1udkjDFx8oSIzBSRq0QktyUHxjM5NTtmXkR6AKcDT7CfhYiAevFGduzvtzbGmKSgqkcD5+FGAc4SkZdE5PhYjo1ncoplzPyDuA61Pa74JyKTa28cC4Va52bksESsWc8YY+JMVZcBvwJuBMYBD4vIEhE5Y0/HxXNARCxj5o8AXnEzYdAJOElEQqr6Zv2dVHUKMAUgMzOzYYLbK2HCLjlFLDkZY0w8iMgw3L1RJwP/Ak5R1TkichDwBfB6U8fGMznVjZkH1uHGzJ9bfwdV7VP7WET+Cvy9YWKKF1c5eSFkN+EaY0ycPAo8CdyiqnUd/Kq6XkR+tacD45acYhwz32bCEsYT8UDQpi8yxph4UNWxe9j2/J6Ojet9Ts2NmW/w+sXxjKWhCBE8EQ8atGXajTEmHkSkH3A37naitNrXVbVvc8cm7fRFYSJIxAMhS07GGBMnzwB/wi0EcRzwHLDHiqlW0ianSG2zniUnY4yJl3RV/RAQVV2jqnfgZjRvVtLOrReRUDQ5Bds6FGOMOVBVi4gHWBYdg7AO6BLLgTFVTiJyrYjkiPMXEZkjIvtlfqV4iRDGGxE0YAMijDEmTq4DMoCfASOB84GLYjkw1ma9S6OLSZ0AdMaNW290Etf2IiIRPCoQsMrJGGNaW3Te1LNUtUJVi1T1ElWdqKozYjk+1uRUO9vDScAzqjqPxmeAaDci4ionCVpyMsaY1had+WekRGdZaKlY+5xmi8g/gT7AzSKSDcRl3fj9RWv7nKxyMsaYePkaeEtE/g+om8hUVZucGaJWrMnpMqAQWKmqlSLSEde0127V9jlJjSUnY4yJk47AVnYdoafsYdqiWrEmpyOBuaq6Q0TOBw7HLSLYbqmE8EYEgq0zkawxxphdqepeFzGxJqc/AcNFZDjwS+AvuJupxu3tG7e1iITwRsBTE0ZV2ctmUWOMMU0QkWfYfTUKVPXS5o6NNTmFVFVF5FTgIVX9i4jENBwwYdUOiKgB1RAi/raOyBhjDjR/r/c4Dbd+X8PVKRoVa3IqF5GbgQuAY6JDBNvtb3NVRT2uWc8TgkgkgMfTbi/HGGMSkqq+Vv+5iLwMfBDLsbEOJT8bCODud9qIW9H2vpYEmUgi6gYa+iLgCYJbRd4YY0yc9QMOjmXHmConVd0oIi8Co0Tkh8BMVX1uHwJsU6GIGwThi4AEIRKx5GSMMa1NRMrZtc9pI25F3GbFlJxE5CxcpfQJ7ubbR0TkBlWd2rJQE0NtcvJSWznZFEbGGNPaVDV7b4+Ntc/pVmCUqm4GEJHOuHbDdpmcwhoGwKsePFY5GWNMXIjI6cBHqloafZ4LHBvLiuex9jl5ahNT1NYWHJtw6pr1cM161udkjDFxcXttYgJQ1RLg9lgOjLVyek9E3gdejj4/mwYr3LYntcnJb5WTMcbEU2NFTEx5J9YBETeIyETgKFyf0xRVfSP2+BLLzspJosnJ+pyMMSYOZonIH4DHcAMjrgFmx3JgzIsNRserv9bsju1AXeUk1qxnjDFxdA1wG/C36PN/Ar+K5cA9JqdGhgHWbQJUVXOaOX48bg4+L/CUqt7TYPupwF24Gc5DwHWq+u9YAt8XO0fr1TbrVcX7LY0xJumo6g7gpr05do+DGpwxL3oAACAASURBVFQ1W1VzGvnKjiExeXGl3ARgEHCOiAxqsNuHwHBVLQQuBZ7am4toqXDEjdbze7x4ghAO72jmCGOMOfCJyHgRWSoiy0Vkt6QiIjeIyNzo1wIRCUdXqWjqfP+KjtCrfZ4XHb/QrHiOuBsNLFfVlerazV4BTq2/Q3SFxNrKLJPGq7RWt7NZTxBLTsYYE1NBoar3qWphtKC4GfhUVbft4bSdoiP0ao/fDnSJJZ54JqcewNp6z4uir+1CRE4XkSXAu7jqaTciMllEZonIrFBo35e4qImeI0VqK6eKfT6nMca0c80WFA2cw84R3E2JiEjddEUi0psYi5B4JqfG1qBobOr0N1R1AHAarv9p94NUp6jqEap6hM8X8xiOJlXXRJOTx2fNesaYZOGr/SM/+jW5wfaYCgoAEckAxtP8ILlbgX+LyPMi8jzwKa7iaj7YWHbaS0VAz3rPC9jDVOmqOl1EDhGRTqq6JY5xEYguMOjzepGQVU7GmKQQUtUj9rA9poIi6hTg82aa9FDV90TkCGAyMBd4C4hpBFo8k9NXQD8R6QOsAyYB59bfQUQOBVZE14o6HEjBzT4RV4GgGxCR4vHiCQqRiFVOxpik15KCYhLNN+khIpcD10bPNRcYA3zBrsu2NypuzXqqGgKuBt4HFgOvqupCEblSRK6M7jYRWCAic3EdcWfXGyARN9XRyinF65KTVU7GGLOzoBCRFFwCervhTiLSAbcK+lsxnPNaYBSwRlWPA0YAxbEEE8/KCVWdRoNpjlT1iXqP/xf433jG0JhATb3kFBLrczLGJD1VDYlIbUHhBZ6uLSii22t/d58O/DN6D1NzqlW1WkQQkVRVXSIi/WOJJ67JKVEF6ionH54aGxBhjDHQfEERff5X4K8xnrIoep/Tm8C/RGQ7rbxM+wElEAwCkOL3IkG1Zj1jjIkDVT09+vAOEfkY6AC8F8uxSZmcSqvLAcj2ZESTk1VOxhgTT6r6aUv2b7drMu2L0uoyALK9mXhCSjhY3sYRGWOMqS8pk1N5IFo5+TMB0IA16xljTCJJzuRUE62cfBmAJSdjjEk0SZmcymrKoCaTtLQUALTa+pyMMSaRJGVyqqgpg0AO/jQv4JLTfrj31xhjTIySMzkFy3dJThKESKS6jaMyxhhTK0mTUxkEsknLcJdvy2YYY0xiScrkVBZwzXodo+s32rIZxhiTWJIyObnKaWdycs16lpyMMSZRJGVyqgy75JST5/qcrFnPGGMSS1Imp2otJ1Wy8WSkAeAJWHIyxphEknTJSVWpkTLSPTmQkwOAtxJCobI2jswYY0ytpEtO1aFqVEJk+XMgOxsAXxWEQqVtHJkxxphaSZecygKuQspK2ZmcvDsgFCppy7CMMcbUk7TJKTetXnKqsuRkjDGJJOnWcyqvcTOS52VkQ2oqpKTgr4RA2Jr1jDEmUcQ1OYnIeOAh3Hr0T6nqPQ22nwfcGH1aAfxEVefFM6aSKlc5dcxygyHIycFfXcUOq5yMMfEWicDmzVBcDF27QjAI8+fD9u1QUQHl5bBpE3i9sHYtbNsGq1eDxwN5eXDhhXDFFW19FftF3JKTiHiBx4DjgSLgKxF5W1UX1dttFTBOVbeLyARgCvCdeMUEsLnEDRnvlJPlXsjOxl8VsmY9Y0xsVCEQgNJSWLrUfU9PBxFYvhy+/hoqK6G62iWbzZuhc2e3b1ERhEJ7Pn9KCoTD0KOHO65/f3fukhKX3JJEPCun0cByVV0JICKvAKcCdclJVf9Tb/8ZQEEc4wFge1kNAHk5brkMcnLwVpXaaD1jko2qq1YqKnZWKKtXw47obDFFRe7xpk2waBH4fC6xbNjgEk9TOnaEDh0gLQ0yMlyC2bQJxoyBPn1c0unUyb3m98OQIa6KysyErCx3i4vI/vgJJLR4JqcewNp6z4vYc1V0GfCPxjaIyGRgMkBKSso+BVVa7v5q6dgheunZ2fgqxSonY9qjHTugqgpqamDmTJdkYGfi2b7dvVb7vf7j7dv3XMXkRAdNZWS4xKLqmtu6dXMJKDMTBg2C3FxXSYVC0LMn9O1ryaUVxDM5NfbpNLpokogch0tORze2XVWn4Jr8yMzM3KeFl8oq3D/G/Dy/eyEnB+8ateRkTFsJhWDVKlc1ZGbCt9/C4sUuuQQCrols7Vr3+OuvXYKorHTNZVu3Nn/+Dh1cMunY0fXbHHyw+177PCvLJZg+faB3b/dctW40r2kb8UxORUDPes8LgPUNdxKRYcBTwARVjeFf2r4prwwCkJO1s3LyVkasWc+Y1hAKwbp1LoFs2eKqmdJS98t/2za3bckS+O9/XWXi88G8eS7Z7EnHjq4JbOhQ9z0zE8aNc5VKTo4bMDB0KPTqtfOYzEz3vl5vfK/ZxEU8k9NXQD8R6QOsAyYB59bfQUQOBl4HLlDVb+MYS53qGlc5ZWdEK6fsbDwVQUKhKlQVsXLcGCcUcglmyxZXSaxcCbNmuYRyyCHw6afueXa2q2zKy13zWnl50+fMznYd/EOGuCa5ykq47DIYMcL145SVwaGHwuDBruJJTd3Zd2OSStySk6qGRORq4H3cUPKnVXWhiFwZ3f4E8GsgH3g8mhRCqnpEvGICqAq4yikrM3rpOTl4dgSBCOFwBT6flfLmALRhg0sqKSmwbBnMnesqmXDYJYTiYpeEiot3Pt6+fffz1P7xpurONW6ca2476qidHfkjRrjv6elw5JGQn+9GmuXnu2rGmBjE9T4nVZ0GTGvw2hP1Hl8OXB7PGBqqrZxyMutVTpU1EHbz61lyMu1CZeXOJLJ5886RZVVVrsJZvtxVHaWlsGaNS05N8fnciLJOndz3ww/f9Xnnzi4Z5ebCcce5e3PWrXP9NZ06xRZvdJJlY2KVdDNEVNe4yim7XuUE9acwivtodmN2FQi4X/7h8M7qZetWN0jggw+ge3fXVDZvnvv3Oneuq3aa0rkz9OvnklVODpx4Igwf7qqZYNB1+o8Y4Uadeb0uibWkOdvvd+c3Jo6SLzkFQ+CBzPSdAyIAfJU2v55pZcGgSyjFxS4RzJzp+mgKCmD9evc8EHAj05rSs6dLROnprsO/vBzOOceNLKutbDp1cufMjk7JZf0z5gCQdMkpEAxCKqR4dw4lh9o1neI+WNC0d6qu6ay01CWeb791j0tLXXNaUZG7i7+y0t3QWVW16/G5ua7/JT0djj7aVSFnneWSitfr+mU6d3bfO3aEAQPsnhmz3zQ35Vx0n2OBBwE/sEVVx8UjliRMTiFIBZ9n18rJWwnV1avbLjDTtrZudSPNUlPhww9d0lixwt3Fv3y5GxywZo0bAh0O7358RgYcdJAbxebzuRFm48e7mze7d3fVU58+UFi483hf0v33MwkslinnRCQXeBwYr6r/FZEu8Yon6f531IRCoILXE733IVo5pVSmUlW1qg0jM3Gh6hLP+vWualmxwg0OmD7djVYLBGDBAlf1NCY11U0306MHjBwJkya5Ic45OW4mgJEj3XO/P/aYLCmZxNTslHO424FeV9X/Aqjq5ngFk3T/SwKhIETqXXb37gBklXWiotqSU7ui6u6vSU93AwnWrXPNamvWwMKF7vV33ml8SHROjks4Pp8bHHDlla6Krqhw1U1ampvvzDr+zYHDJyKz6j2fEp19p1YsU84dBvhF5BMgG3hIVZ+LS7DxOGkiC4ZCeLTeX7kFbnRextYstlhySkzbtrl+mrIyN33Nu++6mzRnzoT33tt9fxE3Iq2kBI4/3t2D0727S2B9+7qkdNhh7j4dY5JHc/eRxjLlnA8YCXwfSAe+EJEZ8ZhEIemSU004iGi9y05Nha5dSSv2UV29ymaJaCvV1W6AwapVbmmB6dPdDZsrV7oqqL7OneG119yggTvvdM11nTq5pFNQ4Pp+0tPb5jqMab9imXKuCDcIYgewQ0SmA8MBS077qiYcwkOD/oGePUndXEE4XEEwuIWUlM5tE1wy2LTJVTuLF7smuXnzXIWzadOuM0QffrjrK+rWDS64wH3PyXFNbUce6UbB1a6hY4xpDc1OOQe8BTwqIj4gBdfs98d4BJN0ySkUDuJpeNk9e+Jb5Jpiq6tX4fd3YuPGZ+jc+cc2Y8TeKC2F2bNdwlm4EN5+2w1E8Hhcnw64vp78fDearVMnl3RGjnTzruXmuipoT+xeHmNaVSxTzqnqYhF5D5gPRHDDzRfEI56kS07BSKjR5OT94J+AS05ebw5Ll16GaoSDDtqvsyu1D6ou2fh88P777sbSDRtg40b3fX29lgCPB445xvX9gEtE48e7QQdW9RiTUJqbci76/D7gvnjHknTJKRQJ4pXdm/WkfAfeCqiqWoXf3xWAmprdVvhILtu2uSHSs2e7+ds+/9zddDpnjnteq2tX18/TrZubJqdvXxg1yq2b06WLu5nUGGNaIAmTU4j0RiongEP+mkbFbcsIpvcFoKZm4/4Or22Vl8Nnn8GLL7obUt96y03BUys9HQYOdHO1HX2029a/P3z/+1YFGWNaVdIlp7CG8HkaVE6HHgrAQa9Vs+bwL6m5sBA4gJNTUZFrfisudk1yX365c5RcJOL6glJT4dxzXRU0YIBLQocc4lYJNcaYOEuq5KQKYQ3ilQaXffjh8M9/wgkn4F+8jkDQNVnV1OxhmYFYVVbunPl5f6upcffyFBfDxx+7PqGvvoIXXti5j4i7Z6h/fzfH25gxcOyx7iZUY4xpI0mVnKqrAU8If8PKSQSOP57AwC6kLiumLOCSUqtUThMmuMrsL3/Z93PFShWeeAKuucbNcPDtt64iApesrr/ercuTl+dWJO3QYf/FZowxMUiq5FRZCXiDOyd9bSA8sDfZH24mcN+7lBwPge4b9u2m3FAIZsyIZsU4CQbd+8yaBX/8o6uMNm92VdNRR7kbWc86C374Q9dEl5vrKjljjElgyZecPCH83iYm6Rw8hJTXZ3LQ0xvJ/jfMeSRAKFSK35+7d2+4bJlLEuvWNb79llvcsOu//rVl5y0qcpOVvvii+9LoDCPdusEPfuDuEerVCy69tG2aE40xZh8lVXKqqgI8Qfzexi/bP/xo4GkAsr+Fwuuh5r2l+Asazn0YowXRe9M2bnTLJNSvWCIReOopF9Qzz+x5tJsqLFrkhnRPneomMwXXRPfTn7pklJcH55/vKiVjjGnnPPE8uYiMF5GlIrJcRG5qZPsAEflCRAIi8ot4xgI7K6eUJion//dOo3xYOrP+DCt+05MOC0FerDd4QBXuu8/14cTim2/c93B41/uCampcoikudjMmrFnT+PEbN7qq6uijXd/QRRe5ZbvvvBM+/dRtf+QRuOkm+H//zxKTMeaAEbfkVG/hqgnAIOAcERnUYLdtwM+A++MVR321fU5NVU7k5bH+1fOoOAyqTx9DKBM3vLrW+vXwy1/G3gy3oN6sHuvXuznkSkrgvPNg9OjG91OF3//eNcv16AGXXOIWuHvoIViyxCW5X/8axo511ZIxxhyA4tms1+zCVdGFqjaLyMlxjKOOa9YLkbKHxd6ys49gw4an8Kd0prKn4Fu6ZOfG2iRSVNT8m6m6QQq9e7vlutevh5/9zC1uN3u222fwYDf33Ny5bpXUF19089AtXOj6ji6+GCZOdFWTJ65FrjHGJJR4JqdYFq7ar+qa9XxNr1ratetFVFR8Q69eN7Oj7+ukzqk3nLx26Ya1axs/uL4FC9x+d9zhvj77DP7zn53b337bVT+9esFtt7kvcHPQXXgh/OIXlpCMMUlLVBuuJdVKJxb5MXCiql4efX4BMFpVr2lk3zuAClVttHlPRCYDkwFSUlJGBgKBXbYHg0GKioqobmbIdkUFbK1ZT3qKny5ZzS+LEdm+CU9ZNdqzB+LxuSUcKirchKdNzZpdWemmAaqNpUeP3Ufribgpk0Rcv1Eg4Jro0tNbttx3K0hLS6OgoAD/fn5fY8z+JSKVqtpuOqbjWTnFsnBVTKJLCU8ByMzM3C2bFhUVkZ2dTe/evfd4T9KGDSDBEHlZmRzSsW+z7xve0gHv6vWEenbGl9PNrUGUluaSyoABu4+wCwRcxZSb6+498vth6FD3ugveLQUOdSvw0rev27cNBjOoKlu3bqWoqIg+ffrs9/c3xpimxDM5xbJwVauorq5uNjFBdA5TUTwx3lTrSe8ArMf3bRF0DbpOK4/HDQOvTT71bYw2AQ4c6JYUr50CKCvLVVx9+uw+LVBqapvdiyQi5OfnU1xc3Cbvb4wxTYlbcopl4SoR6QbMAnKAiIhcBwxS1bKWvl8sszgEgyCpsc/4IOnpBHM8eCJevJs2ufuUOnd2Saimxj1fssQtCZGfD1u2uPWKUlPdfrUOPdRVWQk4M4MtSW+MSURxvQm3uYWrVHUjrrlvvwgGgTRFiPEXssdDsCAL1RCZ/oGur6mqamdyqqx0X4GAO7mqW7+ooT2MDjTGGLO7pBoOVrs0UUuqBY8njUikGvX7XZNeSorbsGKFu3k2NZWSkhIef/RRyMlxgxpa4KSTTqKkpKRFxxhjzIEuaZKTqit2kEjslRMuOUEE1Whm8/lcEsrNdU13fftS0qEDj7/1lutTaiAcDu/x/NOmTSM3dy/n7jPGmAPUAdfedN117p7WhlTdmARS+5Hi8ZMa45WrdmTwYOXhh6vxeFJc39Fhh+2yz0333suKNWsoHDWK448/npNPPpk777yT7t27M3fuXBYtWsRpp53G2rVrqa6u5tprr2Xy5MkA9O7dm1mzZlFRUcGECRM4+uij+c9//kOPHj146623SG9Qib3zzjv89re/paamhvz8fF588UW6du1KRUUF11xzDbNmzUJEuP3225k4cSLvvfcet9xyC+FwmE6dOvHhhx/uzY/VGGP2qwMuOTVll9u5WtCsJ+KKy3C4Ap8vp9F97rnnHhYsWMDcaFb85JNPmDlzJgsWLKgbov3000/TsWNHqqqqGDVqFBMnTiQ/P3+X8yxbtoyXX36ZJ598krPOOovXXnuN888/f5d9jj76aGbMmIGI8NRTT3HvvffywAMPcNddd9GhQwe+ic7nt337doqLi7niiiuYPn06ffr0Ydu2bTFftzHGtKUDLjk9+GDjr5eVwbffKhy0lO5Z3emR08RNtLvxUFlZTk1NGX5/Ph5PbMO+R48evcu9Qw8//DBvvPEGAGvXrmXZsmW7Jac+ffpQWOiWiB85ciSrV6/e7bxFRUWcffbZbNiwgZqamrr3+OCDD3jllVfq9svLy+Odd95h7Nixdft07Ngxxms2xpi2lTR9TrWDIaDlw6fT0g4GIBBoYl2mRmTWu6n2k08+4YMPPuCLL75g3rx5jBgxotHZLFLr3e/k9XoJhUK77XPNNddw9dVX88033/DnP/+57jyNLYq4TwslGmNMG0qa5NSxIwwZ6tr2WjIgAsDjScHv70IotI1wuGq37dnZ2ZSXlzd5fGlpKXl5eWRkZLBkyRJmzJjRsuAbnKtHdOqkZ599tu71E044gUcffbTu+fbt2znyyCP59NNPWbVqFYA16xlj2o2kSU4i4PdHk9NeVBMpKd0AD8Hg5t225efnc9RRRzFkyBBuuOGG3baPHz+eUCjEsGHDuO222xgzZkyL37/WHXfcwY9//GOOOeYYOnXqVPf6r371K7Zv386QIUMYPnw4H3/8MZ07d2bKlCmcccYZDB8+nLPPPnuv39cYY/anuE38Gi+ZmZm6Y8eOXV5bvHgxAwcObPbYUCTE3I1z6ZnTk65ZXVv83lVVqwiFSsjKGoZbrurAEOvPzxjTfrW3iV+TpnIC1wcDez9lj9/fCQgTCKxHNdKKkRljjKkvuZITe9fnVMvrzcLn60gwuImamk2tGZoxxph6kis57WMTpoiQnt4XjyeTUKi0laIyxhjTUFIlp1r7Orza58shEqlAdc9TEwFUVn5LdfWafXo/Y4zZH0RkvIgsFZHlInJTI9uPFZFSEZkb/fp1vGI54G7C3ZO6Pqe9bNar5fXmABsIhcrx+5ueF081TDhcRjjsJTX1YLvnyBiTsMSN8noMOB63WOxXIvK2qi5qsOtnqvrDeMeTVJVTXZ/TPiYJrzcT8FJTs55AYCPhcGWj+4XDFbWPCId3NLqPMcYkiNHAclVdqao1wCvAqW0VTHImp32snEQ8pKX1IRKppKamiKqq5UQiu8/mEAqVQ/S9wuFd10/MysrapxiMMaaFfCIyq97X5AbbewBr6z0vir7W0JEiMk9E/iEig+MWbLxOnIj2dSh5fX5/LiL9UQ1SXb2KQGANaWl9CIW2E4kE8PlyCYfL8HozUYVQaBspKd2tac8Y01ZCqnrEHrY39sup4SiyOUAvVa0QkZOAN4F+rRVgfQdccrruveuYu7GRNTOAsIapDFaS7kvH54n90gu7FfLg+N1nlPX5sgG4+ebbOOigLK64YhIQ5ve/n0J2djaXXHIq5557KyUlpdTUVPKb39zOGWecg0jT793U0hqNLX3R1DIZxhizF4qAnvWeFwDr6++gqmX1Hk8TkcdFpJOqbmntYA645LRH0b8B9rVZr6Fzz72Ma6/9CT/5yZX4/Xm8+eanvPbaA6SlpfLGG2/SoUMea9ZM53vfu4ATTxxJZmbTszE0trRGJBJpdOmLxpbJMMaYvfQV0E9E+gDrgEnAufV3EJFuwCZVVREZjesa2hqPYA645NRYhVOrLFDGt1u/pX9+f7JTs1vtPQ8//HC2bClj+/ZUiovX0LFjJ3r16k04nMItt9zO9OnT8Xhgw4ZiNm78L717N71cR2NLaxQXFze69EVjy2QYY8zeUNWQiFwNvA94gadVdaGIXBnd/gRwJvATEQkBVcAkjdMceHFNTiIyHngId6FPqeo9DbZLdPtJQCVwsarOiVc8rTWUvDFnnnkmU6dOZePGjUyaNImMjIH89a/PUlxczOzZs/H7/fTu3ZtAQKP3PSlVVatJSzu4bkHD+ktrZGRkcOyxx1JdXd3k0he2JIYxpjWp6jRgWoPXnqj3+FHg0YbHxUPcRuvVGzM/ARgEnCMigxrsNgHXmdYPmAz8KV7xNIit1c85adIkXnnlFaZOncqZZ56JiJeysnK6dOmC3+/n448/Zs2aNaSl9YoeoYRCW6iomMuOHQupqSlm27b15OZmk5ISYeHCOcyYMYNwOMDo0YV8+uknrFixhEikhi1bNhGJhDj++B/wyCOPoBpBVa1ZzxhzwIhn5VQ3Zh5ARGrHzNe/oetU4LloWThDRHJFpLuqbmjtYEqrS1m2bVlrn7bO4MGDKS8vp0ePHnTv3h2A8847j1NOOYUjjjiCwsJCBgwYgNebQWZmT8ATHd1XTjhcTiCwhrFje/OnP5VSWDiCfv16MWrUYAKB1WRm5vPggzdwxhmnEokonTvn8dZbj3HddT/kf/7nXgYP7ofX6+Wmmy7nRz/6XjSixhJww9fc8+rqYv7976OizyWavAXw1Hscq/js27I/KNp+X4u3pfsmQqyJr3v3y+nZ8/q2DmO/iGdyamzM/Hdi2KcHsEtyio7HnwyQkpKyV8F4PV7y0vLweryk+9P36hzNqR2YUKtTp0588cUXje5bUeFu0PX781FVIpEAGRlh/vGP93AjNxTXCuke/+hHfTjllPPqnoOSmgrPPPPULq/tqvYcO5833A7g9VbStet50WbPnV9u5vWWNCfHvm/Lmqnbfl+LN377Jkas7UNKSsuX+mmv4pmcYhkzH8s+qOoUYAq49Zz2JpislCyyOibmja8igteb1mbv7/fvoF+/R9rs/Y0xpqF4zhDR7Jj5GPcxxhiTZOKZnOrGzItICm7M/NsN9nkbuFCcMUDp3vY3tbcVfROF/dyMMYkobs16MY6Zn4YbRr4cN5T8kr15r7S0NLZu3Up+fr4NrW4BVWXr1q2kpbVdk6IxxjRG2ttfzpmZmbpjx64zfAeDQYqKiqiurm6jqNqvtLQ0CgoK8Pv9bR2KMSaORKRSVTPbOo5YHRDJyRhjzJ61t+SUVEtmGGOMaR8sORljjEk4lpyMMcYknHbX5yQiEdxsuHvDB+y+ZG37ZNeSmOxaEpNdC6SrarspSNpdctoXIjKrmZUg2w27lsRk15KY7Fran3aTRY0xxiQPS07GGGMSTrIlpyltHUArsmtJTHYticmupZ1Jqj4nY4wx7UOyVU7GGGPaAUtOxhhjEk7SJCcRGS8iS0VkuYjc1NbxtJSIrBaRb0RkrojMir7WUUT+JSLLot/z2jrOxojI0yKyWUQW1HutydhF5Obo57RURE5sm6gb18S13CEi66KfzVwROanetoS8FhHpKSIfi8hiEVkoItdGX293n8serqU9fi5pIjJTROZFr+XO6Ovt7nPZZ6p6wH/hluxYAfQFUoB5wKC2jquF17Aa6NTgtXuBm6KPbwL+t63jbCL2scDhwILmYgcGRT+fVKBP9HPztvU1NHMtdwC/aGTfhL0WoDtwePRxNvBtNN5297ns4Vra4+ciQFb0sR/4EhjTHj+Xff1KlsppNLBcVVeqag3wCnBqG8fUGk4Fno0+fhY4rQ1jaZKqTge2NXi5qdhPBV5R1YCqrsKt9TV6vwQagyaupSkJey2qukFV50QflwOLgR60w89lD9fSlES+FlXViuhTf/RLaYefy75KluTUA1hb73kRe/7Hm4gU+KeIzBaRydHXump05eDo9y5tFl3LNRV7e/2srhaR+dFmv9oml3ZxLSLSGxiB+yu9XX8uDa4F2uHnIiJeEZkLbAb+part/nPZG8mSnBpbHre9jaE/SlUPByYAPxWRsW0dUJy0x8/qT8AhQCGwAXgg+nrCX4uIZAGvAdepatmedm3ktUS/lnb5uahqWFULgQJgtIgM2cPuCX0t+yJZklMR0LPe8wJgfRvFsldUdX30+2bgDVzpvklEugNEv29uuwhbrKnY291npaqbor9QIsCT7GxWSehrERE/7pf5i6r6evTldvm5NHYt7fVzqaWqdGiFFAAAAwlJREFUJcAnwHja6eeyL5IlOX0F9BORPiKSAkwC3m7jmGImIpkikl37GDgBWIC7houiu10EvNU2Ee6VpmJ/G5gkIqki0gfoB8xsg/hiVvtLI+p03GcDCXwtIiLAX4DFqvqHepva3efS1LW008+ls4jkRh+nAz8AltAOP5d91tYjMvbXF3ASbhTPCuDWto6nhbH3xY3ImQcsrI0fyAc+BJZFv3ds61ibiP9lXLNKEPeX3mV7ih24Nfo5LQUmtHX8MVzL88A3wHzcL4vuiX4twNG45p/5wNzo10nt8XPZw7W0x89lGPB1NOYFwK+jr7e7z2Vfv2z6ImOMMQknWZr1jDHGtCOWnIwxxiQcS07GGGMSjiUnY4wxCceSkzHGmIRjycmY/UhEjhWRv7d1HMYkOktOxhhjEo4lJ2MaISLnR9fVmSsif45OxlkhIg+IyBwR+VBEOkf3LRSRGdEJRt+onWBURA4VkQ+ia/PMEZFDoqfPEpGpIrJERF6MznBgjKnHkpMxDYjIQOBs3GS7hUAYOA/IBOaom4D3U+D26CHPATeq6jDcjAS1r78IPKaqw4Hv4maWADdr9nW4tXj6AkfF/aKMaWd8bR2AMQno+8D/b++OVeIKojiMf38bUQTFwiZF0lta+w4WaxPYwjpPIGjjU8RyIU0Q9AksBCtFSGWZavuwYMAUeizuFNGFJY3mLn6/6t7DMNwphjMzF85sAddtU7NEV2jzEfje2nwDTpOsAmtVddHiI+Ck1UL8UFVnAFV1D9D6u6qqcXv/AXwCLl9/WNL8MDlJ0wKMqmr/WTA5fNFuVu2vWUd1f/56fsB5KE3xWE+adg4MkmwAJFlP8pFuvgxam8/AZVVNgF9Jtlt8CFxUd5/QOMlO62MxyfKbjkKaY67YpBeq6jbJAd3Nwwt0Fci/AL+BzSQ3wITuvxR0Vxh8bcnnJ7DX4kPgOMlR62P3DYchzTWrkkv/KMldVa387++Q3gOP9SRJvePOSZLUO+6cJEm9Y3KSJPWOyUmS1DsmJ0lS75icJEm98wReYHOyzF2OVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 76us/step\n",
      "Test accuracy:  0.9717391133308411\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
