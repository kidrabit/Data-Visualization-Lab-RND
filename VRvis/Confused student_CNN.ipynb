{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "EEG = genfromtxt(\"Confusion during MOOC/EEG_data.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6의 raw데이터에 이상이 있으므로 6을 제외하고 분석\n",
    "EEG=EEG[1:,:]\n",
    "EEG=pd.DataFrame(EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12811, 15) (1275,)\n"
     ]
    }
   ],
   "source": [
    "remove_6=EEG[EEG[0]==6].index\n",
    "print(EEG.shape, remove_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11536, 15)\n"
     ]
    }
   ],
   "source": [
    "EEG=EEG.drop(remove_6)\n",
    "print(EEG.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_EEG=EEG[EEG[14]==0].index\n",
    "nc_EEG=EEG[EEG[14]==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusedEEG=EEG.drop(c_EEG)\n",
    "NonConfusedEEG=EEG.drop(nc_EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusedEEG=ConfusedEEG.values\n",
    "NonConfusedEEG=NonConfusedEEG.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index=[]\n",
    "for i in range(7) :\n",
    "    index.append(random.randint(0,5606))\n",
    "    \n",
    "NonConfusedEEG=pd.DataFrame(NonConfusedEEG)\n",
    "NonConfusedEEG=NonConfusedEEG.drop(index)\n",
    "NonConfusedEEG=NonConfusedEEG.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "for i in range(29) :\n",
    "    index.append(random.randint(0,5928))\n",
    "    \n",
    "ConfusedEEG=pd.DataFrame(ConfusedEEG)\n",
    "ConfusedEEG=ConfusedEEG.drop(index)\n",
    "ConfusedEEG=ConfusedEEG.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 15) (5600, 15)\n"
     ]
    }
   ],
   "source": [
    "X=ConfusedEEG\n",
    "NX=NonConfusedEEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동영상, raw, 주파수 data 사용\n",
    "X1=pd.DataFrame(X)\n",
    "X1=X1.drop(X1.columns[[0,2,3,13,14]], axis='columns')\n",
    "#사람 정보, raw, 주파수 data 사용\n",
    "X2=pd.DataFrame(X)\n",
    "X2=X2.drop(X2.columns[[1,2,3,13,14]], axis='columns')\n",
    "#동영상, raw, 주파수 data 사용\n",
    "X3=pd.DataFrame(X)\n",
    "X3=X3.drop(X3.columns[[0,2,3,4,13,14]], axis='columns')\n",
    "#사람 정보, 주파수 data 사용\n",
    "X4=pd.DataFrame(X)\n",
    "X4=X4.drop(X4.columns[[1,2,3,4,13,14]], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동영상, raw, 주파수 data 사용\n",
    "NX1=pd.DataFrame(NX)\n",
    "NX1=NX1.drop(NX1.columns[[0,2,3,13,14]], axis='columns')\n",
    "#사람 정보, raw, 주파수 data 사용\n",
    "NX2=pd.DataFrame(NX)\n",
    "NX2=NX2.drop(NX2.columns[[1,2,3,13,14]], axis='columns')\n",
    "#동영상, raw, 주파수 data 사용\n",
    "NX3=pd.DataFrame(NX)\n",
    "NX3=NX3.drop(NX3.columns[[0,2,3,4,13,14]], axis='columns')\n",
    "#사람 정보, 주파수 data 사용\n",
    "NX4=pd.DataFrame(NX)\n",
    "NX4=NX4.drop(NX4.columns[[1,2,3,4,13,14]], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 10) (5900, 10) (5900, 9) (5900, 9)\n",
      "(5600, 10) (5600, 10) (5600, 9) (5600, 9)\n"
     ]
    }
   ],
   "source": [
    "X1=X1.values\n",
    "X2=X2.values\n",
    "X3=X3.values\n",
    "X4=X4.values\n",
    "\n",
    "NX1=NX1.values\n",
    "NX2=NX2.values\n",
    "NX3=NX3.values\n",
    "NX4=NX4.values\n",
    "\n",
    "print(X1.shape, X2.shape, X3.shape, X4.shape)\n",
    "print(NX1.shape, NX2.shape, NX3.shape, NX4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 10) (5600, 10)\n"
     ]
    }
   ],
   "source": [
    "X=X1\n",
    "#X=X2\n",
    "#X=X3\n",
    "#X=X4\n",
    "\n",
    "NX=NX1\n",
    "#NX=NX2\n",
    "#NX=NX3\n",
    "#NX=NX4\n",
    "\n",
    "print(X.shape, NX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X[:]=scaler.fit_transform(X[:])\n",
    "NX[:]=scaler.fit_transform(NX[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(590,10, 10)\n",
    "NX = NX.reshape(560,10, 10)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150, 1)\n"
     ]
    }
   ],
   "source": [
    "label_X= np.zeros((590,1))\n",
    "label_NX=np.ones((560,1))\n",
    "label=np.r_[label_X,label_NX]\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "data=np.r_[X,NX]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.4, random_state=115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 2) (460, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils as np_utils\n",
    "#one-hot encoding\n",
    "y_train      = np_utils.to_categorical(y_train)\n",
    "y_test       = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 10, 10, 1) (460, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2],1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import  BatchNormalization,Dense, Conv2D, Convolution2D, MaxPooling2D, Dropout, Flatten, TimeDistributed, InputLayer, LSTM\n",
    "from keras.layers import Input, Reshape, Activation, add, Add\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 10, 10, 50)        250       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 10, 10, 50)        10050     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 5, 5, 50)          10050     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 5, 5, 50)          10050     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1250)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                62550     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 93,052\n",
      "Trainable params: 93,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def basic_cnn():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]), filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(filters = 50, kernel_size = (2,2), strides = (1,1), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # prior layer should be flattend to be connected to dense layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    \n",
    "    # final layer with 10 neurons to classify the instances\n",
    "    model.add(Dense(50, activation = 'relu'))\n",
    "    \n",
    "    # final layer with 10 neurons to classify the instances\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = basic_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 690 samples, validate on 460 samples\n",
      "Epoch 1/300\n",
      "690/690 [==============================] - 1s 967us/step - loss: 0.6805 - accuracy: 0.5362 - val_loss: 0.6849 - val_accuracy: 0.5174\n",
      "Epoch 2/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 0.6444 - accuracy: 0.6246 - val_loss: 0.6582 - val_accuracy: 0.6087\n",
      "Epoch 3/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 0.6164 - accuracy: 0.6406 - val_loss: 0.6114 - val_accuracy: 0.6565\n",
      "Epoch 4/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 0.5535 - accuracy: 0.7130 - val_loss: 0.4991 - val_accuracy: 0.7935\n",
      "Epoch 5/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.4275 - accuracy: 0.8290 - val_loss: 0.3503 - val_accuracy: 0.8804\n",
      "Epoch 6/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 0.3039 - accuracy: 0.8942 - val_loss: 0.2214 - val_accuracy: 0.9391\n",
      "Epoch 7/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 0.2420 - accuracy: 0.9188 - val_loss: 0.2220 - val_accuracy: 0.9478\n",
      "Epoch 8/300\n",
      "690/690 [==============================] - 0s 126us/step - loss: 0.1987 - accuracy: 0.9377 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
      "Epoch 9/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 0.1736 - accuracy: 0.9435 - val_loss: 0.1396 - val_accuracy: 0.9609\n",
      "Epoch 10/300\n",
      "690/690 [==============================] - 0s 126us/step - loss: 0.1566 - accuracy: 0.9420 - val_loss: 0.1046 - val_accuracy: 0.9652\n",
      "Epoch 11/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 0.1381 - accuracy: 0.9565 - val_loss: 0.1230 - val_accuracy: 0.9630\n",
      "Epoch 12/300\n",
      "690/690 [==============================] - 0s 127us/step - loss: 0.1058 - accuracy: 0.9638 - val_loss: 0.1215 - val_accuracy: 0.9652\n",
      "Epoch 13/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 0.1022 - accuracy: 0.9638 - val_loss: 0.0974 - val_accuracy: 0.9761\n",
      "Epoch 14/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 0.0746 - accuracy: 0.9754 - val_loss: 0.0888 - val_accuracy: 0.9717\n",
      "Epoch 15/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 0.0867 - val_accuracy: 0.9717\n",
      "Epoch 16/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 0.0554 - accuracy: 0.9797 - val_loss: 0.1061 - val_accuracy: 0.9587\n",
      "Epoch 17/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 0.0591 - accuracy: 0.9783 - val_loss: 0.1042 - val_accuracy: 0.9652\n",
      "Epoch 18/300\n",
      "690/690 [==============================] - 0s 127us/step - loss: 0.0425 - accuracy: 0.9855 - val_loss: 0.0860 - val_accuracy: 0.9739\n",
      "Epoch 19/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.1142 - val_accuracy: 0.9674\n",
      "Epoch 20/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 0.0338 - accuracy: 0.9870 - val_loss: 0.0842 - val_accuracy: 0.9761\n",
      "Epoch 21/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 0.0213 - accuracy: 0.9971 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 22/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.0916 - val_accuracy: 0.9739\n",
      "Epoch 23/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 0.0996 - val_accuracy: 0.9761\n",
      "Epoch 24/300\n",
      "690/690 [==============================] - 0s 164us/step - loss: 0.0163 - accuracy: 0.9986 - val_loss: 0.0973 - val_accuracy: 0.9717\n",
      "Epoch 25/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9761\n",
      "Epoch 26/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1121 - val_accuracy: 0.9674\n",
      "Epoch 27/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9761\n",
      "Epoch 28/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9761\n",
      "Epoch 29/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9717\n",
      "Epoch 30/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9739\n",
      "Epoch 31/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9739\n",
      "Epoch 32/300\n",
      "690/690 [==============================] - 0s 151us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9739\n",
      "Epoch 33/300\n",
      "690/690 [==============================] - 0s 141us/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1293 - val_accuracy: 0.9739\n",
      "Epoch 34/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.1273 - val_accuracy: 0.9652\n",
      "Epoch 35/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.1144 - val_accuracy: 0.9652\n",
      "Epoch 36/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 0.0399 - accuracy: 0.9899 - val_loss: 0.1426 - val_accuracy: 0.9587\n",
      "Epoch 37/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 0.0292 - accuracy: 0.9855 - val_loss: 0.1287 - val_accuracy: 0.9630\n",
      "Epoch 38/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.0983 - val_accuracy: 0.9783\n",
      "Epoch 39/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1154 - val_accuracy: 0.9717\n",
      "Epoch 40/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.1087 - val_accuracy: 0.9717\n",
      "Epoch 41/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 0.0073 - accuracy: 0.9971 - val_loss: 0.2281 - val_accuracy: 0.9543\n",
      "Epoch 42/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.1154 - val_accuracy: 0.9630\n",
      "Epoch 43/300\n",
      "690/690 [==============================] - 0s 183us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9804\n",
      "Epoch 44/300\n",
      "690/690 [==============================] - 0s 183us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9717\n",
      "Epoch 45/300\n",
      "690/690 [==============================] - 0s 179us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9717\n",
      "Epoch 46/300\n",
      "690/690 [==============================] - 0s 168us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9739\n",
      "Epoch 47/300\n",
      "690/690 [==============================] - 0s 218us/step - loss: 7.7682e-04 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9717\n",
      "Epoch 48/300\n",
      "690/690 [==============================] - 0s 160us/step - loss: 7.1727e-04 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9717\n",
      "Epoch 49/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 6.2907e-04 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9717\n",
      "Epoch 50/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 5.8889e-04 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9739\n",
      "Epoch 51/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 5.5479e-04 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9739\n",
      "Epoch 52/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 5.0794e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9739\n",
      "Epoch 53/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 4.8590e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9739\n",
      "Epoch 54/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 4.5666e-04 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9739\n",
      "Epoch 55/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 4.2366e-04 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9739\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 134us/step - loss: 4.1129e-04 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9761\n",
      "Epoch 57/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 3.9457e-04 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9717\n",
      "Epoch 58/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 3.7959e-04 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9739\n",
      "Epoch 59/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 3.4798e-04 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9739\n",
      "Epoch 60/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 3.7976e-04 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9739\n",
      "Epoch 61/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 3.1445e-04 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9739\n",
      "Epoch 62/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 3.1629e-04 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9739\n",
      "Epoch 63/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 2.9967e-04 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9739\n",
      "Epoch 64/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 2.7707e-04 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9739\n",
      "Epoch 65/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 2.8639e-04 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9739\n",
      "Epoch 66/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 2.6127e-04 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9739\n",
      "Epoch 67/300\n",
      "690/690 [==============================] - 0s 147us/step - loss: 2.5902e-04 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9739\n",
      "Epoch 68/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 2.4740e-04 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9739\n",
      "Epoch 69/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 2.3291e-04 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9739\n",
      "Epoch 70/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 2.2491e-04 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9739\n",
      "Epoch 71/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 2.2325e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9739\n",
      "Epoch 72/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 2.0958e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9739\n",
      "Epoch 73/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.1091e-04 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9739\n",
      "Epoch 74/300\n",
      "690/690 [==============================] - 0s 230us/step - loss: 2.0461e-04 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9739\n",
      "Epoch 75/300\n",
      "690/690 [==============================] - 0s 200us/step - loss: 1.9026e-04 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9739\n",
      "Epoch 76/300\n",
      "690/690 [==============================] - 0s 160us/step - loss: 1.9059e-04 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9739\n",
      "Epoch 77/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 1.8363e-04 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9739\n",
      "Epoch 78/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.7556e-04 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9739\n",
      "Epoch 79/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.7300e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9739\n",
      "Epoch 80/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 1.7106e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9739\n",
      "Epoch 81/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.5999e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9739\n",
      "Epoch 82/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.5798e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9739\n",
      "Epoch 83/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.5244e-04 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9761\n",
      "Epoch 84/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.4635e-04 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9739\n",
      "Epoch 85/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.4292e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9739\n",
      "Epoch 86/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 1.4493e-04 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9739\n",
      "Epoch 87/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 1.3455e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9761\n",
      "Epoch 88/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.3811e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9739\n",
      "Epoch 89/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.2691e-04 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9761\n",
      "Epoch 90/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.2589e-04 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9761\n",
      "Epoch 91/300\n",
      "690/690 [==============================] - 0s 150us/step - loss: 1.2291e-04 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9761\n",
      "Epoch 92/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.1868e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9761\n",
      "Epoch 93/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.1904e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9739\n",
      "Epoch 94/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.1474e-04 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9761\n",
      "Epoch 95/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.1307e-04 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9761\n",
      "Epoch 96/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.0791e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9739\n",
      "Epoch 97/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.0562e-04 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9761\n",
      "Epoch 98/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.0986e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9761\n",
      "Epoch 99/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 9.8725e-05 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9739\n",
      "Epoch 100/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 9.8778e-05 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9739\n",
      "Epoch 101/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 9.6511e-05 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9739\n",
      "Epoch 102/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 9.3075e-05 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9761\n",
      "Epoch 103/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 9.7473e-05 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9761\n",
      "Epoch 104/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.0040e-04 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9739\n",
      "Epoch 105/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 8.9608e-05 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9739\n",
      "Epoch 106/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 9.3205e-05 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9761\n",
      "Epoch 107/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 9.5414e-05 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9739\n",
      "Epoch 108/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 8.2845e-05 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9739\n",
      "Epoch 109/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 8.5821e-05 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9761\n",
      "Epoch 110/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 139us/step - loss: 7.8408e-05 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9739\n",
      "Epoch 111/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 7.8247e-05 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9739\n",
      "Epoch 112/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 7.4429e-05 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9761\n",
      "Epoch 113/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 7.3488e-05 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9739\n",
      "Epoch 114/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 7.1652e-05 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9739\n",
      "Epoch 115/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 7.0876e-05 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9739\n",
      "Epoch 116/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 7.0103e-05 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9739\n",
      "Epoch 117/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 6.7496e-05 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9739\n",
      "Epoch 118/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 6.5957e-05 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9761\n",
      "Epoch 119/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 6.4817e-05 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9739\n",
      "Epoch 120/300\n",
      "690/690 [==============================] - 0s 159us/step - loss: 6.4834e-05 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9739\n",
      "Epoch 121/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 6.2409e-05 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9739\n",
      "Epoch 122/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 6.1111e-05 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9739\n",
      "Epoch 123/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 6.2669e-05 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9739\n",
      "Epoch 124/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 5.8392e-05 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9761\n",
      "Epoch 125/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 5.7525e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9739\n",
      "Epoch 126/300\n",
      "690/690 [==============================] - 0s 146us/step - loss: 5.6570e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9739\n",
      "Epoch 127/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 5.5360e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9739\n",
      "Epoch 128/300\n",
      "690/690 [==============================] - 0s 155us/step - loss: 5.4275e-05 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9739\n",
      "Epoch 129/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 5.3540e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9739\n",
      "Epoch 130/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 5.2234e-05 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9739\n",
      "Epoch 131/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 5.1736e-05 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9739\n",
      "Epoch 132/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 5.0605e-05 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9739\n",
      "Epoch 133/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 4.9563e-05 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9739\n",
      "Epoch 134/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 4.9971e-05 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9739\n",
      "Epoch 135/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 4.8611e-05 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9761\n",
      "Epoch 136/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 4.7416e-05 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9739\n",
      "Epoch 137/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 4.6735e-05 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9739\n",
      "Epoch 138/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 4.6275e-05 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9739\n",
      "Epoch 139/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 4.5041e-05 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9739\n",
      "Epoch 140/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 4.3821e-05 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9761\n",
      "Epoch 141/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 4.3456e-05 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9761\n",
      "Epoch 142/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 4.3054e-05 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9739\n",
      "Epoch 143/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 4.1726e-05 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9739\n",
      "Epoch 144/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 4.1979e-05 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9761\n",
      "Epoch 145/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 4.1257e-05 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9739\n",
      "Epoch 146/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 3.9842e-05 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9739\n",
      "Epoch 147/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 3.8944e-05 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9739\n",
      "Epoch 148/300\n",
      "690/690 [==============================] - 0s 166us/step - loss: 3.8565e-05 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9739\n",
      "Epoch 149/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 3.7833e-05 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9739\n",
      "Epoch 150/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.6965e-05 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9739\n",
      "Epoch 151/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 3.6501e-05 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9739\n",
      "Epoch 152/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.6383e-05 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9739\n",
      "Epoch 153/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 3.5136e-05 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9761\n",
      "Epoch 154/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 3.5274e-05 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9761\n",
      "Epoch 155/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.4186e-05 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9739\n",
      "Epoch 156/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.3779e-05 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9739\n",
      "Epoch 157/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 3.3578e-05 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9761\n",
      "Epoch 158/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 3.2704e-05 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9739\n",
      "Epoch 159/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 3.2927e-05 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9739\n",
      "Epoch 160/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.3071e-05 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9761\n",
      "Epoch 161/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.1009e-05 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9739\n",
      "Epoch 162/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 3.0461e-05 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9739\n",
      "Epoch 163/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 3.0241e-05 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9739\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 134us/step - loss: 2.9761e-05 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9739\n",
      "Epoch 165/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.9896e-05 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9739\n",
      "Epoch 166/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 2.8667e-05 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9739\n",
      "Epoch 167/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 2.8369e-05 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9739\n",
      "Epoch 168/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 2.8837e-05 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9761\n",
      "Epoch 169/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 2.8991e-05 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9739\n",
      "Epoch 170/300\n",
      "690/690 [==============================] - 0s 143us/step - loss: 2.7496e-05 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9761\n",
      "Epoch 171/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.6868e-05 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9739\n",
      "Epoch 172/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 2.6441e-05 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9739\n",
      "Epoch 173/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 2.6499e-05 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9739\n",
      "Epoch 174/300\n",
      "690/690 [==============================] - 0s 151us/step - loss: 2.5564e-05 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9739\n",
      "Epoch 175/300\n",
      "690/690 [==============================] - 0s 148us/step - loss: 2.5578e-05 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9739\n",
      "Epoch 176/300\n",
      "690/690 [==============================] - 0s 195us/step - loss: 2.5585e-05 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9739\n",
      "Epoch 177/300\n",
      "690/690 [==============================] - 0s 157us/step - loss: 2.5211e-05 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9761\n",
      "Epoch 178/300\n",
      "690/690 [==============================] - 0s 153us/step - loss: 2.4372e-05 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9739\n",
      "Epoch 179/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 2.3827e-05 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9739\n",
      "Epoch 180/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 2.3593e-05 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9739\n",
      "Epoch 181/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 2.3538e-05 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9739\n",
      "Epoch 182/300\n",
      "690/690 [==============================] - 0s 191us/step - loss: 2.2828e-05 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9739\n",
      "Epoch 183/300\n",
      "690/690 [==============================] - 0s 160us/step - loss: 2.2502e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9739\n",
      "Epoch 184/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 2.2487e-05 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9739\n",
      "Epoch 185/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 2.2125e-05 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9761\n",
      "Epoch 186/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 2.1557e-05 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9761\n",
      "Epoch 187/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.1635e-05 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9739\n",
      "Epoch 188/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 2.1486e-05 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9739\n",
      "Epoch 189/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 2.0858e-05 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9739\n",
      "Epoch 190/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 2.0935e-05 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9761\n",
      "Epoch 191/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 2.0351e-05 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9739\n",
      "Epoch 192/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 2.0078e-05 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9739\n",
      "Epoch 193/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.9764e-05 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9739\n",
      "Epoch 194/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.9532e-05 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9761\n",
      "Epoch 195/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.9335e-05 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9761\n",
      "Epoch 196/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.9806e-05 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9739\n",
      "Epoch 197/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.8925e-05 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9761\n",
      "Epoch 198/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.8549e-05 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9739\n",
      "Epoch 199/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.8165e-05 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9739\n",
      "Epoch 200/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 1.8050e-05 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9739\n",
      "Epoch 201/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.7658e-05 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9739\n",
      "Epoch 202/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 1.7586e-05 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9739\n",
      "Epoch 203/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.7336e-05 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9739\n",
      "Epoch 204/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.7142e-05 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9739\n",
      "Epoch 205/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.6796e-05 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9739\n",
      "Epoch 206/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.6584e-05 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9739\n",
      "Epoch 207/300\n",
      "690/690 [==============================] - 0s 172us/step - loss: 1.6408e-05 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9739\n",
      "Epoch 208/300\n",
      "690/690 [==============================] - 0s 145us/step - loss: 1.6243e-05 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9739\n",
      "Epoch 209/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.6098e-05 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9739\n",
      "Epoch 210/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.5785e-05 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9739\n",
      "Epoch 211/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.5823e-05 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9739\n",
      "Epoch 212/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.5501e-05 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9739\n",
      "Epoch 213/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.5466e-05 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9739\n",
      "Epoch 214/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.5050e-05 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9739\n",
      "Epoch 215/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.4898e-05 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9739\n",
      "Epoch 216/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.5091e-05 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9739\n",
      "Epoch 217/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 1.4785e-05 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9739\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 136us/step - loss: 1.4372e-05 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9739\n",
      "Epoch 219/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 1.4185e-05 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9739\n",
      "Epoch 220/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.4001e-05 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9739\n",
      "Epoch 221/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.3808e-05 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9739\n",
      "Epoch 222/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.3625e-05 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9739\n",
      "Epoch 223/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.3562e-05 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9739\n",
      "Epoch 224/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.3305e-05 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9739\n",
      "Epoch 225/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.3145e-05 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9739\n",
      "Epoch 226/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.3003e-05 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9739\n",
      "Epoch 227/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 1.2907e-05 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9739\n",
      "Epoch 228/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 1.2726e-05 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9739\n",
      "Epoch 229/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 1.2713e-05 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9761\n",
      "Epoch 230/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.2620e-05 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9739\n",
      "Epoch 231/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.2246e-05 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9739\n",
      "Epoch 232/300\n",
      "690/690 [==============================] - 0s 162us/step - loss: 1.2077e-05 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9761\n",
      "Epoch 233/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 1.2050e-05 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9739\n",
      "Epoch 234/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 1.1871e-05 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9761\n",
      "Epoch 235/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.1810e-05 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9739\n",
      "Epoch 236/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.1620e-05 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9739\n",
      "Epoch 237/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.1531e-05 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9739\n",
      "Epoch 238/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 1.1475e-05 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9739\n",
      "Epoch 239/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 1.1243e-05 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9739\n",
      "Epoch 240/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.1071e-05 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9739\n",
      "Epoch 241/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.1048e-05 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9761\n",
      "Epoch 242/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 1.0897e-05 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9739\n",
      "Epoch 243/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.0679e-05 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9739\n",
      "Epoch 244/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 1.0537e-05 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9739\n",
      "Epoch 245/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 1.0449e-05 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9761\n",
      "Epoch 246/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 1.0475e-05 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9739\n",
      "Epoch 247/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.0268e-05 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9739\n",
      "Epoch 248/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.0040e-05 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9739\n",
      "Epoch 249/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.0053e-05 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9739\n",
      "Epoch 250/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 9.8464e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9739\n",
      "Epoch 251/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 1.0029e-05 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9739\n",
      "Epoch 252/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 9.6800e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9739\n",
      "Epoch 253/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 9.5001e-06 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9739\n",
      "Epoch 254/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 9.5608e-06 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9739\n",
      "Epoch 255/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 9.2829e-06 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9739\n",
      "Epoch 256/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 9.2068e-06 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9739\n",
      "Epoch 257/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 9.2075e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9739\n",
      "Epoch 258/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 9.0127e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9739\n",
      "Epoch 259/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 8.8941e-06 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9739\n",
      "Epoch 260/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 8.7984e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9739\n",
      "Epoch 261/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 8.7622e-06 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9739\n",
      "Epoch 262/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 8.6338e-06 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9739\n",
      "Epoch 263/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 8.8201e-06 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9739\n",
      "Epoch 264/300\n",
      "690/690 [==============================] - 0s 127us/step - loss: 8.5654e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9739\n",
      "Epoch 265/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 8.3539e-06 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9739\n",
      "Epoch 266/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 8.3308e-06 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9739\n",
      "Epoch 267/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 8.1017e-06 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9739\n",
      "Epoch 268/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 8.0707e-06 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9739\n",
      "Epoch 269/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 7.9925e-06 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9739\n",
      "Epoch 270/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 7.8361e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9739\n",
      "Epoch 271/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 7.8005e-06 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9739\n",
      "Epoch 272/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 0s 139us/step - loss: 7.7117e-06 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9739\n",
      "Epoch 273/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 7.7917e-06 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9739\n",
      "Epoch 274/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 7.5519e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9739\n",
      "Epoch 275/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 7.5070e-06 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9739\n",
      "Epoch 276/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 7.3811e-06 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9739\n",
      "Epoch 277/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 7.4550e-06 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9761\n",
      "Epoch 278/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 7.2884e-06 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9739\n",
      "Epoch 279/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 7.2781e-06 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9739\n",
      "Epoch 280/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 7.3076e-06 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9739\n",
      "Epoch 281/300\n",
      "690/690 [==============================] - 0s 140us/step - loss: 7.2941e-06 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9739\n",
      "Epoch 282/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 6.9177e-06 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9739\n",
      "Epoch 283/300\n",
      "690/690 [==============================] - 0s 130us/step - loss: 7.0835e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9739\n",
      "Epoch 284/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 6.7273e-06 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9739\n",
      "Epoch 285/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 6.7749e-06 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9739\n",
      "Epoch 286/300\n",
      "690/690 [==============================] - 0s 137us/step - loss: 6.6341e-06 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9739\n",
      "Epoch 287/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 6.5613e-06 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9739\n",
      "Epoch 288/300\n",
      "690/690 [==============================] - 0s 132us/step - loss: 6.5088e-06 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9739\n",
      "Epoch 289/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 6.4159e-06 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9739\n",
      "Epoch 290/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 6.3412e-06 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9739\n",
      "Epoch 291/300\n",
      "690/690 [==============================] - 0s 136us/step - loss: 6.4537e-06 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9739\n",
      "Epoch 292/300\n",
      "690/690 [==============================] - 0s 134us/step - loss: 6.4061e-06 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9739\n",
      "Epoch 293/300\n",
      "690/690 [==============================] - 0s 141us/step - loss: 6.1603e-06 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9739\n",
      "Epoch 294/300\n",
      "690/690 [==============================] - 0s 133us/step - loss: 6.0608e-06 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9739\n",
      "Epoch 295/300\n",
      "690/690 [==============================] - 0s 139us/step - loss: 6.0152e-06 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9739\n",
      "Epoch 296/300\n",
      "690/690 [==============================] - 0s 129us/step - loss: 6.0439e-06 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9739\n",
      "Epoch 297/300\n",
      "690/690 [==============================] - 0s 163us/step - loss: 5.9004e-06 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9739\n",
      "Epoch 298/300\n",
      "690/690 [==============================] - 0s 142us/step - loss: 5.8146e-06 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9739\n",
      "Epoch 299/300\n",
      "690/690 [==============================] - 0s 156us/step - loss: 5.7560e-06 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9739\n",
      "Epoch 300/300\n",
      "690/690 [==============================] - 0s 149us/step - loss: 5.7179e-06 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9739\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, y_train, epochs=300, batch_size=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 0s 401us/step\n",
      "Test accuracy:  0.9739130139350891\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
