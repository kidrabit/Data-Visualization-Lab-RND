{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "EEG = genfromtxt(\"C:/Users/SoobinYim/workspace/Confusion during MOOC/EEG_data.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removal = [2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "#X = np.delete(EEG, list(set(removal+[14])), axis=1)\n",
    "EEG=EEG[1:,:]\n",
    "X=EEG[:,5:-2]\n",
    "y = EEG[:, [14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Conv2D, Convolution2D, MaxPooling2D, Dropout, Flatten, TimeDistributed, InputLayer, LSTM\n",
    "from keras.layers import Input, Reshape, Activation, add, Add\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(eeg_data):\n",
    "    eeg_input=Input(shape=(8,)) #입력 정의\n",
    "    \n",
    "    eeg_output = Dense(50, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(100, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(150, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(200, activation='relu')(eeg_output)\n",
    "    \n",
    "    model = Dense(1, activation='sigmoid')(eeg_output)\n",
    "    \n",
    "    model = keras.models.Model(inputs=eeg_input, outputs=model) #모델 생성(전체 모델 정의)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 150)               1350      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 31,751\n",
      "Trainable params: 31,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_create(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8967 samples, validate on 3844 samples\n",
      "Epoch 1/500\n",
      "8967/8967 [==============================] - 1s 79us/step - loss: 7727.2372 - accuracy: 0.5049 - val_loss: 4666.1564 - val_accuracy: 0.4873\n",
      "Epoch 2/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 3395.2980 - accuracy: 0.5080 - val_loss: 642.3781 - val_accuracy: 0.5492\n",
      "Epoch 3/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 1881.1311 - accuracy: 0.5177 - val_loss: 431.4470 - val_accuracy: 0.5182\n",
      "Epoch 4/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 1181.6567 - accuracy: 0.5122 - val_loss: 462.1299 - val_accuracy: 0.5239\n",
      "Epoch 5/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 719.6335 - accuracy: 0.5081 - val_loss: 209.4748 - val_accuracy: 0.5193\n",
      "Epoch 6/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 432.1817 - accuracy: 0.5072 - val_loss: 199.2225 - val_accuracy: 0.5351\n",
      "Epoch 7/500\n",
      "8967/8967 [==============================] - 1s 67us/step - loss: 251.1077 - accuracy: 0.5201 - val_loss: 78.8287 - val_accuracy: 0.5297\n",
      "Epoch 8/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 120.1232 - accuracy: 0.5183 - val_loss: 42.5847 - val_accuracy: 0.5104\n",
      "Epoch 9/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 56.4141 - accuracy: 0.5238 - val_loss: 24.6416 - val_accuracy: 0.5187\n",
      "Epoch 10/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 28.5379 - accuracy: 0.5199 - val_loss: 18.6418 - val_accuracy: 0.5151\n",
      "Epoch 11/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 18.0631 - accuracy: 0.5120 - val_loss: 11.7279 - val_accuracy: 0.4823\n",
      "Epoch 12/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 11.0157 - accuracy: 0.5053 - val_loss: 8.9756 - val_accuracy: 0.5021\n",
      "Epoch 13/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 8.7090 - accuracy: 0.4943 - val_loss: 7.2562 - val_accuracy: 0.4919\n",
      "Epoch 14/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 6.7129 - accuracy: 0.4893 - val_loss: 7.2426 - val_accuracy: 0.4919\n",
      "Epoch 15/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 5.5469 - accuracy: 0.4897 - val_loss: 4.2090 - val_accuracy: 0.4883\n",
      "Epoch 16/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 5.3751 - accuracy: 0.4893 - val_loss: 4.9285 - val_accuracy: 0.4901\n",
      "Epoch 17/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 4.4372 - accuracy: 0.5206 - val_loss: 3.9873 - val_accuracy: 0.5289\n",
      "Epoch 18/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 3.1852 - accuracy: 0.5253 - val_loss: 4.3318 - val_accuracy: 0.5221\n",
      "Epoch 19/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 2.2737 - accuracy: 0.5265 - val_loss: 2.5653 - val_accuracy: 0.5203\n",
      "Epoch 20/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 2.5463 - accuracy: 0.5201 - val_loss: 2.1493 - val_accuracy: 0.5159\n",
      "Epoch 21/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 1.7352 - accuracy: 0.5188 - val_loss: 2.4396 - val_accuracy: 0.5200\n",
      "Epoch 22/500\n",
      "8967/8967 [==============================] - 1s 68us/step - loss: 2.0842 - accuracy: 0.5208 - val_loss: 3.5556 - val_accuracy: 0.5096\n",
      "Epoch 23/500\n",
      "8967/8967 [==============================] - 1s 72us/step - loss: 3.4164 - accuracy: 0.5221 - val_loss: 1.8415 - val_accuracy: 0.5193\n",
      "Epoch 24/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 2.1016 - accuracy: 0.5193 - val_loss: 1.7717 - val_accuracy: 0.5229\n",
      "Epoch 25/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 2.1196 - accuracy: 0.5208 - val_loss: 1.9791 - val_accuracy: 0.5252\n",
      "Epoch 26/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 1.5170 - accuracy: 0.5211 - val_loss: 1.4795 - val_accuracy: 0.5166\n",
      "Epoch 27/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 1.3411 - accuracy: 0.5230 - val_loss: 1.7104 - val_accuracy: 0.5239\n",
      "Epoch 28/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 1.2478 - accuracy: 0.5208 - val_loss: 1.4741 - val_accuracy: 0.5187\n",
      "Epoch 29/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 1.1118 - accuracy: 0.5199 - val_loss: 1.8093 - val_accuracy: 0.5273\n",
      "Epoch 30/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 1.5009 - accuracy: 0.5189 - val_loss: 1.3154 - val_accuracy: 0.5232\n",
      "Epoch 31/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.9852 - accuracy: 0.5195 - val_loss: 1.5628 - val_accuracy: 0.5237\n",
      "Epoch 32/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 1.5337 - accuracy: 0.5176 - val_loss: 0.9970 - val_accuracy: 0.5195\n",
      "Epoch 33/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 1.2788 - accuracy: 0.5163 - val_loss: 1.2582 - val_accuracy: 0.5182\n",
      "Epoch 34/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 1.4437 - accuracy: 0.5196 - val_loss: 1.0379 - val_accuracy: 0.5169\n",
      "Epoch 35/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.9680 - accuracy: 0.5167 - val_loss: 1.0176 - val_accuracy: 0.5182\n",
      "Epoch 36/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.8779 - accuracy: 0.5168 - val_loss: 1.2034 - val_accuracy: 0.5195\n",
      "Epoch 37/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.8592 - accuracy: 0.5176 - val_loss: 1.0124 - val_accuracy: 0.5161\n",
      "Epoch 38/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.7417 - accuracy: 0.5188 - val_loss: 1.0732 - val_accuracy: 0.5166\n",
      "Epoch 39/500\n",
      "8967/8967 [==============================] - 1s 67us/step - loss: 0.7795 - accuracy: 0.5182 - val_loss: 1.0661 - val_accuracy: 0.5174\n",
      "Epoch 40/500\n",
      "8967/8967 [==============================] - 1s 70us/step - loss: 0.9849 - accuracy: 0.5178 - val_loss: 1.8670 - val_accuracy: 0.5177\n",
      "Epoch 41/500\n",
      "8967/8967 [==============================] - 1s 68us/step - loss: 0.9717 - accuracy: 0.5186 - val_loss: 1.3835 - val_accuracy: 0.5148\n",
      "Epoch 42/500\n",
      "8967/8967 [==============================] - 1s 70us/step - loss: 0.9559 - accuracy: 0.5168 - val_loss: 0.8117 - val_accuracy: 0.5177\n",
      "Epoch 43/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.7720 - accuracy: 0.5176 - val_loss: 0.7690 - val_accuracy: 0.5177\n",
      "Epoch 44/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.7138 - accuracy: 0.5170 - val_loss: 0.8495 - val_accuracy: 0.5174\n",
      "Epoch 45/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.6996 - accuracy: 0.5178 - val_loss: 0.8518 - val_accuracy: 0.5161\n",
      "Epoch 46/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.7325 - accuracy: 0.5156 - val_loss: 0.9337 - val_accuracy: 0.5146\n",
      "Epoch 47/500\n",
      "8967/8967 [==============================] - 1s 67us/step - loss: 0.7236 - accuracy: 0.5161 - val_loss: 0.8073 - val_accuracy: 0.5169\n",
      "Epoch 48/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6966 - accuracy: 0.5173 - val_loss: 0.8209 - val_accuracy: 0.5180\n",
      "Epoch 49/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6954 - accuracy: 0.5169 - val_loss: 0.8340 - val_accuracy: 0.5180\n",
      "Epoch 50/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.7128 - accuracy: 0.5177 - val_loss: 0.8360 - val_accuracy: 0.5172\n",
      "Epoch 51/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.6984 - accuracy: 0.5161 - val_loss: 0.8426 - val_accuracy: 0.5156\n",
      "Epoch 52/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.6989 - accuracy: 0.5159 - val_loss: 0.8436 - val_accuracy: 0.5164\n",
      "Epoch 53/500\n",
      "8967/8967 [==============================] - 1s 69us/step - loss: 0.7044 - accuracy: 0.5167 - val_loss: 0.8522 - val_accuracy: 0.5169\n",
      "Epoch 54/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6925 - accuracy: 0.5164 - val_loss: 0.8488 - val_accuracy: 0.5169\n",
      "Epoch 55/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6946 - accuracy: 0.5162 - val_loss: 0.8426 - val_accuracy: 0.5166\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 67us/step - loss: 0.6895 - accuracy: 0.5166 - val_loss: 0.8418 - val_accuracy: 0.5166\n",
      "Epoch 57/500\n",
      "8967/8967 [==============================] - 1s 60us/step - loss: 0.6909 - accuracy: 0.5158 - val_loss: 0.8107 - val_accuracy: 0.5166\n",
      "Epoch 58/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6891 - accuracy: 0.5166 - val_loss: 0.8270 - val_accuracy: 0.5166\n",
      "Epoch 59/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6891 - accuracy: 0.5167 - val_loss: 0.8220 - val_accuracy: 0.5166\n",
      "Epoch 60/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6891 - accuracy: 0.5163 - val_loss: 0.8171 - val_accuracy: 0.5161\n",
      "Epoch 61/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.7009 - accuracy: 0.5162 - val_loss: 0.7883 - val_accuracy: 0.5164\n",
      "Epoch 62/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6897 - accuracy: 0.5156 - val_loss: 0.8305 - val_accuracy: 0.5159\n",
      "Epoch 63/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.7699 - accuracy: 0.5159 - val_loss: 0.9064 - val_accuracy: 0.5161\n",
      "Epoch 64/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.9179 - val_accuracy: 0.5161\n",
      "Epoch 65/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6984 - accuracy: 0.5154 - val_loss: 0.8544 - val_accuracy: 0.5156\n",
      "Epoch 66/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6964 - accuracy: 0.5153 - val_loss: 0.8565 - val_accuracy: 0.5161\n",
      "Epoch 67/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6943 - accuracy: 0.5160 - val_loss: 0.9713 - val_accuracy: 0.5166\n",
      "Epoch 68/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.7278 - accuracy: 0.5158 - val_loss: 0.8511 - val_accuracy: 0.5166\n",
      "Epoch 69/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6901 - accuracy: 0.5162 - val_loss: 0.8938 - val_accuracy: 0.5153\n",
      "Epoch 70/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6930 - accuracy: 0.5157 - val_loss: 0.8834 - val_accuracy: 0.5151\n",
      "Epoch 71/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6907 - accuracy: 0.5158 - val_loss: 0.8980 - val_accuracy: 0.5153\n",
      "Epoch 72/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.7211 - accuracy: 0.5153 - val_loss: 0.9158 - val_accuracy: 0.5153\n",
      "Epoch 73/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6907 - accuracy: 0.5154 - val_loss: 0.8892 - val_accuracy: 0.5156\n",
      "Epoch 74/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6904 - accuracy: 0.5149 - val_loss: 0.8880 - val_accuracy: 0.5153\n",
      "Epoch 75/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6899 - accuracy: 0.5154 - val_loss: 0.8873 - val_accuracy: 0.5153\n",
      "Epoch 76/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6901 - accuracy: 0.5153 - val_loss: 0.8872 - val_accuracy: 0.5153\n",
      "Epoch 77/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5149 - val_loss: 0.8761 - val_accuracy: 0.5153\n",
      "Epoch 78/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6905 - accuracy: 0.5149 - val_loss: 0.8775 - val_accuracy: 0.5153\n",
      "Epoch 79/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6900 - accuracy: 0.5151 - val_loss: 0.8789 - val_accuracy: 0.5153\n",
      "Epoch 80/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6901 - accuracy: 0.5151 - val_loss: 0.8802 - val_accuracy: 0.5153\n",
      "Epoch 81/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6901 - accuracy: 0.5151 - val_loss: 0.8804 - val_accuracy: 0.5153\n",
      "Epoch 82/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6903 - accuracy: 0.5150 - val_loss: 0.8805 - val_accuracy: 0.5153\n",
      "Epoch 83/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6901 - accuracy: 0.5151 - val_loss: 0.8807 - val_accuracy: 0.5153\n",
      "Epoch 84/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.7365 - accuracy: 0.5146 - val_loss: 0.8970 - val_accuracy: 0.5151\n",
      "Epoch 85/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.7209 - accuracy: 0.5150 - val_loss: 0.8896 - val_accuracy: 0.5153\n",
      "Epoch 86/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6908 - accuracy: 0.5144 - val_loss: 0.8962 - val_accuracy: 0.5153\n",
      "Epoch 87/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6918 - accuracy: 0.5148 - val_loss: 0.9037 - val_accuracy: 0.5153\n",
      "Epoch 88/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6911 - accuracy: 0.5151 - val_loss: 0.9290 - val_accuracy: 0.5159\n",
      "Epoch 89/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6907 - accuracy: 0.5147 - val_loss: 0.9025 - val_accuracy: 0.5153\n",
      "Epoch 90/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6893 - accuracy: 0.5163 - val_loss: 0.9027 - val_accuracy: 0.5153\n",
      "Epoch 91/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6902 - accuracy: 0.5151 - val_loss: 0.9031 - val_accuracy: 0.5153\n",
      "Epoch 92/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6900 - accuracy: 0.5152 - val_loss: 0.9033 - val_accuracy: 0.5153\n",
      "Epoch 93/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6902 - accuracy: 0.5150 - val_loss: 0.9066 - val_accuracy: 0.5151\n",
      "Epoch 94/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6902 - accuracy: 0.5154 - val_loss: 0.9022 - val_accuracy: 0.5153\n",
      "Epoch 95/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6901 - accuracy: 0.5153 - val_loss: 0.9023 - val_accuracy: 0.5153\n",
      "Epoch 96/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6955 - accuracy: 0.5143 - val_loss: 1.0767 - val_accuracy: 0.5156\n",
      "Epoch 97/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6938 - accuracy: 0.5148 - val_loss: 0.9845 - val_accuracy: 0.5153\n",
      "Epoch 98/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6905 - accuracy: 0.5149 - val_loss: 0.9844 - val_accuracy: 0.5153\n",
      "Epoch 99/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6900 - accuracy: 0.5154 - val_loss: 0.9845 - val_accuracy: 0.5153\n",
      "Epoch 100/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6986 - accuracy: 0.5153 - val_loss: 0.8530 - val_accuracy: 0.5153\n",
      "Epoch 101/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6903 - accuracy: 0.5152 - val_loss: 0.8257 - val_accuracy: 0.5153\n",
      "Epoch 102/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6902 - accuracy: 0.5150 - val_loss: 0.8265 - val_accuracy: 0.5153\n",
      "Epoch 103/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.7212 - accuracy: 0.5152 - val_loss: 0.8317 - val_accuracy: 0.5153\n",
      "Epoch 104/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.7832 - accuracy: 0.5137 - val_loss: 1.0817 - val_accuracy: 0.5159\n",
      "Epoch 105/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.7433 - accuracy: 0.5148 - val_loss: 0.8247 - val_accuracy: 0.5153\n",
      "Epoch 106/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6908 - accuracy: 0.5149 - val_loss: 0.8005 - val_accuracy: 0.5151\n",
      "Epoch 107/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6905 - accuracy: 0.5147 - val_loss: 0.8019 - val_accuracy: 0.5151\n",
      "Epoch 108/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6904 - accuracy: 0.5149 - val_loss: 0.8979 - val_accuracy: 0.5153\n",
      "Epoch 109/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6905 - accuracy: 0.5149 - val_loss: 0.8980 - val_accuracy: 0.5153\n",
      "Epoch 110/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6905 - accuracy: 0.5148 - val_loss: 0.8979 - val_accuracy: 0.5153\n",
      "Epoch 111/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6905 - accuracy: 0.5147 - val_loss: 0.8978 - val_accuracy: 0.5153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6905 - accuracy: 0.5148 - val_loss: 0.8978 - val_accuracy: 0.5153\n",
      "Epoch 113/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6907 - accuracy: 0.5146 - val_loss: 0.9130 - val_accuracy: 0.5153\n",
      "Epoch 114/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6905 - accuracy: 0.5149 - val_loss: 0.9129 - val_accuracy: 0.5153\n",
      "Epoch 115/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.7513 - accuracy: 0.5147 - val_loss: 0.7772 - val_accuracy: 0.5153\n",
      "Epoch 116/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.7927 - accuracy: 0.5149 - val_loss: 1.2235 - val_accuracy: 0.5161\n",
      "Epoch 117/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.8071 - accuracy: 0.5131 - val_loss: 0.9766 - val_accuracy: 0.5151\n",
      "Epoch 118/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.7534 - accuracy: 0.5135 - val_loss: 0.8721 - val_accuracy: 0.5148\n",
      "Epoch 119/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 0.8720 - val_accuracy: 0.5148\n",
      "Epoch 120/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6921 - accuracy: 0.5137 - val_loss: 0.8081 - val_accuracy: 0.5148\n",
      "Epoch 121/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5130 - val_loss: 0.8080 - val_accuracy: 0.5148\n",
      "Epoch 122/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 0.8080 - val_accuracy: 0.5148\n",
      "Epoch 123/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 0.8080 - val_accuracy: 0.5148\n",
      "Epoch 124/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.8080 - val_accuracy: 0.5148\n",
      "Epoch 125/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.8080 - val_accuracy: 0.5148\n",
      "Epoch 126/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.8079 - val_accuracy: 0.5148\n",
      "Epoch 127/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5131 - val_loss: 0.8080 - val_accuracy: 0.5148\n",
      "Epoch 128/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 0.8079 - val_accuracy: 0.5148\n",
      "Epoch 129/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6918 - accuracy: 0.5130 - val_loss: 0.8080 - val_accuracy: 0.5148\n",
      "Epoch 130/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 0.8078 - val_accuracy: 0.5148\n",
      "Epoch 131/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5135 - val_loss: 0.8079 - val_accuracy: 0.5148\n",
      "Epoch 132/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5132 - val_loss: 0.8078 - val_accuracy: 0.5148\n",
      "Epoch 133/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5134 - val_loss: 0.8077 - val_accuracy: 0.5148\n",
      "Epoch 134/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 0.8077 - val_accuracy: 0.5148\n",
      "Epoch 135/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 0.8076 - val_accuracy: 0.5148\n",
      "Epoch 136/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 0.8075 - val_accuracy: 0.5148\n",
      "Epoch 137/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 0.8076 - val_accuracy: 0.5148\n",
      "Epoch 138/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 0.8075 - val_accuracy: 0.5148\n",
      "Epoch 139/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 0.8073 - val_accuracy: 0.5148\n",
      "Epoch 140/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 0.8076 - val_accuracy: 0.5148\n",
      "Epoch 141/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 0.8074 - val_accuracy: 0.5148\n",
      "Epoch 142/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.8072 - val_accuracy: 0.5148\n",
      "Epoch 143/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.8069 - val_accuracy: 0.5148\n",
      "Epoch 144/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 0.8073 - val_accuracy: 0.5148\n",
      "Epoch 145/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 0.8070 - val_accuracy: 0.5148\n",
      "Epoch 146/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.8070 - val_accuracy: 0.5148\n",
      "Epoch 147/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 0.8071 - val_accuracy: 0.5148\n",
      "Epoch 148/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 0.8065 - val_accuracy: 0.5148\n",
      "Epoch 149/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 0.8063 - val_accuracy: 0.5148\n",
      "Epoch 150/500\n",
      "8967/8967 [==============================] - 1s 60us/step - loss: 0.6914 - accuracy: 0.5135 - val_loss: 0.8064 - val_accuracy: 0.5148\n",
      "Epoch 151/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 0.8063 - val_accuracy: 0.5148\n",
      "Epoch 152/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6911 - accuracy: 0.5138 - val_loss: 0.8066 - val_accuracy: 0.5148\n",
      "Epoch 153/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 0.8061 - val_accuracy: 0.5148\n",
      "Epoch 154/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 0.8061 - val_accuracy: 0.5148\n",
      "Epoch 155/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 0.8058 - val_accuracy: 0.5148\n",
      "Epoch 156/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5133 - val_loss: 0.8053 - val_accuracy: 0.5148\n",
      "Epoch 157/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 0.8053 - val_accuracy: 0.5148\n",
      "Epoch 158/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5132 - val_loss: 0.8045 - val_accuracy: 0.5148\n",
      "Epoch 159/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 0.8047 - val_accuracy: 0.5148\n",
      "Epoch 160/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6911 - accuracy: 0.5138 - val_loss: 0.8040 - val_accuracy: 0.5148\n",
      "Epoch 161/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6911 - accuracy: 0.5140 - val_loss: 0.8032 - val_accuracy: 0.5148\n",
      "Epoch 162/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 0.8039 - val_accuracy: 0.5148\n",
      "Epoch 163/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 0.8026 - val_accuracy: 0.5148\n",
      "Epoch 164/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5132 - val_loss: 0.8021 - val_accuracy: 0.5148\n",
      "Epoch 165/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 0.8021 - val_accuracy: 0.5148\n",
      "Epoch 166/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 0.8017 - val_accuracy: 0.5148\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5132 - val_loss: 0.8021 - val_accuracy: 0.5148\n",
      "Epoch 168/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5135 - val_loss: 0.8014 - val_accuracy: 0.5148\n",
      "Epoch 169/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 0.8005 - val_accuracy: 0.5148\n",
      "Epoch 170/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5133 - val_loss: 0.7998 - val_accuracy: 0.5148\n",
      "Epoch 171/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6912 - accuracy: 0.5137 - val_loss: 0.7998 - val_accuracy: 0.5148\n",
      "Epoch 172/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 0.7995 - val_accuracy: 0.5148\n",
      "Epoch 173/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5135 - val_loss: 0.7993 - val_accuracy: 0.5148\n",
      "Epoch 174/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.7981 - val_accuracy: 0.5148\n",
      "Epoch 175/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 0.7975 - val_accuracy: 0.5148\n",
      "Epoch 176/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5128 - val_loss: 0.7969 - val_accuracy: 0.5148\n",
      "Epoch 177/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 0.7964 - val_accuracy: 0.5148\n",
      "Epoch 178/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5135 - val_loss: 0.7961 - val_accuracy: 0.5148\n",
      "Epoch 179/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 0.7959 - val_accuracy: 0.5148\n",
      "Epoch 180/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 0.7950 - val_accuracy: 0.5148\n",
      "Epoch 181/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.7838 - accuracy: 0.5128 - val_loss: 0.7753 - val_accuracy: 0.5146\n",
      "Epoch 182/500\n",
      "8967/8967 [==============================] - 1s 60us/step - loss: 1.6084 - accuracy: 0.5139 - val_loss: 1.3413 - val_accuracy: 0.5148\n",
      "Epoch 183/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6962 - accuracy: 0.5137 - val_loss: 1.0044 - val_accuracy: 0.5148\n",
      "Epoch 184/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0043 - val_accuracy: 0.5148\n",
      "Epoch 185/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0042 - val_accuracy: 0.5148\n",
      "Epoch 186/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0042 - val_accuracy: 0.5148\n",
      "Epoch 187/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0041 - val_accuracy: 0.5148\n",
      "Epoch 188/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0041 - val_accuracy: 0.5148\n",
      "Epoch 189/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5132 - val_loss: 1.0041 - val_accuracy: 0.5148\n",
      "Epoch 190/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.0040 - val_accuracy: 0.5148\n",
      "Epoch 191/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.7173 - accuracy: 0.5135 - val_loss: 1.1608 - val_accuracy: 0.5148\n",
      "Epoch 192/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.1607 - val_accuracy: 0.5148\n",
      "Epoch 193/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.1607 - val_accuracy: 0.5148\n",
      "Epoch 194/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.1606 - val_accuracy: 0.5148\n",
      "Epoch 195/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.1606 - val_accuracy: 0.5148\n",
      "Epoch 196/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1606 - val_accuracy: 0.5148\n",
      "Epoch 197/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.1604 - val_accuracy: 0.5148\n",
      "Epoch 198/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 1.1603 - val_accuracy: 0.5148\n",
      "Epoch 199/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.1602 - val_accuracy: 0.5148\n",
      "Epoch 200/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6922 - accuracy: 0.5129 - val_loss: 1.1599 - val_accuracy: 0.5148\n",
      "Epoch 201/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1596 - val_accuracy: 0.5148\n",
      "Epoch 202/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.1597 - val_accuracy: 0.5148\n",
      "Epoch 203/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1593 - val_accuracy: 0.5148\n",
      "Epoch 204/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1592 - val_accuracy: 0.5148\n",
      "Epoch 205/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1583 - val_accuracy: 0.5148\n",
      "Epoch 206/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.1581 - val_accuracy: 0.5148\n",
      "Epoch 207/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1582 - val_accuracy: 0.5148\n",
      "Epoch 208/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1583 - val_accuracy: 0.5148\n",
      "Epoch 209/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1582 - val_accuracy: 0.5148\n",
      "Epoch 210/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.1579 - val_accuracy: 0.5148\n",
      "Epoch 211/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6920 - accuracy: 0.5129 - val_loss: 1.1577 - val_accuracy: 0.5148\n",
      "Epoch 212/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.1570 - val_accuracy: 0.5148\n",
      "Epoch 213/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1569 - val_accuracy: 0.5148\n",
      "Epoch 214/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5137 - val_loss: 1.1566 - val_accuracy: 0.5148\n",
      "Epoch 215/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1560 - val_accuracy: 0.5148\n",
      "Epoch 216/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.1562 - val_accuracy: 0.5148\n",
      "Epoch 217/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1555 - val_accuracy: 0.5148\n",
      "Epoch 218/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.1563 - val_accuracy: 0.5148\n",
      "Epoch 219/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1551 - val_accuracy: 0.5148\n",
      "Epoch 220/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 1.1553 - val_accuracy: 0.5148\n",
      "Epoch 221/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.1553 - val_accuracy: 0.5148\n",
      "Epoch 222/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.1542 - val_accuracy: 0.5148\n",
      "Epoch 223/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.1530 - val_accuracy: 0.5148\n",
      "Epoch 224/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.1535 - val_accuracy: 0.5148\n",
      "Epoch 225/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 1.1527 - val_accuracy: 0.5148\n",
      "Epoch 226/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6920 - accuracy: 0.5127 - val_loss: 1.1519 - val_accuracy: 0.5148\n",
      "Epoch 227/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.1517 - val_accuracy: 0.5148\n",
      "Epoch 228/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 1.1515 - val_accuracy: 0.5148\n",
      "Epoch 229/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.1502 - val_accuracy: 0.5148\n",
      "Epoch 230/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1498 - val_accuracy: 0.5148\n",
      "Epoch 231/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 1.1489 - val_accuracy: 0.5148\n",
      "Epoch 232/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5139 - val_loss: 1.1492 - val_accuracy: 0.5148\n",
      "Epoch 233/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1477 - val_accuracy: 0.5148\n",
      "Epoch 234/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1463 - val_accuracy: 0.5148\n",
      "Epoch 235/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.1469 - val_accuracy: 0.5148\n",
      "Epoch 236/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6912 - accuracy: 0.5138 - val_loss: 1.1471 - val_accuracy: 0.5148\n",
      "Epoch 237/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 1.1460 - val_accuracy: 0.5148\n",
      "Epoch 238/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 1.1412 - val_accuracy: 0.5148\n",
      "Epoch 239/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.1418 - val_accuracy: 0.5148\n",
      "Epoch 240/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5131 - val_loss: 1.1396 - val_accuracy: 0.5148\n",
      "Epoch 241/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.1366 - val_accuracy: 0.5148\n",
      "Epoch 242/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 1.1385 - val_accuracy: 0.5148\n",
      "Epoch 243/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5135 - val_loss: 1.1368 - val_accuracy: 0.5148\n",
      "Epoch 244/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5131 - val_loss: 1.1348 - val_accuracy: 0.5148\n",
      "Epoch 245/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.1331 - val_accuracy: 0.5148\n",
      "Epoch 246/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5139 - val_loss: 1.1343 - val_accuracy: 0.5148\n",
      "Epoch 247/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.1330 - val_accuracy: 0.5148\n",
      "Epoch 248/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.1340 - val_accuracy: 0.5148\n",
      "Epoch 249/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.1306 - val_accuracy: 0.5148\n",
      "Epoch 250/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 1.1296 - val_accuracy: 0.5148\n",
      "Epoch 251/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.1287 - val_accuracy: 0.5148\n",
      "Epoch 252/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5138 - val_loss: 1.1269 - val_accuracy: 0.5148\n",
      "Epoch 253/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 1.1312 - val_accuracy: 0.5148\n",
      "Epoch 254/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1297 - val_accuracy: 0.5148\n",
      "Epoch 255/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1269 - val_accuracy: 0.5148\n",
      "Epoch 256/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5139 - val_loss: 1.1301 - val_accuracy: 0.5148\n",
      "Epoch 257/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6921 - accuracy: 0.5128 - val_loss: 1.1239 - val_accuracy: 0.5148\n",
      "Epoch 258/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.1230 - val_accuracy: 0.5148\n",
      "Epoch 259/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.1259 - val_accuracy: 0.5148\n",
      "Epoch 260/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.1247 - val_accuracy: 0.5148\n",
      "Epoch 261/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6921 - accuracy: 0.5128 - val_loss: 1.1247 - val_accuracy: 0.5148\n",
      "Epoch 262/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.1208 - val_accuracy: 0.5148\n",
      "Epoch 263/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1183 - val_accuracy: 0.5148\n",
      "Epoch 264/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1146 - val_accuracy: 0.5148\n",
      "Epoch 265/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5139 - val_loss: 1.1148 - val_accuracy: 0.5148\n",
      "Epoch 266/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5141 - val_loss: 1.1147 - val_accuracy: 0.5148\n",
      "Epoch 267/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.1139 - val_accuracy: 0.5148\n",
      "Epoch 268/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.1149 - val_accuracy: 0.5148\n",
      "Epoch 269/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1137 - val_accuracy: 0.5148\n",
      "Epoch 270/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1110 - val_accuracy: 0.5148\n",
      "Epoch 271/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6920 - accuracy: 0.5128 - val_loss: 1.1130 - val_accuracy: 0.5148\n",
      "Epoch 272/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.1117 - val_accuracy: 0.5148\n",
      "Epoch 273/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.1112 - val_accuracy: 0.5148\n",
      "Epoch 274/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.1065 - val_accuracy: 0.5148\n",
      "Epoch 275/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1069 - val_accuracy: 0.5148\n",
      "Epoch 276/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.1068 - val_accuracy: 0.5148\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.1025 - val_accuracy: 0.5148\n",
      "Epoch 278/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.1025 - val_accuracy: 0.5148\n",
      "Epoch 279/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.1028 - val_accuracy: 0.5148\n",
      "Epoch 280/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.1022 - val_accuracy: 0.5148\n",
      "Epoch 281/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.1001 - val_accuracy: 0.5148\n",
      "Epoch 282/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6920 - accuracy: 0.5130 - val_loss: 1.0957 - val_accuracy: 0.5148\n",
      "Epoch 283/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6914 - accuracy: 0.5135 - val_loss: 1.0955 - val_accuracy: 0.5148\n",
      "Epoch 284/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5133 - val_loss: 1.0942 - val_accuracy: 0.5148\n",
      "Epoch 285/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6922 - accuracy: 0.5127 - val_loss: 1.0939 - val_accuracy: 0.5148\n",
      "Epoch 286/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 1.0895 - val_accuracy: 0.5148\n",
      "Epoch 287/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 1.0904 - val_accuracy: 0.5148\n",
      "Epoch 288/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0880 - val_accuracy: 0.5148\n",
      "Epoch 289/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5135 - val_loss: 1.0878 - val_accuracy: 0.5148\n",
      "Epoch 290/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0876 - val_accuracy: 0.5148\n",
      "Epoch 291/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0851 - val_accuracy: 0.5148\n",
      "Epoch 292/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.0843 - val_accuracy: 0.5148\n",
      "Epoch 293/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.0829 - val_accuracy: 0.5148\n",
      "Epoch 294/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0834 - val_accuracy: 0.5148\n",
      "Epoch 295/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0832 - val_accuracy: 0.5148\n",
      "Epoch 296/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0817 - val_accuracy: 0.5148\n",
      "Epoch 297/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0812 - val_accuracy: 0.5148\n",
      "Epoch 298/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.0812 - val_accuracy: 0.5148\n",
      "Epoch 299/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.0809 - val_accuracy: 0.5148\n",
      "Epoch 300/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5139 - val_loss: 1.0805 - val_accuracy: 0.5148\n",
      "Epoch 301/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 1.0797 - val_accuracy: 0.5148\n",
      "Epoch 302/500\n",
      "8967/8967 [==============================] - 1s 60us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0806 - val_accuracy: 0.5148\n",
      "Epoch 303/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6911 - accuracy: 0.5140 - val_loss: 1.0794 - val_accuracy: 0.5148\n",
      "Epoch 304/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5139 - val_loss: 1.0788 - val_accuracy: 0.5148\n",
      "Epoch 305/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.0786 - val_accuracy: 0.5148\n",
      "Epoch 306/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0783 - val_accuracy: 0.5148\n",
      "Epoch 307/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6919 - accuracy: 0.5132 - val_loss: 1.0778 - val_accuracy: 0.5148\n",
      "Epoch 308/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0771 - val_accuracy: 0.5148\n",
      "Epoch 309/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.0775 - val_accuracy: 0.5148\n",
      "Epoch 310/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0757 - val_accuracy: 0.5148\n",
      "Epoch 311/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0755 - val_accuracy: 0.5148\n",
      "Epoch 312/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0742 - val_accuracy: 0.5148\n",
      "Epoch 313/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0737 - val_accuracy: 0.5148\n",
      "Epoch 314/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0730 - val_accuracy: 0.5148\n",
      "Epoch 315/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0722 - val_accuracy: 0.5148\n",
      "Epoch 316/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0719 - val_accuracy: 0.5148\n",
      "Epoch 317/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0709 - val_accuracy: 0.5148\n",
      "Epoch 318/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0704 - val_accuracy: 0.5148\n",
      "Epoch 319/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0705 - val_accuracy: 0.5148\n",
      "Epoch 320/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0694 - val_accuracy: 0.5148\n",
      "Epoch 321/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0691 - val_accuracy: 0.5148\n",
      "Epoch 322/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5138 - val_loss: 1.0686 - val_accuracy: 0.5148\n",
      "Epoch 323/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0679 - val_accuracy: 0.5148\n",
      "Epoch 324/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0677 - val_accuracy: 0.5148\n",
      "Epoch 325/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0675 - val_accuracy: 0.5148\n",
      "Epoch 326/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0672 - val_accuracy: 0.5148\n",
      "Epoch 327/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0670 - val_accuracy: 0.5148\n",
      "Epoch 328/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0669 - val_accuracy: 0.5148\n",
      "Epoch 329/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 330/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 331/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5139 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 333/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 334/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 335/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5139 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 336/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 337/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 338/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 1.0667 - val_accuracy: 0.5148\n",
      "Epoch 339/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5139 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 340/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 341/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 342/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 343/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 344/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 345/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 346/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 347/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 348/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 349/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 350/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 351/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 352/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 353/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6912 - accuracy: 0.5141 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 354/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 355/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 356/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 357/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 358/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6912 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 359/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6920 - accuracy: 0.5129 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 360/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 361/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 362/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 363/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5139 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 364/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 365/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6919 - accuracy: 0.5129 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 366/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 367/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 368/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 369/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 370/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 371/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 372/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 373/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5139 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 374/500\n",
      "8967/8967 [==============================] - 1s 60us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 375/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6911 - accuracy: 0.5140 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 376/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 377/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6920 - accuracy: 0.5130 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 378/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 379/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 380/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 381/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 382/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 383/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 384/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 385/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 386/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 388/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 389/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 390/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 391/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 392/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 393/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 394/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6911 - accuracy: 0.5141 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 395/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 396/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 397/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 398/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 399/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 400/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 401/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 402/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 403/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 404/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6915 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 405/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6920 - accuracy: 0.5130 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 406/500\n",
      "8967/8967 [==============================] - 1s 61us/step - loss: 0.6919 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 407/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 408/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 409/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 410/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 411/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 412/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 413/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 414/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 415/500\n",
      "8967/8967 [==============================] - 1s 62us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 416/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 417/500\n",
      "8967/8967 [==============================] - 1s 69us/step - loss: 0.6912 - accuracy: 0.5140 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 418/500\n",
      "8967/8967 [==============================] - 1s 73us/step - loss: 0.6915 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 419/500\n",
      "8967/8967 [==============================] - 1s 73us/step - loss: 0.6914 - accuracy: 0.5139 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 420/500\n",
      "8967/8967 [==============================] - 1s 68us/step - loss: 0.6913 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 421/500\n",
      "8967/8967 [==============================] - 1s 71us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 422/500\n",
      "8967/8967 [==============================] - 1s 72us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 423/500\n",
      "8967/8967 [==============================] - 1s 72us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 424/500\n",
      "8967/8967 [==============================] - 1s 72us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 425/500\n",
      "8967/8967 [==============================] - 1s 74us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 426/500\n",
      "8967/8967 [==============================] - 1s 72us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 427/500\n",
      "8967/8967 [==============================] - 1s 74us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 428/500\n",
      "8967/8967 [==============================] - 1s 74us/step - loss: 0.6919 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 429/500\n",
      "8967/8967 [==============================] - 1s 68us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 430/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 431/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 432/500\n",
      "8967/8967 [==============================] - 1s 68us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 433/500\n",
      "8967/8967 [==============================] - 1s 68us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 434/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.6920 - accuracy: 0.5130 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 435/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 436/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 437/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 438/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6920 - accuracy: 0.5130 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 439/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 440/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 441/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 442/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6920 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 443/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 444/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 445/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 446/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 447/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 448/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5139 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 449/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 450/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 451/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.6912 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 452/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 453/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 454/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 455/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 456/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 457/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 458/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 459/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 460/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 461/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 462/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6911 - accuracy: 0.5139 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 463/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 464/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 465/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 466/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 467/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6915 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 468/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 469/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6919 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 470/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 471/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 472/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5132 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 473/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 1.0669 - val_accuracy: 0.5148\n",
      "Epoch 474/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6913 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 475/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6919 - accuracy: 0.5129 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 476/500\n",
      "8967/8967 [==============================] - 1s 67us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 477/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 478/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 479/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 480/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 481/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 482/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 483/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6919 - accuracy: 0.5130 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 484/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 485/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6914 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 486/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 487/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 488/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5137 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 489/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6913 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 490/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 491/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 492/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5133 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 493/500\n",
      "8967/8967 [==============================] - 1s 65us/step - loss: 0.6914 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 494/500\n",
      "8967/8967 [==============================] - 1s 66us/step - loss: 0.6915 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 495/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 496/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6917 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 498/500\n",
      "8967/8967 [==============================] - 1s 63us/step - loss: 0.6912 - accuracy: 0.5139 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 499/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6918 - accuracy: 0.5134 - val_loss: 1.0668 - val_accuracy: 0.5148\n",
      "Epoch 500/500\n",
      "8967/8967 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5135 - val_loss: 1.0668 - val_accuracy: 0.5148\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, y_train, epochs=300, batch_size=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3844/3844 [==============================] - 0s 44us/step\n",
      "Test accuracy:  0.5148283243179321\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
