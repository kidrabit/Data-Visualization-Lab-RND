{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "EEG = genfromtxt(\"C:/Users/SoobinYim/workspace/Confusion during MOOC/EEG_data.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6의 raw데이터에 이상이 있으므로 6을 제외하고 분석\n",
    "EEG=EEG[1:,:]\n",
    "EEG=pd.DataFrame(EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12811, 15) (1275,)\n"
     ]
    }
   ],
   "source": [
    "remove_6=EEG[EEG[0]==6].index\n",
    "print(EEG.shape, remove_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11536, 15)\n"
     ]
    }
   ],
   "source": [
    "EEG=EEG.drop(remove_6)\n",
    "print(EEG.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG=EEG.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11536, 15) (11536,)\n"
     ]
    }
   ],
   "source": [
    "X=EEG\n",
    "y = EEG[:, -1]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1      4          5         6         7        8        9         10  \\\n",
       "0  0.0  278.0   301963.0   90612.0   33735.0  23991.0  27946.0   45097.0   \n",
       "1  0.0  -50.0    73787.0   28083.0    1439.0   2240.0   2746.0    3687.0   \n",
       "2  0.0  101.0   758353.0  383745.0  201999.0  62107.0  36293.0  130536.0   \n",
       "3  0.0   -5.0  2012240.0  129350.0   61236.0  17084.0  11488.0   62462.0   \n",
       "4  0.0   -8.0  1005145.0  354328.0   37102.0  88881.0  45307.0   99603.0   \n",
       "\n",
       "        11       12  \n",
       "0  33228.0   8293.0  \n",
       "1   5293.0   2740.0  \n",
       "2  57243.0  25354.0  \n",
       "3  49960.0  33932.0  \n",
       "4  44790.0  29749.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#동영상, raw, 주파수 data 사용\n",
    "X1=pd.DataFrame(X)\n",
    "X1=X1.drop(X1.columns[[0,2,3,13,14]], axis='columns')\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      4          5         6         7        8        9         10  \\\n",
       "0  0.0  278.0   301963.0   90612.0   33735.0  23991.0  27946.0   45097.0   \n",
       "1  0.0  -50.0    73787.0   28083.0    1439.0   2240.0   2746.0    3687.0   \n",
       "2  0.0  101.0   758353.0  383745.0  201999.0  62107.0  36293.0  130536.0   \n",
       "3  0.0   -5.0  2012240.0  129350.0   61236.0  17084.0  11488.0   62462.0   \n",
       "4  0.0   -8.0  1005145.0  354328.0   37102.0  88881.0  45307.0   99603.0   \n",
       "\n",
       "        11       12  \n",
       "0  33228.0   8293.0  \n",
       "1   5293.0   2740.0  \n",
       "2  57243.0  25354.0  \n",
       "3  49960.0  33932.0  \n",
       "4  44790.0  29749.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#사람 정보, raw, 주파수 data 사용\n",
    "X2=pd.DataFrame(X)\n",
    "X2=X2.drop(X2.columns[[1,2,3,13,14]], axis='columns')\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1          5         6         7        8        9         10       11  \\\n",
       "0  0.0   301963.0   90612.0   33735.0  23991.0  27946.0   45097.0  33228.0   \n",
       "1  0.0    73787.0   28083.0    1439.0   2240.0   2746.0    3687.0   5293.0   \n",
       "2  0.0   758353.0  383745.0  201999.0  62107.0  36293.0  130536.0  57243.0   \n",
       "3  0.0  2012240.0  129350.0   61236.0  17084.0  11488.0   62462.0  49960.0   \n",
       "4  0.0  1005145.0  354328.0   37102.0  88881.0  45307.0   99603.0  44790.0   \n",
       "\n",
       "        12  \n",
       "0   8293.0  \n",
       "1   2740.0  \n",
       "2  25354.0  \n",
       "3  33932.0  \n",
       "4  29749.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#동영상, raw, 주파수 data 사용\n",
    "X3=pd.DataFrame(X)\n",
    "X3=X3.drop(X3.columns[[0,2,3,4,13,14]], axis='columns')\n",
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0          5         6         7        8        9         10       11  \\\n",
       "0  0.0   301963.0   90612.0   33735.0  23991.0  27946.0   45097.0  33228.0   \n",
       "1  0.0    73787.0   28083.0    1439.0   2240.0   2746.0    3687.0   5293.0   \n",
       "2  0.0   758353.0  383745.0  201999.0  62107.0  36293.0  130536.0  57243.0   \n",
       "3  0.0  2012240.0  129350.0   61236.0  17084.0  11488.0   62462.0  49960.0   \n",
       "4  0.0  1005145.0  354328.0   37102.0  88881.0  45307.0   99603.0  44790.0   \n",
       "\n",
       "        12  \n",
       "0   8293.0  \n",
       "1   2740.0  \n",
       "2  25354.0  \n",
       "3  33932.0  \n",
       "4  29749.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#사람 정보, 주파수 data 사용\n",
    "X4=pd.DataFrame(X)\n",
    "X4=X4.drop(X4.columns[[1,2,3,4,13,14]], axis='columns')\n",
    "X4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X1.values\n",
    "X2=X2.values\n",
    "X3=X3.values\n",
    "X4=X4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=X1\n",
    "X=X2\n",
    "#X=X3\n",
    "#X=X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8075, 10) (3461, 10) (8075,) (3461,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=14)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8075, 2) (3461, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils as np_utils\n",
    "#one-hot encoding\n",
    "y_train      = np_utils.to_categorical(y_train)\n",
    "y_test       = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Input, Reshape, Activation, add, Add\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(eeg_data):\n",
    "    eeg_input=Input(shape=(10,)) #입력 정의\n",
    "    \n",
    "    eeg_output = Dense(50, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(150, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(150, activation='relu')(eeg_input)\n",
    "    eeg_output = Dropout(0.5)(eeg_output)\n",
    "    eeg_output = Dense(200, activation='relu')(eeg_output)\n",
    "    \n",
    "    model = Dense(2, activation='sigmoid')(eeg_output)\n",
    "    \n",
    "    model = keras.models.Model(inputs=eeg_input, outputs=model) \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 150)               1650      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 32,252\n",
      "Trainable params: 32,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_create(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8075 samples, validate on 3461 samples\n",
      "Epoch 1/150\n",
      "8075/8075 [==============================] - 1s 83us/step - loss: 7979.4543 - accuracy: 0.5130 - val_loss: 1976.9997 - val_accuracy: 0.5059\n",
      "Epoch 2/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 3279.5767 - accuracy: 0.5130 - val_loss: 2531.2187 - val_accuracy: 0.5092\n",
      "Epoch 3/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 1930.5650 - accuracy: 0.5028 - val_loss: 995.5533 - val_accuracy: 0.5182\n",
      "Epoch 4/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 1079.0325 - accuracy: 0.5041 - val_loss: 520.5965 - val_accuracy: 0.5006\n",
      "Epoch 5/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 527.6069 - accuracy: 0.5154 - val_loss: 109.8714 - val_accuracy: 0.5130\n",
      "Epoch 6/150\n",
      "8075/8075 [==============================] - 1s 70us/step - loss: 259.8587 - accuracy: 0.5178 - val_loss: 55.9520 - val_accuracy: 0.5225\n",
      "Epoch 7/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 113.2658 - accuracy: 0.5215 - val_loss: 26.8197 - val_accuracy: 0.5259\n",
      "Epoch 8/150\n",
      "8075/8075 [==============================] - 1s 72us/step - loss: 38.4299 - accuracy: 0.5134 - val_loss: 12.4576 - val_accuracy: 0.5451\n",
      "Epoch 9/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 16.4777 - accuracy: 0.5065 - val_loss: 7.4471 - val_accuracy: 0.5202\n",
      "Epoch 10/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 9.5658 - accuracy: 0.5006 - val_loss: 5.4494 - val_accuracy: 0.4893\n",
      "Epoch 11/150\n",
      "8075/8075 [==============================] - 1s 71us/step - loss: 7.9834 - accuracy: 0.4926 - val_loss: 5.1793 - val_accuracy: 0.5092\n",
      "Epoch 12/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 4.9462 - accuracy: 0.4895 - val_loss: 4.1044 - val_accuracy: 0.4883\n",
      "Epoch 13/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 3.1210 - accuracy: 0.4911 - val_loss: 3.0600 - val_accuracy: 0.5033\n",
      "Epoch 14/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 2.9478 - accuracy: 0.4928 - val_loss: 3.3046 - val_accuracy: 0.5033\n",
      "Epoch 15/150\n",
      "8075/8075 [==============================] - 1s 80us/step - loss: 3.3692 - accuracy: 0.5063 - val_loss: 2.5010 - val_accuracy: 0.5134\n",
      "Epoch 16/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 2.4976 - accuracy: 0.5163 - val_loss: 3.0306 - val_accuracy: 0.4994\n",
      "Epoch 17/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 1.7138 - accuracy: 0.5218 - val_loss: 3.1631 - val_accuracy: 0.5159\n",
      "Epoch 18/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 2.2877 - accuracy: 0.5213 - val_loss: 1.7177 - val_accuracy: 0.5156\n",
      "Epoch 19/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 1.9894 - accuracy: 0.5258 - val_loss: 1.7867 - val_accuracy: 0.5134\n",
      "Epoch 20/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 1.4744 - accuracy: 0.5214 - val_loss: 1.5184 - val_accuracy: 0.5166\n",
      "Epoch 21/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 1.4004 - accuracy: 0.5212 - val_loss: 2.0488 - val_accuracy: 0.5173\n",
      "Epoch 22/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 1.2157 - accuracy: 0.5203 - val_loss: 1.6756 - val_accuracy: 0.5150\n",
      "Epoch 23/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 1.3858 - accuracy: 0.5211 - val_loss: 1.5263 - val_accuracy: 0.5185\n",
      "Epoch 24/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 1.0401 - accuracy: 0.5228 - val_loss: 1.2535 - val_accuracy: 0.5186\n",
      "Epoch 25/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 1.0142 - accuracy: 0.5212 - val_loss: 1.4843 - val_accuracy: 0.5182\n",
      "Epoch 26/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 1.1260 - accuracy: 0.5209 - val_loss: 1.4551 - val_accuracy: 0.5192\n",
      "Epoch 27/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.9630 - accuracy: 0.5232 - val_loss: 1.5724 - val_accuracy: 0.5179\n",
      "Epoch 28/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 1.0336 - accuracy: 0.5196 - val_loss: 1.4952 - val_accuracy: 0.5181\n",
      "Epoch 29/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.9055 - accuracy: 0.5207 - val_loss: 0.9950 - val_accuracy: 0.5191\n",
      "Epoch 30/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.8070 - accuracy: 0.5196 - val_loss: 1.1651 - val_accuracy: 0.5175\n",
      "Epoch 31/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.8478 - accuracy: 0.5191 - val_loss: 1.0423 - val_accuracy: 0.5181\n",
      "Epoch 32/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.8362 - accuracy: 0.5192 - val_loss: 0.9145 - val_accuracy: 0.5176\n",
      "Epoch 33/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.8324 - accuracy: 0.5192 - val_loss: 0.8932 - val_accuracy: 0.5175\n",
      "Epoch 34/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.9442 - accuracy: 0.5186 - val_loss: 0.9412 - val_accuracy: 0.5159\n",
      "Epoch 35/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.8195 - accuracy: 0.5199 - val_loss: 0.8936 - val_accuracy: 0.5175\n",
      "Epoch 36/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.7768 - accuracy: 0.5178 - val_loss: 0.9148 - val_accuracy: 0.5170\n",
      "Epoch 37/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.7359 - accuracy: 0.5185 - val_loss: 1.0957 - val_accuracy: 0.5179\n",
      "Epoch 38/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.7382 - accuracy: 0.5173 - val_loss: 0.9892 - val_accuracy: 0.5169\n",
      "Epoch 39/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 1.0198 - accuracy: 0.5170 - val_loss: 0.8667 - val_accuracy: 0.5168\n",
      "Epoch 40/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6986 - accuracy: 0.5180 - val_loss: 0.8747 - val_accuracy: 0.5165\n",
      "Epoch 41/150\n",
      "8075/8075 [==============================] - 1s 72us/step - loss: 0.7080 - accuracy: 0.5181 - val_loss: 0.8049 - val_accuracy: 0.5162\n",
      "Epoch 42/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6970 - accuracy: 0.5181 - val_loss: 0.7686 - val_accuracy: 0.5159\n",
      "Epoch 43/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.7369 - accuracy: 0.5175 - val_loss: 0.7892 - val_accuracy: 0.5160\n",
      "Epoch 44/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.7039 - accuracy: 0.5176 - val_loss: 0.7833 - val_accuracy: 0.5155\n",
      "Epoch 45/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6932 - accuracy: 0.5170 - val_loss: 0.7756 - val_accuracy: 0.5157\n",
      "Epoch 46/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.7755 - val_accuracy: 0.5157\n",
      "Epoch 47/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6958 - accuracy: 0.5172 - val_loss: 0.7742 - val_accuracy: 0.5152\n",
      "Epoch 48/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6928 - accuracy: 0.5172 - val_loss: 0.7746 - val_accuracy: 0.5150\n",
      "Epoch 49/150\n",
      "8075/8075 [==============================] - 1s 72us/step - loss: 0.6936 - accuracy: 0.5173 - val_loss: 0.7764 - val_accuracy: 0.5146\n",
      "Epoch 50/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.7143 - accuracy: 0.5172 - val_loss: 0.7705 - val_accuracy: 0.5152\n",
      "Epoch 51/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6912 - accuracy: 0.5178 - val_loss: 0.7719 - val_accuracy: 0.5147\n",
      "Epoch 52/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6943 - accuracy: 0.5167 - val_loss: 0.7760 - val_accuracy: 0.5149\n",
      "Epoch 53/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6902 - accuracy: 0.5176 - val_loss: 0.7736 - val_accuracy: 0.5150\n",
      "Epoch 54/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6933 - accuracy: 0.5170 - val_loss: 0.7739 - val_accuracy: 0.5139\n",
      "Epoch 55/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 0.6910 - accuracy: 0.5169 - val_loss: 0.7739 - val_accuracy: 0.5140\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6915 - accuracy: 0.5175 - val_loss: 0.7737 - val_accuracy: 0.5140\n",
      "Epoch 57/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6905 - accuracy: 0.5177 - val_loss: 0.7691 - val_accuracy: 0.5144\n",
      "Epoch 58/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6898 - accuracy: 0.5178 - val_loss: 0.7638 - val_accuracy: 0.5144\n",
      "Epoch 59/150\n",
      "8075/8075 [==============================] - 1s 72us/step - loss: 0.6938 - accuracy: 0.5174 - val_loss: 0.7792 - val_accuracy: 0.5140\n",
      "Epoch 60/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6900 - accuracy: 0.5173 - val_loss: 0.7805 - val_accuracy: 0.5140\n",
      "Epoch 61/150\n",
      "8075/8075 [==============================] - 1s 74us/step - loss: 0.6900 - accuracy: 0.5178 - val_loss: 0.7805 - val_accuracy: 0.5139\n",
      "Epoch 62/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6923 - accuracy: 0.5172 - val_loss: 0.7867 - val_accuracy: 0.5139\n",
      "Epoch 63/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6907 - accuracy: 0.5171 - val_loss: 0.7882 - val_accuracy: 0.5137\n",
      "Epoch 64/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6902 - accuracy: 0.5172 - val_loss: 0.7887 - val_accuracy: 0.5137\n",
      "Epoch 65/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6960 - accuracy: 0.5172 - val_loss: 0.7860 - val_accuracy: 0.5139\n",
      "Epoch 66/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6901 - accuracy: 0.5172 - val_loss: 0.7861 - val_accuracy: 0.5139\n",
      "Epoch 67/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6900 - accuracy: 0.5173 - val_loss: 0.7857 - val_accuracy: 0.5142\n",
      "Epoch 68/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.7017 - accuracy: 0.5174 - val_loss: 0.7917 - val_accuracy: 0.5140\n",
      "Epoch 69/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6948 - accuracy: 0.5170 - val_loss: 0.7922 - val_accuracy: 0.5137\n",
      "Epoch 70/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6905 - accuracy: 0.5169 - val_loss: 0.7921 - val_accuracy: 0.5137\n",
      "Epoch 71/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6970 - accuracy: 0.5165 - val_loss: 0.7893 - val_accuracy: 0.5136\n",
      "Epoch 72/150\n",
      "8075/8075 [==============================] - 1s 73us/step - loss: 0.6905 - accuracy: 0.5169 - val_loss: 0.7895 - val_accuracy: 0.5136\n",
      "Epoch 73/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6905 - accuracy: 0.5168 - val_loss: 0.7894 - val_accuracy: 0.5136\n",
      "Epoch 74/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6901 - accuracy: 0.5172 - val_loss: 0.7895 - val_accuracy: 0.5133\n",
      "Epoch 75/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6905 - accuracy: 0.5168 - val_loss: 0.7897 - val_accuracy: 0.5133\n",
      "Epoch 76/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6905 - accuracy: 0.5168 - val_loss: 1.3540 - val_accuracy: 0.5134\n",
      "Epoch 77/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.7049 - accuracy: 0.5170 - val_loss: 0.7857 - val_accuracy: 0.5130\n",
      "Epoch 78/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6929 - accuracy: 0.5169 - val_loss: 0.8621 - val_accuracy: 0.5131\n",
      "Epoch 79/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6946 - accuracy: 0.5162 - val_loss: 0.8088 - val_accuracy: 0.5140\n",
      "Epoch 80/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6945 - accuracy: 0.5174 - val_loss: 0.7976 - val_accuracy: 0.5137\n",
      "Epoch 81/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6905 - accuracy: 0.5168 - val_loss: 0.8037 - val_accuracy: 0.5137\n",
      "Epoch 82/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 0.6970 - accuracy: 0.5162 - val_loss: 0.7678 - val_accuracy: 0.5136\n",
      "Epoch 83/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 0.6945 - accuracy: 0.5168 - val_loss: 0.8090 - val_accuracy: 0.5131\n",
      "Epoch 84/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.7018 - accuracy: 0.5166 - val_loss: 0.7707 - val_accuracy: 0.5133\n",
      "Epoch 85/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6911 - accuracy: 0.5161 - val_loss: 0.7679 - val_accuracy: 0.5133\n",
      "Epoch 86/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6907 - accuracy: 0.5167 - val_loss: 0.7679 - val_accuracy: 0.5133\n",
      "Epoch 87/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6911 - accuracy: 0.5162 - val_loss: 0.7678 - val_accuracy: 0.5133\n",
      "Epoch 88/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6911 - accuracy: 0.5162 - val_loss: 0.7679 - val_accuracy: 0.5133\n",
      "Epoch 89/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6913 - accuracy: 0.5159 - val_loss: 0.7679 - val_accuracy: 0.5133\n",
      "Epoch 90/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6913 - accuracy: 0.5158 - val_loss: 0.7678 - val_accuracy: 0.5133\n",
      "Epoch 91/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6909 - accuracy: 0.5163 - val_loss: 0.7677 - val_accuracy: 0.5133\n",
      "Epoch 92/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6907 - accuracy: 0.5164 - val_loss: 0.7677 - val_accuracy: 0.5133\n",
      "Epoch 93/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6904 - accuracy: 0.5168 - val_loss: 0.7677 - val_accuracy: 0.5133\n",
      "Epoch 94/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6904 - accuracy: 0.5168 - val_loss: 0.7677 - val_accuracy: 0.5133\n",
      "Epoch 95/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6907 - accuracy: 0.5164 - val_loss: 0.7677 - val_accuracy: 0.5133\n",
      "Epoch 96/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6910 - accuracy: 0.5163 - val_loss: 0.7676 - val_accuracy: 0.5133\n",
      "Epoch 97/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.7607 - accuracy: 0.5163 - val_loss: 0.7468 - val_accuracy: 0.5136\n",
      "Epoch 98/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.7041 - accuracy: 0.5161 - val_loss: 0.7452 - val_accuracy: 0.5130\n",
      "Epoch 99/150\n",
      "8075/8075 [==============================] - 1s 71us/step - loss: 0.7024 - accuracy: 0.5152 - val_loss: 0.7468 - val_accuracy: 0.5136\n",
      "Epoch 100/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5153 - val_loss: 0.7425 - val_accuracy: 0.5133\n",
      "Epoch 101/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6931 - accuracy: 0.5150 - val_loss: 0.7614 - val_accuracy: 0.5134\n",
      "Epoch 102/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6919 - accuracy: 0.5153 - val_loss: 0.7614 - val_accuracy: 0.5134\n",
      "Epoch 103/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 0.6915 - accuracy: 0.5155 - val_loss: 0.7614 - val_accuracy: 0.5134\n",
      "Epoch 104/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5155 - val_loss: 0.7614 - val_accuracy: 0.5134\n",
      "Epoch 105/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6917 - accuracy: 0.5155 - val_loss: 0.7614 - val_accuracy: 0.5134\n",
      "Epoch 106/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 0.6914 - accuracy: 0.5157 - val_loss: 0.7614 - val_accuracy: 0.5134\n",
      "Epoch 107/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6916 - accuracy: 0.5154 - val_loss: 0.7624 - val_accuracy: 0.5134\n",
      "Epoch 108/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6927 - accuracy: 0.5153 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 109/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6917 - accuracy: 0.5155 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 110/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6916 - accuracy: 0.5155 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 111/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6917 - accuracy: 0.5154 - val_loss: 0.7616 - val_accuracy: 0.5134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6917 - accuracy: 0.5154 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 113/150\n",
      "8075/8075 [==============================] - 1s 62us/step - loss: 0.6913 - accuracy: 0.5155 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 114/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6915 - accuracy: 0.5157 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 115/150\n",
      "8075/8075 [==============================] - 1s 68us/step - loss: 0.6918 - accuracy: 0.5157 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 116/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5155 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 117/150\n",
      "8075/8075 [==============================] - 1s 71us/step - loss: 0.6915 - accuracy: 0.5154 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 118/150\n",
      "8075/8075 [==============================] - 1s 72us/step - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 119/150\n",
      "8075/8075 [==============================] - 1s 69us/step - loss: 0.6915 - accuracy: 0.5155 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 120/150\n",
      "8075/8075 [==============================] - 1s 67us/step - loss: 0.6919 - accuracy: 0.5152 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 121/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6915 - accuracy: 0.5157 - val_loss: 0.7616 - val_accuracy: 0.5134\n",
      "Epoch 122/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 123/150\n",
      "8075/8075 [==============================] - 1s 62us/step - loss: 0.6917 - accuracy: 0.5153 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 124/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6917 - accuracy: 0.5152 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 125/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6919 - accuracy: 0.5150 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 126/150\n",
      "8075/8075 [==============================] - 1s 66us/step - loss: 0.6919 - accuracy: 0.5153 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 127/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5154 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 128/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5153 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 129/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.7618 - val_accuracy: 0.5134\n",
      "Epoch 130/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5158 - val_loss: 0.7617 - val_accuracy: 0.5134\n",
      "Epoch 131/150\n",
      "8075/8075 [==============================] - 1s 65us/step - loss: 0.6919 - accuracy: 0.5152 - val_loss: 0.7618 - val_accuracy: 0.5134\n",
      "Epoch 132/150\n",
      "8075/8075 [==============================] - 0s 62us/step - loss: 0.6915 - accuracy: 0.5155 - val_loss: 0.7618 - val_accuracy: 0.5134\n",
      "Epoch 133/150\n",
      "8075/8075 [==============================] - 0s 62us/step - loss: 0.6912 - accuracy: 0.5159 - val_loss: 0.7618 - val_accuracy: 0.5134\n",
      "Epoch 134/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5158 - val_loss: 0.7618 - val_accuracy: 0.5134\n",
      "Epoch 135/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6917 - accuracy: 0.5154 - val_loss: 0.7618 - val_accuracy: 0.5134\n",
      "Epoch 136/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6919 - accuracy: 0.5153 - val_loss: 0.7618 - val_accuracy: 0.5134\n",
      "Epoch 137/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5155 - val_loss: 0.7619 - val_accuracy: 0.5134\n",
      "Epoch 138/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5152 - val_loss: 0.7619 - val_accuracy: 0.5134\n",
      "Epoch 139/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5157 - val_loss: 0.7619 - val_accuracy: 0.5134\n",
      "Epoch 140/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.7620 - val_accuracy: 0.5134\n",
      "Epoch 141/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6916 - accuracy: 0.5155 - val_loss: 0.7620 - val_accuracy: 0.5134\n",
      "Epoch 142/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5158 - val_loss: 0.7620 - val_accuracy: 0.5134\n",
      "Epoch 143/150\n",
      "8075/8075 [==============================] - 1s 62us/step - loss: 0.6921 - accuracy: 0.5153 - val_loss: 0.7621 - val_accuracy: 0.5134\n",
      "Epoch 144/150\n",
      "8075/8075 [==============================] - 1s 64us/step - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.7621 - val_accuracy: 0.5134\n",
      "Epoch 145/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6914 - accuracy: 0.5158 - val_loss: 0.7622 - val_accuracy: 0.5134\n",
      "Epoch 146/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5154 - val_loss: 0.7623 - val_accuracy: 0.5134\n",
      "Epoch 147/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6919 - accuracy: 0.5152 - val_loss: 0.7624 - val_accuracy: 0.5136\n",
      "Epoch 148/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6915 - accuracy: 0.5157 - val_loss: 0.7625 - val_accuracy: 0.5136\n",
      "Epoch 149/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.7627 - val_accuracy: 0.5137\n",
      "Epoch 150/150\n",
      "8075/8075 [==============================] - 1s 63us/step - loss: 0.6916 - accuracy: 0.5158 - val_loss: 0.7628 - val_accuracy: 0.5137\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, y_train, epochs=150, batch_size=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3461/3461 [==============================] - 0s 45us/step\n",
      "Test accuracy:  0.5137243866920471\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
