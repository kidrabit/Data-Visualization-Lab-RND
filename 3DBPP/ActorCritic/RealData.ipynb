{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc19087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, concatenate, Conv2D, MaxPooling2D\n",
    "\n",
    "from libs.utils import *\n",
    "from libs.generate_boxes import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.keras.backend.floatx()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbfeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_box(sizes,positions,fs=(10,5), title=''):\n",
    "    colors = get_colors(len(positions))\n",
    "    plt.figure('SPLTV', figsize=(15,5))\n",
    "    #ax = fig.gca(projection='3d')\n",
    "    ax = plt.subplot(141, projection='3d')\n",
    "    #ax.set_aspect('auto')\n",
    "    plt.title(title)\n",
    "    #ax.subplot(sub[0],sub[1],sub[2],projection='3d')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    \n",
    "    ax = plt.subplot(142,projection='3d')\n",
    "    plt.title(title + '(z)')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.view_init(90,-90)\n",
    "    \n",
    "    ax = plt.subplot(143,projection='3d')\n",
    "    plt.title(title + '(x)')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.view_init(0,0)\n",
    "    \n",
    "    ax = plt.subplot(144,projection='3d')\n",
    "    plt.title(title + '(y)')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.view_init(0,-90)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_box_colors(colors,sizes,positions,fs=(10,5), title=''):\n",
    "    colors = colors\n",
    "    plt.figure('SPLTV', figsize=(15,5))\n",
    "    #ax = fig.gca(projection='3d')\n",
    "    ax = plt.subplot(141, projection='3d')\n",
    "    #ax.set_aspect('auto')\n",
    "    plt.title(title)\n",
    "    #ax.subplot(sub[0],sub[1],sub[2],projection='3d')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    \n",
    "    ax = plt.subplot(142,projection='3d')\n",
    "    plt.title(title + '(z)')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.view_init(90,-90)\n",
    "    \n",
    "    ax = plt.subplot(143,projection='3d')\n",
    "    plt.title(title + '(x)')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.view_init(0,0)\n",
    "    \n",
    "    ax = plt.subplot(144,projection='3d')\n",
    "    plt.title(title + '(y)')\n",
    "    pc = plotCubeAt2(positions,sizes,colors=colors, edgecolor=\"w\")\n",
    "    ax.add_collection3d(pc)    \n",
    "    ax.set_xlim([0,20])\n",
    "    ax.set_ylim([0,20])\n",
    "    ax.set_zlim([0,20])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.view_init(0,-90)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ec88d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T11:04:41.123401Z",
     "start_time": "2021-04-27T11:04:41.097278Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9bfaa8681f04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mActorCritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActorCritic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcase_cnn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcase_cnn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "    def __init__(self, state_size, selected_size, remain_size, output_size):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.case_cnn1 = Conv2D(filters=16, kernel_size=3, activation='relu', padding=\"valid\", input_shape = selected_size)\n",
    "        self.case_cnn2 = Conv2D(filters=16, kernel_size=3, activation='relu', padding=\"valid\")\n",
    "\n",
    "        self.select_cnn1 = Conv2D(filters=16, kernel_size=3, activation='relu', padding=\"valid\", input_shape = selected_size)\n",
    "        self.select_cnn2 = Conv2D(filters=16, kernel_size=3, activation='relu', padding=\"valid\")\n",
    "        \n",
    "        self.remain_cnn1 = Conv1D(filters=32, kernel_size=2, activation='relu', padding=\"same\", input_shape = remain_size )\n",
    "        self.remain_cnn2 = Conv1D(filters=32, kernel_size=2, activation='relu', padding=\"same\")\n",
    "        \n",
    "        self.d1 = Dense(256, activation='relu')\n",
    "        self.d2 = Dense(256, activation='relu')\n",
    "        self.out = Dense(output_size)\n",
    "        \n",
    "    def call(self, cb_list):\n",
    "        c, s, r = cb_list[0], cb_list[1], cb_list[2]\n",
    "\n",
    "        c = self.case_cnn1(c)\n",
    "        print(c.shape)\n",
    "        c = MaxPooling2D(pool_size=(2, 2))(c)\n",
    "        print(c.shape)\n",
    "        c = self.case_cnn2(c)\n",
    "        print(c.shape)\n",
    "        c = MaxPooling2D(pool_size=(2, 2))(c)\n",
    "        print(c.shape)\n",
    "        c = Flatten()(c)\n",
    "\n",
    "        s = self.select_cnn1(s)\n",
    "        s = MaxPooling2D(pool_size=(2, 2))(s)\n",
    "        s = self.select_cnn2(s)\n",
    "        s = MaxPooling2D(pool_size=(2, 2))(s)\n",
    "        s = Flatten()(s)\n",
    "\n",
    "        r = self.remain_cnn1(r)\n",
    "        r = self.remain_cnn2(r)\n",
    "        r = MaxPooling1D(pool_size=1)(r)\n",
    "        r = Flatten()(r)\n",
    "        \n",
    "        x = concatenate([c,s, r])\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        q = self.out(x)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eca45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticAgent:\n",
    "    def __init__(self, L=20,B=20,H=20,n_remains=5,lr=1e-8,gamma=0.99):\n",
    "        self.state_size = (L,B,1)\n",
    "        self.selected_size = (L,B,H)\n",
    "        self.remain_size = (n_remains, 3)\n",
    "        self.output_size = 1\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.actor = ActorCritic(self.state_size, self.selected_size,\n",
    "                          self.remain_size, self.output_size)\n",
    "        self.critic = ActorCritic(self.state_size, self.selected_size,\n",
    "                           self.remain_size, self.output_size)\n",
    "        \n",
    "        self.actor_optimizer = Adam(learning_rate = self.lr)\n",
    "        self.critic_optimizer = Adam(learning_rate = self.lr)\n",
    "        \n",
    "        self.memory = deque(maxlen=500)\n",
    "        \n",
    "        self.avg_actor_loss = 0\n",
    "        self.avg_critic_loss = 0\n",
    "        \n",
    "    def append_sample(self, history, s_boxes, remains, action, reward, last, t_history, t_s_boxes, t_remains):\n",
    "        self.memory.append((history, s_boxes, remains, action, reward, last, t_history, t_s_boxes, t_remains))\n",
    "        \n",
    "    def get_action(self, state, s_locs, r_boxes):\n",
    "        actor = self.actor([state, s_locs, r_boxes])\n",
    "        argmax_idx = np.where(actor == tf.math.reduce_max(actor))\n",
    "        action_idx = argmax_idx[0][0]\n",
    "        return action_idx\n",
    "    \n",
    "    def get_actor_loss():\n",
    "        pass\n",
    "    \n",
    "    def get_critic_loss():\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        batch = random.sample(self.memory, len(self.memory))\n",
    "        \n",
    "        history = np.array([sample[0] for sample in batch])\n",
    "        s_boxes = np.array([sample[1] for sample in batch])\n",
    "        remains = np.array([sample[2] for sample in batch])\n",
    "        action = np.array([sample[3] for sample in batch])\n",
    "        reward = np.array([sample[4] for sample in batch])\n",
    "        dones = np.array([sample[5] for sample in batch])\n",
    "        next_history = [sample[6] for sample in batch]\n",
    "        next_s_boxes = [sample[7] for sample in batch]\n",
    "        next_remains = [sample[8] for sample in batch]\n",
    "        \n",
    "        #print(history.shape, s_boxes.shape, remains.shape, action.shape, reward.shape, dones.shape)\n",
    "        #print(len(next_history), len(next_s_boxes), len(next_remains))\n",
    "        #print(next_history[0].shape, next_s_boxes[0].shape, next_remains[0].shape)\n",
    "        \n",
    "        with tf.GradientTape() as actor_tape, tf.GradientTape() as critic_tape:\n",
    "            actor = self.actor([history, s_boxes, remains])\n",
    "            value = self.critic([history, s_boxes, remains])\n",
    "            \n",
    "            targets = []\n",
    "            action_idx = np.stack([np.arange(len(self.memory)),action],axis=1)\n",
    "            acts = tf.gather_nd(actor, action_idx, batch_dims=0, name=None)\n",
    "            predicts = tf.gather_nd(value, action_idx, batch_dims=0, name=None)\n",
    "            \n",
    "            for i in range(len(self.memory)):\n",
    "                next_value = self.critic([next_history[i],next_s_boxes[i],\n",
    "                                         next_remains[i]])\n",
    "                next_max_value = tf.math.reduce_max(next_value)\n",
    "                targets.append([(1-0.875)*reward[i] + (1-dones[i])*0.75*next_max_value])\n",
    "            \n",
    "            targets = np.array(targets)\n",
    "            actor_loss = tf.reduce_mean(tf.square(targets - acts))\n",
    "            critic_loss = tf.reduce_mean(tf.square(targets - predicts))\n",
    "            \n",
    "            self.avg_actor_loss += actor_loss.numpy()\n",
    "            self.avg_critic_loss += critic_loss.numpy()\n",
    "        \n",
    "        actor_grads = actor_tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        critic_grads = critic_tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(zip(actor_grads,\n",
    "                                                self.actor.trainable_variables))\n",
    "        self.critic_optimizer.apply_gradients(zip(critic_grads,\n",
    "                                                 self.critic.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ebff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bpp3DEnv():#(gym.Env):\n",
    "    #metadata = {'render.modes': ['human']}\n",
    "    #\n",
    "    def __init__(self,length=20, breadth=20, height=20):\n",
    "        super(Bpp3DEnv, self).__init__()\n",
    "        self.length=length\n",
    "        self.breadth=breadth\n",
    "        self.height=height\n",
    "        self.container_h=np.zeros((self.length,self.breadth))\n",
    "        self.container=np.zeros((self.length, self.breadth, self.height))\n",
    "    \n",
    "    def update_h(self):\n",
    "        idx = np.where(self.container == 1)\n",
    "        h = pd.DataFrame(np.transpose(idx, (1,0)))\n",
    "        h.columns = ['0','1','2']\n",
    "        h = h.groupby(['0','1']).agg({'0':'first','1':'first','2':'max'}).values\n",
    "        self.reset_h()\n",
    "        self.container_h[h[:,0],h[:,1]] = h[:,2]+1\n",
    "        return self.container_h\n",
    "    \n",
    "    def convert_state(self, new_container):\n",
    "        self.container = new_container\n",
    "        self.update_h()\n",
    "    \n",
    "    def next_state(self, upleft,bxl,bxb,bxh):\n",
    "        next_container_h = self.container_h.copy()\n",
    "        loading_area_h = self.container_h[upleft[0]:upleft[0]+bxl, upleft[1]:upleft[1]+bxb]\n",
    "        max_h = np.max(loading_area_h).astype('int')\n",
    "        next_container_h[upleft[0]:upleft[0]+bxl,upleft[1]:upleft[1]+bxb] = bxh + max_h\n",
    "        \n",
    "        next_container = self.container.copy()\n",
    "        next_container[upleft[0]:upleft[0]+bxl, upleft[1]:upleft[1]+bxb, max_h:bxh + max_h] = 1\n",
    "        \n",
    "        return next_container, next_container_h\n",
    "    \n",
    "    def step(self, upleft,bxl,bxb,bxh):\n",
    "        n_s, n_h = self.next_state(upleft,bxl,bxb,bxh)\n",
    "        self.convert_state(n_s)\n",
    "        return n_s\n",
    "    \n",
    "    def reset(self):\n",
    "        self.container = np.zeros((self.length,self.breadth, self.height))\n",
    "        self.container_h = np.zeros((self.length,self.breadth))\n",
    "    \n",
    "    def reset_h(self):\n",
    "        self.container_h = np.zeros((self.length,self.breadth))\n",
    "        \n",
    "    def terminal_reward(self):\n",
    "        return np.sum(self.container)/(self.length*self.breadth*self.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee508acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/preprocessed_data/U1_PP_r.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "bbox = pd.read_csv('preprocessed_data_bbox/U1_bbox.csv')\n",
    "\n",
    "for i in range(len(data)): data[i] = data[i]//10\n",
    "    \n",
    "bbox = np.ceil(( bbox.values * 0.93)/10).astype('int')\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88872f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episode = 1000\n",
    "N_MDD = 5\n",
    "K = 3\n",
    "N_candidates = 4\n",
    "\n",
    "boxes, gt_pos = generation_3dbox_random(case_size=[[20,20,20]],min_s=1,\n",
    "                                        N_mdd = N_MDD)\n",
    "num_max_boxes = len(boxes)\n",
    "num_max_remain = num_max_boxes - K\n",
    "env = Bpp3DEnv()\n",
    "agent = ActorCriticAgent(L=20,B=20,H=20,n_remains=num_max_remain,\n",
    "                        lr=0.001,gamma=0.99)\n",
    "\n",
    "used_box_list, pred_pos_list = [], []\n",
    "box_list, pos_list = [],[]\n",
    "frac_l, avg_actor_loss, avg_critic_loss = [],[],[]\n",
    "for episode in range(max_episode):\n",
    "    boxes, gt_pos = generation_3dbox_random(case_size=[[20,20,20]],min_s=1,\n",
    "                                        N_mdd = N_MDD)\n",
    "    boxes = boxes[0]\n",
    "    gt_pos = gt_pos[0]\n",
    "\n",
    "    box_list.append(boxes)\n",
    "    pos_list.append(gt_pos)\n",
    "\n",
    "    num_max_boxes = len(boxes)\n",
    "    num_max_remain = num_max_boxes - K\n",
    "    st = time.time()\n",
    "    env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    print(np.sum(env.container))\n",
    "    \n",
    "    history, used_boxes, remains, comb, pred_pos, actions, s_orders = [],[],[],[],[],[],[]\n",
    "    next_history, next_comb, next_remains, next_s_orders = [],[],[],[]\n",
    "    \n",
    "    r_boxes = np.array(np.array(boxes).copy())\n",
    "    \n",
    "    while not done:\n",
    "        state = env.container.copy()\n",
    "        k = min(K, len(r_boxes))\n",
    "        step += 1\n",
    "        \n",
    "        selected = cbn_select_boxes(r_boxes[:N_candidates], k)\n",
    "        s_order = get_selected_order(selected, k)\n",
    "        \n",
    "        state_h = env.update_h().copy()\n",
    "        in_state, in_r_boxes = raw_to_input(state_h, s_order,\n",
    "                                           r_boxes, num_max_remain)\n",
    "        s_loc_c, pred_pos_c, used_boxes_c, next_state_c, num_loaded_box_c, next_cube_c = get_selected_location(s_order, pred_pos, used_boxes, state)\n",
    "        \n",
    "        action_idx = agent.get_action(in_state, s_loc_c, in_r_boxes)\n",
    "        num_loaded_box = num_loaded_box_c[action_idx]\n",
    "        \n",
    "        if num_loaded_box != 0:\n",
    "            history.append(in_state[action_idx])\n",
    "            remains.append(in_r_boxes[action_idx])\n",
    "            s_orders.append(s_order[action_idx])\n",
    "            comb.append(s_loc_c[action_idx])\n",
    "            actions.append(action_idx)\n",
    "            \n",
    "            new_used_boxes = get_remain(used_boxes, used_boxes_c[action_idx])\n",
    "            r_boxes = get_remain(new_used_boxes, r_boxes)\n",
    "            \n",
    "            used_boxes = used_boxes_c[action_idx]\n",
    "            pred_pos = pred_pos_c[action_idx]\n",
    "            \n",
    "            env.convert_state(next_cube_c[action_idx])\n",
    "            \n",
    "            next_state = env.container.copy()\n",
    "            next_state_h = env.container_h.copy()\n",
    "            \n",
    "            next_history.append(next_state_h)      \n",
    "            if len(r_boxes) == 0:\n",
    "                done = True\n",
    "                next_remains.append(np.zeros((num_max_remain, 3)))\n",
    "                next_comb.append(np.zeros((1,20,20,20)))\n",
    "                next_s_orders.append(np.zeros((1,1,3)))\n",
    "            else:\n",
    "                next_remains.append(r_boxes)\n",
    "                k = min(K, len(r_boxes))\n",
    "                selected = cbn_select_boxes(r_boxes[:N_candidates], k)\n",
    "                s_order = get_selected_order(selected, k)\n",
    "                s_loc_c,_,_,_,_,_ = get_selected_location(s_order, pred_pos,\n",
    "                                                         used_boxes, next_state)\n",
    "                next_comb.append(s_loc_c)\n",
    "                next_s_orders.append(s_order)\n",
    "        else:\n",
    "            r_boxes = get_remain(s_order[action_idx], r_boxes)\n",
    "            if len(r_boxes) == 0:\n",
    "                done = True\n",
    "                \n",
    "        if done:\n",
    "            terminal_reward = env.terminal_reward()\n",
    "            frac_l.append(env.terminal_reward())\n",
    "            \n",
    "            is_last = False\n",
    "            N = len(history)\n",
    "            for i in range(N):\n",
    "                if i == N-1:\n",
    "                    is_last = True\n",
    "                reward = (agent.gamma ** (N-i-1)) * terminal_reward\n",
    "                in_next_history, in_next_remains = raw_to_input(next_history[i],\n",
    "                                                               next_s_orders[i],\n",
    "                                                               next_remains[i],\n",
    "                                                               num_max_remain)\n",
    "                \n",
    "                agent.append_sample(history[i], comb[i], remains[i], actions[i],\n",
    "                                   reward, is_last, in_next_history,\n",
    "                                   next_comb[i], in_next_remains)\n",
    "            agent.train()\n",
    "            avg_actor_loss.append(agent.avg_actor_loss / float(step))\n",
    "            avg_critic_loss.append(agent.avg_critic_loss / float(step))\n",
    "            used_box_list.append(used_boxes)\n",
    "            pred_pos_list.append(pred_pos)\n",
    "\n",
    "    log = \"=====episode: {:5d} | \".format(episode)\n",
    "    log += \"memory length: {:5d} | \".format(len(agent.memory))\n",
    "    log += \"env.terminal_reward(): {:.3f} | \".format(env.terminal_reward())\n",
    "    log += \"avg actor loss : {:6f} \".format(agent.avg_actor_loss / float(step))\n",
    "    log += \"avg critic loss : {:6f} \".format(agent.avg_critic_loss / float(step))\n",
    "    log += \"time: {:.3f}\".format(time.time()-st)\n",
    "    print(log)\n",
    "    \n",
    "    agent.avg_actor_loss = 0\n",
    "    agent.avg_critic_loss = 0\n",
    "    agent.memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac237dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
