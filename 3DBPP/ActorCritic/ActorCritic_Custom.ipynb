{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7066c07e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:25.676228Z",
     "start_time": "2021-04-22T10:59:25.648304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13585792589863284389,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4949437312\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15461685689681602294\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c2378d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:25.919246Z",
     "start_time": "2021-04-22T10:59:25.903323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b1398f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:26.300804Z",
     "start_time": "2021-04-22T10:59:26.296781Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import collections\n",
    "import statistics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21916997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:26.669253Z",
     "start_time": "2021-04-22T10:59:26.651299Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = np.finfo(np.float32).eps.item()\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64603f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:27.006007Z",
     "start_time": "2021-04-22T10:59:26.836310Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActorCriticModel(tf.keras.Model):\n",
    "    def __init__(self, action_n, hidden_n):\n",
    "        super().__init__()\n",
    "        self.x = layers.Dense(hidden_n, activation='relu')\n",
    "        self.actor = layers.Dense(action_n)\n",
    "        self.critic = layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.x(inputs)\n",
    "        return self.actor(x), self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "314187d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:27.205066Z",
     "start_time": "2021-04-22T10:59:27.179826Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActorCritic():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def env_step(self, action):\n",
    "        state, reward, done = env.step(action)\n",
    "        return (state.astype(np.int32), \n",
    "                np.array(reward, np.int32), \n",
    "                np.array(done, np.int32))\n",
    "    \n",
    "    def step(self, action):\n",
    "        return tf.numpy_function(self.env_step, [action], \n",
    "                                 [tf.float32, tf.int32, tf.int32])\n",
    "    \n",
    "    def expect_reward(self, rewards, gamma, is_standard):\n",
    "        shape = tf.shape(rewards)[0]\n",
    "        expect_rewards = tf.TensorArray(dtype=tf.float32, size=shape)\n",
    "        \n",
    "        rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "        discount_sum = tf.constant(0.0)\n",
    "        sum_shape = discount_sum.shape\n",
    "        \n",
    "        for i in tf.range(shape):\n",
    "            reward = rewards[i]\n",
    "            discount_sum = reward + gamma * discount_sum\n",
    "            discount_sum.set_shape(sum_shape)\n",
    "            expect_rewards = expect_rewards.write(i, discount_sum)\n",
    "        expect_rewards = expect_rewards.stack()[::-1]\n",
    "        \n",
    "        if is_standard:\n",
    "            expect_rewards = ((expect_rewards-math.reduce_mean(expect_rewards)) \n",
    "                              / (math.reduce_std(expect_rewards) + epsilon))\n",
    "            \n",
    "        return expect_rewards\n",
    "    \n",
    "    def run(self, init_state, model, max_step):\n",
    "        actions = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "        \n",
    "        shape = init_state.shape\n",
    "        state = init_state\n",
    "        \n",
    "        boxes를 여기 넣는게 맞나?\n",
    "        이전에 Model선언했던거 없애\n",
    "        AC를 Agent로 바꾸고\n",
    "        \n",
    "        for step in range(max_step):\n",
    "            box = boxes[step]\n",
    "            w_upleft = \n",
    "            f_upleft = feasible_location(state, w_upleft, box, ~)\n",
    "            \n",
    "            if len(f_upleft) == 0:\n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "                state = tf.expand_dims(state, 0)\n",
    "                model = ActorCriticModel(len(f_upleft), 128)\n",
    "                actor, critic = model(state)\n",
    "                action = tf.random.categorical(actor, 1)[0,0]\n",
    "                actor_by_actions = tf.nn.softmax(actor)\n",
    "                values = values.write(step, tf.squeeze(critic))\n",
    "                actions = actions.write(step, actor_by_actions[0, action])\n",
    "\n",
    "                state, reward, done = self.step(action)\n",
    "            \n",
    "                state.set_shape(shape)\n",
    "                rewards = rewards.write(step, reward)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        actions = actions.stack()\n",
    "        values = values.stack()\n",
    "        rewards = rewards.stack()\n",
    "        \n",
    "        return actions, values, rewards\n",
    "    \n",
    "    def get_loss(self, actions, values, expect_reward):\n",
    "        loss = losses.Huber(reduction=losses.Reduction.SUM)\n",
    "        error = expect_reward - values\n",
    "        action_log = math.log(actions)\n",
    "        \n",
    "        actor_loss = -math.reduce_sum(action_log * error)\n",
    "        critic_loss = loss(values, expect_reward)\n",
    "        \n",
    "        return actor_loss + critic_loss\n",
    "    \n",
    "    def fit_RL(self, init_state, model, optimizer, gamma, max_step):\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions, values, rewards = self.run(init_state, model, max_step)\n",
    "            expect_rewards = self.expect_reward(rewards, gamma, True)\n",
    "            \n",
    "            actions, values, expect_rewards = [tf.expand_dims(x,1) for x in [actions,values,expect_rewards]]\n",
    "            \n",
    "            loss = self.get_loss(actions, values, expect_rewards)\n",
    "        gradient = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "        reward = math.reduce_sum(rewards)\n",
    "        \n",
    "        return loss, int(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b41e8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T17:12:18.905493Z",
     "start_time": "2021-04-22T17:12:18.888538Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bpp3DEnv():\n",
    "    def __init__(self,length=20, breadth=20, height=20):\n",
    "        super(Bpp3DEnv, self).__init__()\n",
    "        self.length=length\n",
    "        self.breadth=breadth\n",
    "        self.height=height\n",
    "        self.container=np.zeros((self.length,self.breadth))\n",
    "    \n",
    "    def convert_state(self, new_container):\n",
    "        self.container = new_container\n",
    "    \n",
    "    def next_state(self, upleft,bxl,bxb,bxh):\n",
    "        next_container = self.container.copy()\n",
    "        next_container[upleft[0]:upleft[0]+bxl,upleft[1]:upleft[1]+bxb] += bxh \n",
    "        return next_container\n",
    "    \n",
    "    def step(self, upleft,bxl,bxb,bxh):\n",
    "        self.container[upleft[0]:upleft[0]+bxl,upleft[1]:upleft[1]+bxb] += bxh \n",
    "        return self.container\n",
    "    \n",
    "    def reset(self):\n",
    "        self.container=np.zeros((self.length,self.breadth))\n",
    "    \n",
    "    def terminal_reward(self):\n",
    "        return np.sum(self.container)/(self.length*self.breadth*self.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63daa784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T17:12:06.376342Z",
     "start_time": "2021-04-22T17:12:06.352415Z"
    }
   },
   "outputs": [],
   "source": [
    "from ActorCritic.libs.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5d382c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T17:15:17.762707Z",
     "start_time": "2021-04-22T17:15:17.743757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0],\n",
       " [0, -10],\n",
       " [-10, 0],\n",
       " [-10, -10],\n",
       " [0, 10],\n",
       " [0, 20],\n",
       " [-10, 10],\n",
       " [-10, 20],\n",
       " [10, 0],\n",
       " [10, -10],\n",
       " [20, 0],\n",
       " [20, -10],\n",
       " [10, 10],\n",
       " [10, 20],\n",
       " [20, 10],\n",
       " [20, 20]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_upleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34050096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T17:15:22.592354Z",
     "start_time": "2021-04-22T17:15:22.586344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 0, 10],\n",
       "       [10,  0],\n",
       "       [10, 10]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_upleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac99b633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T17:14:43.030834Z",
     "start_time": "2021-04-22T17:14:43.004870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Bpp3DEnv()\n",
    "env.reset()\n",
    "history = env.container.copy()\n",
    "box, pos = [10,10,20], [0,0,0]\n",
    "upleft_l, used_boxes = [], []\n",
    "\n",
    "w_upleft = whole_upleft(*box_cornel([0,0],20,20), box[0], box[1])\n",
    "f_upleft = feasible_location(history, w_upleft, box[0], box[1], box[2], state_H = env.height, is2d=False)\n",
    "\n",
    "a_ops = action_options(f_upleft)\n",
    "a_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_value_list = []\n",
    "history = np.array([history.flatten()]*len(a_ops))\n",
    "actions = np.array([sample.flatten() for sample in a_ops])\n",
    "remains = np.array([remains]*len(a_ops))\n",
    "q_value_list = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659e50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4381d625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T09:03:59.701789Z",
     "start_time": "2021-04-22T09:03:21.017382Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 120:   1%|▎                       | 121/10000 [00:38<52:03,  3.16it/s, episode_reward=101, running_reward=73.9]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-fac8732b336c>\u001b[0m in \u001b[0;36mfit_RL\u001b[1;34m(self, init_state, model, optimizer, gamma, max_step)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_RL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mexpect_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpect_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-fac8732b336c>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, init_state, model, max_step)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    964\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 1823\u001b[1;33m         _ctx, \"Cast\", name, x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[0;32m   1824\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_episode = 10000\n",
    "gamma = 0.99\n",
    "\n",
    "episode_rewards:collections.deque = collections.deque(maxlen=100)\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "rewards = 0\n",
    "loss_list = []\n",
    "reward_list = []\n",
    "AC = ActorCritic()\n",
    "ACModel = ActorCriticModel(env.action_space.n, 128)\n",
    "with tqdm.trange(max_episode) as t:\n",
    "    for i in t:\n",
    "        init_state = tf.constant(env.reset(), dtype=tf.float32)\n",
    "        loss, reward = AC.fit_RL(init_state, ACModel, optimizer, gamma, 1000)\n",
    "        episode_rewards.append(reward)\n",
    "        rewards = statistics.mean(episode_rewards)\n",
    "        \n",
    "        t.set_description(f'Episode {i}')\n",
    "        t.set_postfix(episode_reward = reward, running_reward = rewards)\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        reward_list.append(rewards)\n",
    "        \n",
    "        if rewards > 190:\n",
    "            break\n",
    "            \n",
    "print(i, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b01804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:54.764443Z",
     "start_time": "2021-04-22T10:59:54.748511Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bpp3DEnv():\n",
    "    def __init__(self):\n",
    "        super(Bpp3DEnv, self).__init__()\n",
    "        self.length=20\n",
    "        self.breadth=20\n",
    "        self.height=20\n",
    "        self.container=np.zeros((self.length,self.breadth))\n",
    "        \n",
    "    def step(self, upleft,bxl,bxb,bxh):\n",
    "        self.container[upleft[0]:upleft[0]+bxl,upleft[1]:upleft[1]+bxb] += bxh \n",
    "        return self.container\n",
    "    \n",
    "    def reset(self):\n",
    "        self.container=np.zeros((self.length,self.breadth))\n",
    "\n",
    "    def terminal_reward(self):\n",
    "        return np.sum(self.container)/(self.length*self.breadth*self.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ddfb64d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T10:59:18.981412Z",
     "start_time": "2021-04-22T10:59:18.966415Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import generation_2dbox, whole_upleft, box_cornel, feasible_location, action_options_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3294e1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:00:49.128298Z",
     "start_time": "2021-04-22T11:00:49.120352Z"
    }
   },
   "outputs": [],
   "source": [
    "env = Bpp3DEnv()\n",
    "agent = ActorCritic()\n",
    "global_step = 0\n",
    "num_episode = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_list = []\n",
    "avg_loss_list = []\n",
    "history_eps = []\n",
    "used_boxes_eps =[]\n",
    "\n",
    "for e in range(num_episode):\n",
    "    done = False\n",
    "    step = 0\n",
    "    \n",
    "    env.reset()\n",
    "    boxes, gt_tmp = generation_2dbox(N_epi=1, c_l=20, c_b=20)\n",
    "    boxes = boxes[0]\n",
    "    \n",
    "    history = np.zeros((20,20))\n",
    "    history_list=[]\n",
    "    action_list=[]\n",
    "    reward_list=[]\n",
    "    next_history_list=[]\n",
    "    upleft_list=[]\n",
    "    next_action_list=[]\n",
    "    used_boxes=[]\n",
    "    \n",
    "    while not done:\n",
    "        global_step += 1\n",
    "        step += 1\n",
    "        box = boxes[step-1]\n",
    "        w_upleft = whole_upleft(*box_cornel([0,0],20,20),box[0],box[1])\n",
    "        \n",
    "        for i,ul in enumerate(upleft_list):\n",
    "            w_upleft += whole_upleft(*box_cornel([ul[0],ul[1]], used_boxes[i][0], used_boxes[i][1]),box[0],box[1])\n",
    "        f_upleft = feasible_location(history,w_upleft,box[0],box[1])\n",
    "        a_ops=action_options_list(f_upleft)\n",
    "        action, action_idx = \n",
    "        \n",
    "        if action_idx == -1 and step != len(boxes):\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4efa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor array 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
