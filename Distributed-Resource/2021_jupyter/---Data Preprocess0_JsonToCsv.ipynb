{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쏠2호 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/elsys/solar/_OMN/csv_RSRS0000000241/_20200101_20210531.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY_NM</th>\n",
       "      <th>SET_GEN_NM</th>\n",
       "      <th>GEN_ID</th>\n",
       "      <th>GEN_NM</th>\n",
       "      <th>CBP_GEN_ID</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>PATN_DT</th>\n",
       "      <th>HR_01</th>\n",
       "      <th>HR_02</th>\n",
       "      <th>HR_03</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_15</th>\n",
       "      <th>HR_16</th>\n",
       "      <th>HR_17</th>\n",
       "      <th>HR_18</th>\n",
       "      <th>HR_19</th>\n",
       "      <th>HR_20</th>\n",
       "      <th>HR_21</th>\n",
       "      <th>HR_22</th>\n",
       "      <th>HR_23</th>\n",
       "      <th>HR_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>125145.0</td>\n",
       "      <td>125136.0</td>\n",
       "      <td>125133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>(주)엘시스</td>\n",
       "      <td>elsys0001</td>\n",
       "      <td>235</td>\n",
       "      <td>쏠2호태양광발전소</td>\n",
       "      <td>AE97</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    COMPANY_NM SET_GEN_NM  GEN_ID     GEN_NM CBP_GEN_ID  CAPACITY     PATN_DT  \\\n",
       "0       (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2020-01-01   \n",
       "1       (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2020-01-02   \n",
       "2       (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2020-01-03   \n",
       "3       (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2020-01-04   \n",
       "4       (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2020-01-05   \n",
       "..         ...        ...     ...        ...        ...       ...         ...   \n",
       "511     (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2021-05-27   \n",
       "512     (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2021-05-28   \n",
       "513     (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2021-05-29   \n",
       "514     (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2021-05-30   \n",
       "515     (주)엘시스  elsys0001     235  쏠2호태양광발전소       AE97      96.6  2021-05-31   \n",
       "\n",
       "     HR_01  HR_02  HR_03  ...  HR_15  HR_16  HR_17     HR_18     HR_19  \\\n",
       "0      0.0    0.0    0.0  ...   25.0    6.0    3.0       1.0       0.0   \n",
       "1      0.0    0.0    0.0  ...   20.0   10.0    6.0       0.0       0.0   \n",
       "2      0.0    0.0    0.0  ...   25.0   10.0    6.0       1.0       0.0   \n",
       "3      0.0    0.0    0.0  ...   22.0   11.0    5.0       0.0       0.0   \n",
       "4      0.0    0.0    0.0  ...   23.0    6.0    4.0       0.0       0.0   \n",
       "..     ...    ...    ...  ...    ...    ...    ...       ...       ...   \n",
       "511    0.0    0.0    0.0  ...   19.0   22.0   21.0      13.0       5.0   \n",
       "512    0.0    0.0    0.0  ...   29.0   20.0   11.0       6.0       0.0   \n",
       "513    0.0    0.0    0.0  ...   28.0   27.0   25.0  125145.0  125136.0   \n",
       "514    0.0    0.0    0.0  ...   26.0   25.0   19.0      12.0       3.0   \n",
       "515    0.0    0.0    0.0  ...   28.0   28.0   19.0      10.0       5.0   \n",
       "\n",
       "        HR_20  HR_21  HR_22  HR_23  HR_24  \n",
       "0         0.0    0.0    0.0    0.0    0.0  \n",
       "1         0.0    0.0    0.0    0.0    0.0  \n",
       "2         0.0    0.0    0.0    0.0    0.0  \n",
       "3         0.0    0.0    0.0    0.0    0.0  \n",
       "4         0.0    0.0    0.0    0.0    0.0  \n",
       "..        ...    ...    ...    ...    ...  \n",
       "511       0.0    0.0    0.0    0.0    0.0  \n",
       "512       0.0    0.0    0.0    0.0    0.0  \n",
       "513  125133.0    0.0    0.0    0.0    0.0  \n",
       "514  125158.0    0.0    0.0    0.0    0.0  \n",
       "515       0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[516 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch\n",
    "from pandas import read_csv\n",
    "\n",
    "capacity = 96.6\n",
    "base_anomaly = 100000\n",
    "\n",
    "RSRSID_list=['RSRS0000000239', 'RSRS0000000241', 'RSRS0000000247', 'RSRS0000000249']\n",
    "file_path = 'C:/elsys/solar/_ONM/csv_'+ RSRSID_list[1]+'/'\n",
    "file_list = os.listdir(file_path)\n",
    "for filename in file_list:\n",
    "    if fnmatch.fnmatch(filename,'_202*.csv'):\n",
    "        print(file_path+filename)\n",
    "        filedata = pd.read_csv(file_path+filename, encoding='cp949')\n",
    "        sol2 = pd.DataFrame(filedata)\n",
    "        display(sol2)\n",
    "#origin.to_csv(dir_path+\"/weather_2014_2020.csv\",mode='w',index=False, encoding='CP949')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 31)\n"
     ]
    }
   ],
   "source": [
    "print(sol2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMPANY_NM        (주)엘시스\n",
       "SET_GEN_NM     elsys0001\n",
       "GEN_ID               235\n",
       "GEN_NM         쏠2호태양광발전소\n",
       "CBP_GEN_ID          AE97\n",
       "CAPACITY            96.6\n",
       "PATN_DT       2020-10-13\n",
       "HR_01                0.0\n",
       "HR_02                0.0\n",
       "HR_03                0.0\n",
       "HR_04                0.0\n",
       "HR_05                0.0\n",
       "HR_06                0.0\n",
       "HR_07                0.0\n",
       "HR_08                1.0\n",
       "HR_09                6.0\n",
       "HR_10               16.0\n",
       "HR_11               17.0\n",
       "HR_12               28.0\n",
       "HR_13               14.0\n",
       "HR_14               13.0\n",
       "HR_15               12.0\n",
       "HR_16               14.0\n",
       "HR_17                6.0\n",
       "HR_18                1.0\n",
       "HR_19                0.0\n",
       "HR_20                0.0\n",
       "HR_21                0.0\n",
       "HR_22                0.0\n",
       "HR_23                0.0\n",
       "HR_24                0.0\n",
       "Name: 286, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sol2.iloc[286])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY_NM</th>\n",
       "      <th>SET_GEN_NM</th>\n",
       "      <th>GEN_ID</th>\n",
       "      <th>GEN_NM</th>\n",
       "      <th>CBP_GEN_ID</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>PATN_DT</th>\n",
       "      <th>HR_01</th>\n",
       "      <th>HR_02</th>\n",
       "      <th>HR_03</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_15</th>\n",
       "      <th>HR_16</th>\n",
       "      <th>HR_17</th>\n",
       "      <th>HR_18</th>\n",
       "      <th>HR_19</th>\n",
       "      <th>HR_20</th>\n",
       "      <th>HR_21</th>\n",
       "      <th>HR_22</th>\n",
       "      <th>HR_23</th>\n",
       "      <th>HR_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [COMPANY_NM, SET_GEN_NM, GEN_ID, GEN_NM, CBP_GEN_ID, CAPACITY, PATN_DT, HR_01, HR_02, HR_03, HR_04, HR_05, HR_06, HR_07, HR_08, HR_09, HR_10, HR_11, HR_12, HR_13, HR_14, HR_15, HR_16, HR_17, HR_18, HR_19, HR_20, HR_21, HR_22, HR_23, HR_24]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sol2 = sol2.loc[286:]\n",
    "display(sol2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sol2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저녁부터 체크\n",
    "  \n",
    "print(df.shape)\n",
    "cnt_processed = 0\n",
    "cnt_nonprocessed = 0\n",
    "print(\"for range ({},{},{})\".format(df.shape[1]-1, 24-1, -1))\n",
    "\n",
    "for r in range(candidate_r, df.shape[0]):\n",
    "    anomal_exist_yn = 'N'\n",
    "    for c in range(df.shape[1]-1, 24-1, -1):# 17PM~\n",
    "        \n",
    "        if df.iloc[r,c] > capacity:\n",
    "            if df.iloc[r,c+1] > 0:# 오른쪽 0 아님\n",
    "                if df.iloc[r,c-1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c+1]+df.iloc[r,c-1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-(df.iloc[r,c+1]+1)\n",
    "            else:# 오른쪽 0\n",
    "                if df.iloc[r,c-1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c+1]+df.iloc[r,c-1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-1\n",
    "                \n",
    "            anomal_exist_yn = 'Y'\n",
    "            break;\n",
    "            \n",
    "    \n",
    "    for c in range(df.shape[1]-1, 7-1, -1):\n",
    "        if capacity < df.iloc[r,c]:\n",
    "            if(anomal_exist_yn == 'Y'):\n",
    "                cnt_processed = cnt_processed+1\n",
    "                df.iloc[r,c] = df.iloc[r,c]-base_anomaly\n",
    "            else:\n",
    "                cnt_nonprocessed = cnt_nonprocessed+1\n",
    "                \n",
    "\n",
    "df.to_csv(file_path+'_sol2_AnomalyProcessing_pm.csv',mode='w',index=False, encoding='CP949')   \n",
    "print(\"Anomaly_processed O {} \".format(cnt_processed)) \n",
    "print(\"Anomaly_processed X {} \".format(cnt_nonprocessed))\n",
    "\n",
    "'''            \n",
    "candidate_idx=[7,8,9,10,11,12,13,22,23,24,25,26,27,28,29,30,31]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.0 24.5\n"
     ]
    }
   ],
   "source": [
    "def getFirstAnomaly(base_anomaly):\n",
    "    candidate_r=0\n",
    "    candidate_c=0\n",
    "    for r in range(sol2.shape[0]):\n",
    "        for c in range(7,df.shape[1]):\n",
    "            if capacity < df.iloc[r,c]:\n",
    "                base_anomaly = df.iloc[r,c]\n",
    "                df.iloc[r,c] = (df.iloc[r,c-1]+df.iloc[r,c+1])/2\n",
    "                candidate_r=r\n",
    "                candidate_c=c\n",
    "                print(base_anomaly, df.iloc[r,c])\n",
    "                return base_anomaly, candidate_r\n",
    "            \n",
    "base_anomaly, candidate_r = getFirstAnomaly(base_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 31)\n",
      "for range (30,23,-1)\n",
      "Anomaly_processed O 191 \n",
      "Anomaly_processed X 366 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'            \\ncandidate_idx=[7,8,9,10,11,12,13,22,23,24,25,26,27,28,29,30,31]\\n'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저녁부터 체크\n",
    "  \n",
    "print(df.shape)\n",
    "cnt_processed = 0\n",
    "cnt_nonprocessed = 0\n",
    "print(\"for range ({},{},{})\".format(df.shape[1]-1, 24-1, -1))\n",
    "\n",
    "for r in range(candidate_r, df.shape[0]):\n",
    "    anomal_exist_yn = 'N'\n",
    "    for c in range(df.shape[1]-1, 24-1, -1):# 17PM~\n",
    "        \n",
    "        if df.iloc[r,c] > capacity:\n",
    "            if df.iloc[r,c+1] > 0:# 오른쪽 0 아님\n",
    "                if df.iloc[r,c-1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c+1]+df.iloc[r,c-1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-(df.iloc[r,c+1]+1)\n",
    "            else:# 오른쪽 0\n",
    "                if df.iloc[r,c-1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c+1]+df.iloc[r,c-1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-1\n",
    "                \n",
    "            anomal_exist_yn = 'Y'\n",
    "            break;\n",
    "            \n",
    "    \n",
    "    for c in range(df.shape[1]-1, 7-1, -1):\n",
    "        if capacity < df.iloc[r,c]:\n",
    "            if(anomal_exist_yn == 'Y'):\n",
    "                cnt_processed = cnt_processed+1\n",
    "                df.iloc[r,c] = df.iloc[r,c]-base_anomaly\n",
    "            else:\n",
    "                cnt_nonprocessed = cnt_nonprocessed+1\n",
    "                \n",
    "\n",
    "df.to_csv(file_path+'_sol2_AnomalyProcessing_pm.csv',mode='w',index=False, encoding='CP949')   \n",
    "print(\"Anomaly_processed O {} \".format(cnt_processed)) \n",
    "print(\"Anomaly_processed X {} \".format(cnt_nonprocessed))\n",
    "\n",
    "'''            \n",
    "candidate_idx=[7,8,9,10,11,12,13,22,23,24,25,26,27,28,29,30,31]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 31)\n",
      "for range (30,23,-1)\n",
      "Anomaly_processed O 175 \n",
      "Anomaly_processed X 191 \n"
     ]
    }
   ],
   "source": [
    "# 아침부터 체크\n",
    "       \n",
    "print(df.shape)\n",
    "cnt_processed = 0\n",
    "cnt_nonprocessed = 0\n",
    "print(\"for range ({},{},{})\".format(df.shape[1]-1, 24-1, -1))\n",
    "\n",
    "for r in range(candidate_r, df.shape[0]):\n",
    "    anomal_exist_yn = 'N'\n",
    "    for c in range(7, 16):# ~8AM\n",
    "        \n",
    "        if df.iloc[r,c] > capacity:\n",
    "            if df.iloc[r,c-1] > 0:# 왼쪽 0 아님\n",
    "                if df.iloc[r,c+1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c-1]+df.iloc[r,c+1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-(df.iloc[r,c-1]+1)\n",
    "            else:# 왼쪽 0\n",
    "                if df.iloc[r,c-1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c+1]+df.iloc[r,c-1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-1\n",
    "                \n",
    "            anomal_exist_yn = 'Y'\n",
    "            break;\n",
    "            \n",
    "    for c in range(7, df.shape[1]):\n",
    "        if capacity < df.iloc[r,c]:\n",
    "            if(anomal_exist_yn == 'Y'):\n",
    "                cnt_processed = cnt_processed+1\n",
    "                df.iloc[r,c] = df.iloc[r,c]-base_anomaly\n",
    "            else:\n",
    "                cnt_nonprocessed = cnt_nonprocessed+1\n",
    "                \n",
    "\n",
    "df.to_csv(file_path+'_sol2_AnomalyProcessing_am.csv',mode='w',index=False, encoding='CP949')   \n",
    "print(\"Anomaly_processed O {} \".format(cnt_processed)) \n",
    "print(\"Anomaly_processed X {} \".format(cnt_nonprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아침부터 체크\n",
    "       \n",
    "print(df.shape)\n",
    "cnt_processed = 0\n",
    "cnt_nonprocessed = 0\n",
    "print(\"for range ({},{},{})\".format(df.shape[1]-1, 24-1, -1))\n",
    "\n",
    "for r in range(candidate_r, df.shape[0]):\n",
    "    anomal_exist_yn = 'N'\n",
    "    for c in range(7, 16):# ~8AM\n",
    "        \n",
    "        if df.iloc[r,c] > capacity:\n",
    "            if df.iloc[r,c-1] > 0:# 왼쪽 0 아님\n",
    "                if df.iloc[r,c+1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c-1]+df.iloc[r,c+1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-(df.iloc[r,c-1]+1)\n",
    "            else:# 왼쪽 0\n",
    "                if df.iloc[r,c-1] < capacity:\n",
    "                    base_anomaly = df.iloc[r,c]-math.floor((df.iloc[r,c+1]+df.iloc[r,c-1])/2)\n",
    "                else:\n",
    "                    base_anomaly = df.iloc[r,c]-1\n",
    "                \n",
    "            anomal_exist_yn = 'Y'\n",
    "            break;\n",
    "            \n",
    "    for c in range(7, df.shape[1]):\n",
    "        if capacity < df.iloc[r,c]:\n",
    "            if(anomal_exist_yn == 'Y'):\n",
    "                cnt_processed = cnt_processed+1\n",
    "                df.iloc[r,c] = df.iloc[r,c]-base_anomaly\n",
    "            else:\n",
    "                cnt_nonprocessed = cnt_nonprocessed+1\n",
    "                \n",
    "\n",
    "df.to_csv(file_path+'_sol2_AnomalyProcessing_am.csv',mode='w',index=False, encoding='CP949')   \n",
    "print(\"Anomaly_processed O {} \".format(cnt_processed)) \n",
    "print(\"Anomaly_processed X {} \".format(cnt_nonprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPX power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/elsys/solar/_KPX/json_RSRS0000000239\n",
      "C:/elsys/solar/_KPX/json_RSRS0000000241\n",
      "C:/elsys/solar/_KPX/json_RSRS0000000247\n",
      "C:/elsys/solar/_KPX/json_RSRS0000000249\n",
      "-----------------------------------------------------------------\n",
      "\t FILE SIZE ERROR > file path / file size\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "# .json -> .csv\n",
    "\n",
    "\n",
    "RSRSID_list=['RSRS0000000239', 'RSRS0000000241', 'RSRS0000000247', 'RSRS0000000249']\n",
    "err_file_size = []\n",
    "\n",
    "for RSRSID in RSRSID_list:\n",
    "\n",
    "    base_dir        = 'C:/elsys/solar/_KPX/json_'+ RSRSID\n",
    "    save_dir        = 'C:/elsys/solar/_KPX/csv_'+ RSRSID+'/'\n",
    "    print(base_dir)\n",
    "    \n",
    "    column_list=['COMPANY_NM','SET_GEN_NM','GEN_ID','GEN_NM','CBP_GEN_ID','CAPACITY','PATN_DT','HR_01','HR_02','HR_03','HR_04','HR_05','HR_06','HR_07','HR_08','HR_09','HR_10','HR_11','HR_12','HR_13','HR_14','HR_15','HR_16','HR_17','HR_18','HR_19','HR_20','HR_21','HR_22','HR_23','HR_24']\n",
    "    COMPANY_NM=[]\n",
    "    PATN_DT=[]\n",
    "    GEN_NM=[]\n",
    "    CBP_GEN_ID=[]\n",
    "    SET_GEN_NM=[]\n",
    "    CAPACITY=[]\n",
    "    GEN_ID=[]\n",
    "    HR_01=[]\n",
    "    HR_02=[]\n",
    "    HR_03=[]\n",
    "    HR_04=[]\n",
    "    HR_05=[]\n",
    "    HR_06=[]\n",
    "    HR_07=[]\n",
    "    HR_08=[]\n",
    "    HR_09=[]\n",
    "    HR_10=[]\n",
    "    HR_11=[]\n",
    "    HR_12=[]\n",
    "    HR_13=[]\n",
    "    HR_14=[]\n",
    "    HR_15=[]\n",
    "    HR_16=[]\n",
    "    HR_17=[]\n",
    "    HR_18=[]\n",
    "    HR_19=[]\n",
    "    HR_20=[]\n",
    "    HR_21=[]\n",
    "    HR_22=[]\n",
    "    HR_23=[]\n",
    "    HR_24=[]\n",
    "\n",
    "    json_pattern    = os.path.join(base_dir,'*.json')\n",
    "    file_list       = glob.glob(json_pattern)\n",
    "    #print(file_list)\n",
    "\n",
    "    for file in file_list:\n",
    "        with open(file, encoding='UTF-8') as json_file:\n",
    "            #print(file)\n",
    "            \n",
    "\n",
    "            # parsing json file\n",
    "            json_data = json.load(json_file)\n",
    "            data = json_data['result']\n",
    "            \n",
    "            \n",
    "            # 2. empty file check\n",
    "            file_size = os.path.getsize(file)\n",
    "            #print(file_size)\n",
    "            if file_size < 100:\n",
    "                err_file_size.append(file + \"/\" + str(file_size))#err2\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            COMPANY_NM.append(data['COMPANY_NM'])\n",
    "            SET_GEN_NM.append(data['SET_GEN_NM'])\n",
    "            GEN_ID.append(data['GEN_ID'])\n",
    "            GEN_NM.append(data['GEN_NM'])\n",
    "            CBP_GEN_ID.append(data['CBP_GEN_ID'])\n",
    "            CAPACITY.append(data['CAPACITY'])\n",
    "            PATN_DT.append(data['PATN_DT'])\n",
    "            HR_01.append(data['HR_01'])\n",
    "            HR_02.append(data['HR_02'])\n",
    "            HR_03.append(data['HR_03'])\n",
    "            HR_04.append(data['HR_04'])\n",
    "            HR_05.append(data['HR_05'])\n",
    "            HR_06.append(data['HR_06'])\n",
    "            HR_07.append(data['HR_07'])\n",
    "            HR_08.append(data['HR_08'])\n",
    "            HR_09.append(data['HR_09'])\n",
    "            HR_10.append(data['HR_10'])\n",
    "            HR_11.append(data['HR_11'])\n",
    "            HR_12.append(data['HR_12'])\n",
    "            HR_13.append(data['HR_13'])\n",
    "            HR_14.append(data['HR_14'])\n",
    "            HR_15.append(data['HR_15'])\n",
    "            HR_16.append(data['HR_16'])\n",
    "            HR_17.append(data['HR_17'])\n",
    "            HR_18.append(data['HR_18'])\n",
    "            HR_19.append(data['HR_19'])\n",
    "            HR_20.append(data['HR_20'])\n",
    "            HR_21.append(data['HR_21'])\n",
    "            HR_22.append(data['HR_22'])\n",
    "            HR_23.append(data['HR_23'])\n",
    "            HR_24.append(data['HR_24'])\n",
    "                    \n",
    "    df = pd.DataFrame(columns=column_list)\n",
    "    df['COMPANY_NM'] = COMPANY_NM\n",
    "    df['SET_GEN_NM'] = SET_GEN_NM\n",
    "    df['GEN_ID'] = GEN_ID\n",
    "    df['GEN_NM'] = GEN_NM\n",
    "    df['CBP_GEN_ID'] = CBP_GEN_ID\n",
    "    df['CAPACITY'] = CAPACITY\n",
    "    df['PATN_DT'] = PATN_DT\n",
    "    df['HR_01'] = HR_01\n",
    "    df['HR_02'] = HR_02\n",
    "    df['HR_03'] = HR_03\n",
    "    df['HR_04'] = HR_04\n",
    "    df['HR_05'] = HR_05\n",
    "    df['HR_06'] = HR_06\n",
    "    df['HR_07'] = HR_07\n",
    "    df['HR_08'] = HR_08\n",
    "    df['HR_09'] = HR_09\n",
    "    df['HR_10'] = HR_10\n",
    "    df['HR_11'] = HR_11\n",
    "    df['HR_12'] = HR_12\n",
    "    df['HR_13'] = HR_13\n",
    "    df['HR_14'] = HR_14\n",
    "    df['HR_15'] = HR_15\n",
    "    df['HR_16'] = HR_16\n",
    "    df['HR_17'] = HR_17\n",
    "    df['HR_18'] = HR_18\n",
    "    df['HR_19'] = HR_19\n",
    "    df['HR_20'] = HR_20\n",
    "    df['HR_21'] = HR_21\n",
    "    df['HR_22'] = HR_22\n",
    "    df['HR_23'] = HR_23\n",
    "    df['HR_24'] = HR_24\n",
    "    df.sort_values('PATN_DT')\n",
    "    \n",
    "    # save csv file\n",
    "    savefilenm = '_' + df.iloc[0,6].replace(\"-\",\"\") + '_' + df.iloc[-1,6].replace(\"-\",\"\") + '.csv'\n",
    "    df.to_csv(save_dir + savefilenm, index=False, header=True, encoding='CP949')\n",
    "    \n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"\\t FILE SIZE ERROR > file path / file size\")\n",
    "for f in err_file_size:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/elsys/solar/_KPX/json_RSRS0000000239\n",
      "C:/elsys/solar/_KPX/json_RSRS0000000241\n",
      "C:/elsys/solar/_KPX/json_RSRS0000000247\n",
      "C:/elsys/solar/_KPX/json_RSRS0000000249\n",
      "-----------------------------------------------------------------\n",
      "\t FILE SIZE ERROR > file path / file size\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "# .json -> .csv\n",
    "\n",
    "\n",
    "RSRSID_list=['RSRS0000000239', 'RSRS0000000241', 'RSRS0000000247', 'RSRS0000000249']\n",
    "err_file_size = []\n",
    "\n",
    "for RSRSID in RSRSID_list:\n",
    "\n",
    "    base_dir        = 'C:/elsys/solar/_KPX/json_'+ RSRSID\n",
    "    save_dir        = 'C:/elsys/solar/_KPX/csv_'+ RSRSID+'/'\n",
    "    print(base_dir)\n",
    "    \n",
    "    column_list=['COMPANY_NM','SET_GEN_NM','GEN_ID','GEN_NM','CBP_GEN_ID','CAPACITY','PATN_DT','HR_01','HR_02','HR_03','HR_04','HR_05','HR_06','HR_07','HR_08','HR_09','HR_10','HR_11','HR_12','HR_13','HR_14','HR_15','HR_16','HR_17','HR_18','HR_19','HR_20','HR_21','HR_22','HR_23','HR_24']\n",
    "    COMPANY_NM=[]\n",
    "    PATN_DT=[]\n",
    "    GEN_NM=[]\n",
    "    CBP_GEN_ID=[]\n",
    "    SET_GEN_NM=[]\n",
    "    CAPACITY=[]\n",
    "    GEN_ID=[]\n",
    "    HR_01=[]\n",
    "    HR_02=[]\n",
    "    HR_03=[]\n",
    "    HR_04=[]\n",
    "    HR_05=[]\n",
    "    HR_06=[]\n",
    "    HR_07=[]\n",
    "    HR_08=[]\n",
    "    HR_09=[]\n",
    "    HR_10=[]\n",
    "    HR_11=[]\n",
    "    HR_12=[]\n",
    "    HR_13=[]\n",
    "    HR_14=[]\n",
    "    HR_15=[]\n",
    "    HR_16=[]\n",
    "    HR_17=[]\n",
    "    HR_18=[]\n",
    "    HR_19=[]\n",
    "    HR_20=[]\n",
    "    HR_21=[]\n",
    "    HR_22=[]\n",
    "    HR_23=[]\n",
    "    HR_24=[]\n",
    "\n",
    "    json_pattern    = os.path.join(base_dir,'*.json')\n",
    "    file_list       = glob.glob(json_pattern)\n",
    "    #print(file_list)\n",
    "\n",
    "    for file in file_list:\n",
    "        with open(file, encoding='UTF-8') as json_file:\n",
    "            #print(file)\n",
    "            \n",
    "\n",
    "            # parsing json file\n",
    "            json_data = json.load(json_file)\n",
    "            data = json_data['result']\n",
    "            \n",
    "            \n",
    "            # 2. empty file check\n",
    "            file_size = os.path.getsize(file)\n",
    "            #print(file_size)\n",
    "            if file_size < 100:\n",
    "                err_file_size.append(file + \"/\" + str(file_size))#err2\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            df = pd.DataFrame(columns=column_list)\n",
    "            \n",
    "            df['COMPANY_NM']=data['COMPANY_NM']\n",
    "            df['SET_GEN_NM']=data['SET_GEN_NM']\n",
    "            df['GEN_ID']=data['GEN_ID']\n",
    "            df['GEN_NM']=data['GEN_NM']\n",
    "            df['CBP_GEN_ID']=data['CBP_GEN_ID']\n",
    "            df['CAPACITY']=data['CAPACITY']\n",
    "            df['PATN_DT']=data['PATN_DT']\n",
    "            df['HR_01']=data['HR_01']\n",
    "            df['HR_02']=data['HR_02']\n",
    "            df['HR_03']=data['HR_03']\n",
    "            df['HR_04']=data['HR_04']\n",
    "            df['HR_05']=data['HR_05']\n",
    "            df['HR_06']=data['HR_06']\n",
    "            df['HR_07']=data['HR_07']\n",
    "            df['HR_08']=data['HR_08']\n",
    "            df['HR_09']=data['HR_09']\n",
    "            df['HR_10']=data['HR_10']\n",
    "            df['HR_11']=data['HR_11']\n",
    "            df['HR_12']=data['HR_12']\n",
    "            df['HR_13']=data['HR_13']\n",
    "            df['HR_14']=data['HR_14']\n",
    "            df['HR_15']=data['HR_15']\n",
    "            df['HR_16']=data['HR_16']\n",
    "            df['HR_17']=data['HR_17']\n",
    "            df['HR_18']=data['HR_18']\n",
    "            df['HR_19']=data['HR_19']\n",
    "            df['HR_20']=data['HR_20']\n",
    "            df['HR_21']=data['HR_21']\n",
    "            df['HR_22']=data['HR_22']\n",
    "            df['HR_23']=data['HR_23']\n",
    "            df['HR_24']=data['HR_24']\n",
    "            \n",
    "            df.sort_values('PATN_DT')\n",
    "\n",
    "            # save csv file\n",
    "            df.to_csv(save_dir + file[-13:-5] + '.csv', index=False, header=True, encoding='CP949')\n",
    "    \n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"\\t FILE SIZE ERROR > file path / file size\")\n",
    "for f in err_file_size:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONM power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/elsys/solar/_OMN/json_RSRS0000000239\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000241\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000247\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000249\n",
      "-----------------------------------------------------------------\n",
      "\t FILE SIZE ERROR > file path / file size\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000241\\20201227.json/15\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000247\\20201227.json/15\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000247\\20201228.json/15\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000249\\20201227.json/15\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "# .json -> .csv\n",
    "\n",
    "\n",
    "RSRSID_list=['RSRS0000000239', 'RSRS0000000241', 'RSRS0000000247', 'RSRS0000000249']\n",
    "err_file_size = []\n",
    "\n",
    "for RSRSID in RSRSID_list:\n",
    "\n",
    "    base_dir        = 'C:/elsys/solar/_ONM/json_'+ RSRSID\n",
    "    save_dir        = 'C:/elsys/solar/_ONM/csv_'+ RSRSID+'/'\n",
    "    print(base_dir)\n",
    "    \n",
    "    column_list=['COMPANY_NM','SET_GEN_NM','GEN_ID','GEN_NM','CBP_GEN_ID','CAPACITY','PATN_DT','HR_01','HR_02','HR_03','HR_04','HR_05','HR_06','HR_07','HR_08','HR_09','HR_10','HR_11','HR_12','HR_13','HR_14','HR_15','HR_16','HR_17','HR_18','HR_19','HR_20','HR_21','HR_22','HR_23','HR_24']\n",
    "    COMPANY_NM=[]\n",
    "    PATN_DT=[]\n",
    "    GEN_NM=[]\n",
    "    CBP_GEN_ID=[]\n",
    "    SET_GEN_NM=[]\n",
    "    CAPACITY=[]\n",
    "    GEN_ID=[]\n",
    "    HR_01=[]\n",
    "    HR_02=[]\n",
    "    HR_03=[]\n",
    "    HR_04=[]\n",
    "    HR_05=[]\n",
    "    HR_06=[]\n",
    "    HR_07=[]\n",
    "    HR_08=[]\n",
    "    HR_09=[]\n",
    "    HR_10=[]\n",
    "    HR_11=[]\n",
    "    HR_12=[]\n",
    "    HR_13=[]\n",
    "    HR_14=[]\n",
    "    HR_15=[]\n",
    "    HR_16=[]\n",
    "    HR_17=[]\n",
    "    HR_18=[]\n",
    "    HR_19=[]\n",
    "    HR_20=[]\n",
    "    HR_21=[]\n",
    "    HR_22=[]\n",
    "    HR_23=[]\n",
    "    HR_24=[]\n",
    "\n",
    "    json_pattern    = os.path.join(base_dir,'*.json')\n",
    "    file_list       = glob.glob(json_pattern)\n",
    "    #print(file_list)\n",
    "\n",
    "    for file in file_list:\n",
    "        with open(file, encoding='UTF-8') as json_file:\n",
    "            #print(file)\n",
    "            \n",
    "\n",
    "            # parsing json file\n",
    "            json_data = json.load(json_file)\n",
    "            data = json_data['result']\n",
    "            \n",
    "            \n",
    "            # 2. empty file check\n",
    "            file_size = os.path.getsize(file)\n",
    "            #print(file_size)\n",
    "            if file_size < 100:\n",
    "                err_file_size.append(file + \"/\" + str(file_size))#err2\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            \n",
    "            df = pd.DataFrame(columns=column_list)\n",
    "            df['COMPANY_NM']=data['COMPANY_NM']\n",
    "            df['SET_GEN_NM']=data['SET_GEN_NM']\n",
    "            df['GEN_ID']=data['GEN_ID']\n",
    "            df['GEN_NM']=data['GEN_NM']\n",
    "            df['CBP_GEN_ID']=data['CBP_GEN_ID']\n",
    "            df['CAPACITY']=data['CAPACITY']\n",
    "            df['PATN_DT']=data['PATN_DT']\n",
    "            df['HR_01']=data['HR_01']\n",
    "            df['HR_02']=data['HR_02']\n",
    "            df['HR_03']=data['HR_03']\n",
    "            df['HR_04']=data['HR_04']\n",
    "            df['HR_05']=data['HR_05']\n",
    "            df['HR_06']=data['HR_06']\n",
    "            df['HR_07']=data['HR_07']\n",
    "            df['HR_08']=data['HR_08']\n",
    "            df['HR_09']=data['HR_09']\n",
    "            df['HR_10']=data['HR_10']\n",
    "            df['HR_11']=data['HR_11']\n",
    "            df['HR_12']=data['HR_12']\n",
    "            df['HR_13']=data['HR_13']\n",
    "            df['HR_14']=data['HR_14']\n",
    "            df['HR_15']=data['HR_15']\n",
    "            df['HR_16']=data['HR_16']\n",
    "            df['HR_17']=data['HR_17']\n",
    "            df['HR_18']=data['HR_18']\n",
    "            df['HR_19']=data['HR_19']\n",
    "            df['HR_20']=data['HR_20']\n",
    "            df['HR_21']=data['HR_21']\n",
    "            df['HR_22']=data['HR_22']\n",
    "            df['HR_23']=data['HR_23']\n",
    "            df['HR_24']=data['HR_24']\n",
    "            \n",
    "            df.sort_values('PATN_DT')\n",
    "\n",
    "            # save csv file\n",
    "            df.to_csv(save_dir + file[-13:-5] + '.csv', index=False, header=True, encoding='CP949')\n",
    "    \n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"\\t FILE SIZE ERROR > file path / file size\")\n",
    "for f in err_file_size:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통합 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/elsys/solar/_OMN/json_RSRS0000000239\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000241\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000247\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000249\n",
      "-----------------------------------------------------------------\n",
      "\t FILE SIZE ERROR > file path / file size\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000241\\20201227.json/15\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000247\\20201227.json/15\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000247\\20201228.json/15\n",
      "C:/elsys/solar/_OMN/json_RSRS0000000249\\20201227.json/15\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "# .json -> .csv\n",
    "\n",
    "\n",
    "RSRSID_list=['RSRS0000000239', 'RSRS0000000241', 'RSRS0000000247', 'RSRS0000000249']\n",
    "err_file_size = []\n",
    "\n",
    "for RSRSID in RSRSID_list:\n",
    "\n",
    "    base_dir        = 'C:/elsys/solar/_ONM/json_'+ RSRSID\n",
    "    save_dir        = 'C:/elsys/solar/_ONM/csv_'+ RSRSID+'/'\n",
    "    print(base_dir)\n",
    "    \n",
    "    column_list=['COMPANY_NM','SET_GEN_NM','GEN_ID','GEN_NM','CBP_GEN_ID','CAPACITY','PATN_DT','HR_01','HR_02','HR_03','HR_04','HR_05','HR_06','HR_07','HR_08','HR_09','HR_10','HR_11','HR_12','HR_13','HR_14','HR_15','HR_16','HR_17','HR_18','HR_19','HR_20','HR_21','HR_22','HR_23','HR_24']\n",
    "    COMPANY_NM=[]\n",
    "    PATN_DT=[]\n",
    "    GEN_NM=[]\n",
    "    CBP_GEN_ID=[]\n",
    "    SET_GEN_NM=[]\n",
    "    CAPACITY=[]\n",
    "    GEN_ID=[]\n",
    "    HR_01=[]\n",
    "    HR_02=[]\n",
    "    HR_03=[]\n",
    "    HR_04=[]\n",
    "    HR_05=[]\n",
    "    HR_06=[]\n",
    "    HR_07=[]\n",
    "    HR_08=[]\n",
    "    HR_09=[]\n",
    "    HR_10=[]\n",
    "    HR_11=[]\n",
    "    HR_12=[]\n",
    "    HR_13=[]\n",
    "    HR_14=[]\n",
    "    HR_15=[]\n",
    "    HR_16=[]\n",
    "    HR_17=[]\n",
    "    HR_18=[]\n",
    "    HR_19=[]\n",
    "    HR_20=[]\n",
    "    HR_21=[]\n",
    "    HR_22=[]\n",
    "    HR_23=[]\n",
    "    HR_24=[]\n",
    "\n",
    "    json_pattern    = os.path.join(base_dir,'*.json')\n",
    "    file_list       = glob.glob(json_pattern)\n",
    "    #print(file_list)\n",
    "\n",
    "    for file in file_list:\n",
    "        with open(file, encoding='UTF-8') as json_file:\n",
    "            #print(file)\n",
    "            \n",
    "\n",
    "            # parsing json file\n",
    "            json_data = json.load(json_file)\n",
    "            data = json_data['result']\n",
    "            \n",
    "            \n",
    "            # 2. empty file check\n",
    "            file_size = os.path.getsize(file)\n",
    "            #print(file_size)\n",
    "            if file_size < 100:\n",
    "                err_file_size.append(file + \"/\" + str(file_size))#err2\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            COMPANY_NM.append(data['COMPANY_NM'])\n",
    "            SET_GEN_NM.append(data['SET_GEN_NM'])\n",
    "            GEN_ID.append(data['GEN_ID'])\n",
    "            GEN_NM.append(data['GEN_NM'])\n",
    "            CBP_GEN_ID.append(data['CBP_GEN_ID'])\n",
    "            CAPACITY.append(data['CAPACITY'])\n",
    "            PATN_DT.append(data['PATN_DT'])\n",
    "            HR_01.append(data['HR_01'])\n",
    "            HR_02.append(data['HR_02'])\n",
    "            HR_03.append(data['HR_03'])\n",
    "            HR_04.append(data['HR_04'])\n",
    "            HR_05.append(data['HR_05'])\n",
    "            HR_06.append(data['HR_06'])\n",
    "            HR_07.append(data['HR_07'])\n",
    "            HR_08.append(data['HR_08'])\n",
    "            HR_09.append(data['HR_09'])\n",
    "            HR_10.append(data['HR_10'])\n",
    "            HR_11.append(data['HR_11'])\n",
    "            HR_12.append(data['HR_12'])\n",
    "            HR_13.append(data['HR_13'])\n",
    "            HR_14.append(data['HR_14'])\n",
    "            HR_15.append(data['HR_15'])\n",
    "            HR_16.append(data['HR_16'])\n",
    "            HR_17.append(data['HR_17'])\n",
    "            HR_18.append(data['HR_18'])\n",
    "            HR_19.append(data['HR_19'])\n",
    "            HR_20.append(data['HR_20'])\n",
    "            HR_21.append(data['HR_21'])\n",
    "            HR_22.append(data['HR_22'])\n",
    "            HR_23.append(data['HR_23'])\n",
    "            HR_24.append(data['HR_24'])\n",
    "                    \n",
    "    df = pd.DataFrame(columns=column_list)\n",
    "    df['COMPANY_NM'] = COMPANY_NM\n",
    "    df['SET_GEN_NM'] = SET_GEN_NM\n",
    "    df['GEN_ID'] = GEN_ID\n",
    "    df['GEN_NM'] = GEN_NM\n",
    "    df['CBP_GEN_ID'] = CBP_GEN_ID\n",
    "    df['CAPACITY'] = CAPACITY\n",
    "    df['PATN_DT'] = PATN_DT\n",
    "    df['HR_01'] = HR_01\n",
    "    df['HR_02'] = HR_02\n",
    "    df['HR_03'] = HR_03\n",
    "    df['HR_04'] = HR_04\n",
    "    df['HR_05'] = HR_05\n",
    "    df['HR_06'] = HR_06\n",
    "    df['HR_07'] = HR_07\n",
    "    df['HR_08'] = HR_08\n",
    "    df['HR_09'] = HR_09\n",
    "    df['HR_10'] = HR_10\n",
    "    df['HR_11'] = HR_11\n",
    "    df['HR_12'] = HR_12\n",
    "    df['HR_13'] = HR_13\n",
    "    df['HR_14'] = HR_14\n",
    "    df['HR_15'] = HR_15\n",
    "    df['HR_16'] = HR_16\n",
    "    df['HR_17'] = HR_17\n",
    "    df['HR_18'] = HR_18\n",
    "    df['HR_19'] = HR_19\n",
    "    df['HR_20'] = HR_20\n",
    "    df['HR_21'] = HR_21\n",
    "    df['HR_22'] = HR_22\n",
    "    df['HR_23'] = HR_23\n",
    "    df['HR_24'] = HR_24\n",
    "    df.sort_values('PATN_DT')\n",
    "    \n",
    "    # save csv file\n",
    "    savefilenm = '_' + df.iloc[0,6].replace(\"-\",\"\") + '_' + df.iloc[-1,6].replace(\"-\",\"\") + '.csv'\n",
    "    df.to_csv(save_dir + savefilenm, index=False, header=True, encoding='CP949')\n",
    "    \n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"\\t FILE SIZE ERROR > file path / file size\")\n",
    "for f in err_file_size:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor data\n",
    "id\n",
    "loc_oid\n",
    "TIME\n",
    "solarradiation\n",
    "uv\n",
    "temp\n",
    "humidity\n",
    "winddir\n",
    "windspeed\n",
    "windgust\n",
    "dewpoint\n",
    "maxdailygust\n",
    "feelslike\n",
    "hourlyrainin\n",
    "dailyrainin\n",
    "weeklyrainin\n",
    "monthlyrainin\n",
    "yearlyrainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19854\t46204\t45504\t44929\t45565\t45814\t45920\t46069\t45619\t45268\t45299\t45961\t45130\t45541\t45106\t44847\t45514\t45207\t45785\t46124\t46130\t45880\t42422\t45910\t45252\t45330\t45467\t45127\t45198\t45573\t45960\t45292\t46068\t46213\t45765\t44813\t45568\t45569\t45289\t45043\t45385\t39433\t45394\t46103\t45788\t45421\t45199\t46626\t45791\t45792\t45275\t46639\t45970\t45667\t45979\t45492\t45403\t45208\t46164\t46304\t45607\t45889\t45587\t45309\t45389\t44551\t45785\t45253\t45953\t45668\t45697\t46152\t45818\t45479\t46393\t46475\t46389\t45724\t46251\t46205\t46137\t44793\t45163\t45478\t45194\t46148\t45862\t45605\t45316\t45499\t45760\t45875\t46305\t46592\t45439\t45894\t46244\t46532\t45869\t46121\t46099\t45414\t45882\t45951\t45858\t45817\t45750\t46380\t45458\t45609\t45931\t45462\t46540\t46326\t46188\t45744\t46140\t45991\t45512\t46749\t46214\t46077\t45532\t\n",
      "-----------------------------------------------------------------\n",
      "\t FILE SIZE ERROR > file path / file size\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "# .json -> .csv\n",
    "\n",
    "\n",
    "base_dir        = 'C:/elsys/solar/'\n",
    "sensor_dir      = base_dir + '_SENSOR/json'\n",
    "save_dir        = base_dir + '_SENSOR/csv/'\n",
    "\n",
    "column_list     = ['id','loc_oid','TIME','solarradiation','uv','temp','humidity','winddir','windspeed','windgust','dewpoint','maxdailygust','feelslike','hourlyrainin','dailyrainin','weeklyrainin','monthlyrainin','yearlyrainin']\n",
    "err_file_size = []\n",
    "\n",
    "json_pattern    = os.path.join(sensor_dir,'*.json')\n",
    "file_list       = glob.glob(json_pattern)\n",
    "\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file) as json_file:\n",
    "        \n",
    "        # parsing json file\n",
    "        json_data = json.load(json_file)\n",
    "        data = json_data['result']\n",
    "\n",
    "        \n",
    "        # 2. empty file check\n",
    "        file_size = os.path.getsize(file)\n",
    "        print(str(file_size)+'\\t',end='')\n",
    "        if file_size < 100:\n",
    "            err_file_size.append(file + \"/\" + str(file_size))#err2\n",
    "            continue\n",
    "            \n",
    "        _id              = []\n",
    "        loc_oid          = []\n",
    "        TIME             = []\n",
    "        solarradiation   = []\n",
    "        uv               = []\n",
    "        temp             = []\n",
    "        humidity         = []\n",
    "        winddir          = []\n",
    "        windspeed        = []\n",
    "        windgust         = []\n",
    "        dewpoint         = []\n",
    "        maxdailygust     = []\n",
    "        feelslike        = []\n",
    "        hourlyrainin     = []\n",
    "        dailyrainin      = []\n",
    "        weeklyrainin     = []\n",
    "        monthlyrainin    = []\n",
    "        yearlyrainin     = []\n",
    "        \n",
    "\n",
    "\n",
    "        for dataline in data:\n",
    "            #print(dataline)\n",
    "            _id.append(dataline['id'])\n",
    "            loc_oid.append(dataline['loc_oid'])\n",
    "            TIME.append(dataline['TIME'])\n",
    "            solarradiation.append(dataline['solarradiation'])\n",
    "            uv.append(dataline['uv'])\n",
    "            temp.append(dataline['temp'])\n",
    "            humidity.append(dataline['humidity'])\n",
    "            winddir.append(dataline['winddir'])\n",
    "            windspeed.append(dataline['windspeed'])\n",
    "            windgust.append(dataline['windgust'])\n",
    "            dewpoint.append(dataline['dewpoint'])\n",
    "            maxdailygust.append(dataline['maxdailygust'])\n",
    "            feelslike.append(dataline['feelslike'])\n",
    "            hourlyrainin.append(dataline['hourlyrainin'])\n",
    "            dailyrainin.append(dataline['dailyrainin'])\n",
    "            weeklyrainin.append(dataline['weeklyrainin'])\n",
    "            monthlyrainin.append(dataline['monthlyrainin'])\n",
    "            yearlyrainin.append(dataline['yearlyrainin'])\n",
    "            \n",
    "            \n",
    "                \n",
    "        df = pd.DataFrame(columns=column_list)\n",
    "        df['id'] = _id\n",
    "        df['loc_oid'] = loc_oid\n",
    "        df['TIME'] = TIME\n",
    "        df['solarradiation'] = solarradiation\n",
    "        df['uv'] = uv\n",
    "        df['temp'] = temp\n",
    "        df['humidity'] = humidity\n",
    "        df['winddir'] = winddir\n",
    "        df['windspeed'] = windspeed\n",
    "        df['windgust'] = windgust\n",
    "        df['dewpoint'] = dewpoint\n",
    "        df['maxdailygust'] = maxdailygust\n",
    "        df['feelslike'] = feelslike\n",
    "        df['hourlyrainin'] = hourlyrainin\n",
    "        df['dailyrainin'] = dailyrainin\n",
    "        df['weeklyrainin'] = weeklyrainin\n",
    "        df['monthlyrainin'] = monthlyrainin\n",
    "        df['yearlyrainin'] = yearlyrainin\n",
    "        \n",
    "        # save csv file\n",
    "        df.to_csv(save_dir + file[-13:-5] + '.csv', index=False, header=True)\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------\")\n",
    "print(\"\\t FILE SIZE ERROR > file path / file size\")\n",
    "for f in err_file_size:\n",
    "    print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
