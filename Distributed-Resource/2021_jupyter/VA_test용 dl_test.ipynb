{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n",
      "14\n",
      "OBS_ASOS_TIM_20200929025447.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\core\\_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\core\\_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\core\\_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\core\\_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before :  (5344, 18)\n",
      "after :  (5344, 7)\n",
      "len(dataX) :  327 (48, 8)\n",
      "len(dataY) :  327 (16, 1)\n",
      "train X :  (228, 48, 8) \tY :  (228, 16, 1)\n",
      "val   X :  (65, 48, 8) \tY :  (65, 16, 1)\n",
      "test  X :  (34, 48, 8) \tY :  (34, 16, 1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f00009543c90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRepeatVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhoursteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[1;34m(self, name, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_base_init\u001b[1;34m(self, name, trainable, dtype)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[1;34m(prefix)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         raise RuntimeError(\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[1;34m'It looks like you are trying to use '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;34m'a version of multi-backend Keras that '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
     ]
    }
   ],
   "source": [
    "#---- to do list -----\n",
    "# err_data_list 파일자동화\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow.python.keras.optimizer_v2.rmsprop import RMSProp\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, RepeatVector, LSTM, Input, TimeDistributed, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#pow 낮값만 추출 test\n",
    "#pow = 0인 구간 : 0~4, 21-23시\n",
    "powhr_start = 5\n",
    "powhr_end   = 20\n",
    "\n",
    "shift_days  = 3\n",
    "hoursteps   = powhr_end-powhr_start+1 #(16)\n",
    "timesteps   = shift_days*hoursteps #hours step\n",
    "\n",
    "data_dim    = 7\n",
    "out_dim     = 1\n",
    "n_model    = 10\n",
    "\n",
    "data_dir  = 'C:/Users/VISLAB_PHY/Desktop/Workspace/Data'\n",
    "\n",
    "season_mod = 'all_1102_f7'\n",
    "date_start = '10190901'\n",
    "date_end   = '30191201'\n",
    "\n",
    "err_date_list = ['20190912',\n",
    "                    '20191122',\n",
    "                    '20191130',\n",
    "                    '20191217',\n",
    "                    '20200501',\n",
    "                    '20200502',\n",
    "                    '20191028',\n",
    "                    '20191107',\n",
    "                    '20191108',\n",
    "                    '20191109',\n",
    "                    '20191110',\n",
    "                    '20191111',\n",
    "                    '20191112',\n",
    "                    '20200214',\n",
    "                    '20200307',\n",
    "                    '20200308',\n",
    "                    '20200309',\n",
    "                    '20200310',\n",
    "                    '20200328',\n",
    "                    '20200329',\n",
    "                    '20200625',\n",
    "                    '20200809']\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer \n",
    "\n",
    "transf_type = 'yeo-johnson'\n",
    "#transf_type = 'box-cox'\n",
    "\n",
    "def yeo_johnson_transform(dataset):\n",
    "    \n",
    "    column_trans = ColumnTransformer(\n",
    "                    [('sunshine', PowerTransformer(method=transf_type, standardize=True), ['sunshine']),\n",
    "                     ('humdt', PowerTransformer(method=transf_type, standardize=True), ['humdt']),\n",
    "                     ('wnd_spd', PowerTransformer(method=transf_type, standardize=True), ['wnd_spd']),\n",
    "                     ('visiblt', PowerTransformer(method=transf_type, standardize=True), ['visiblt']),\n",
    "                     ('cloud2', PowerTransformer(method=transf_type, standardize=True), ['cloud2']),\n",
    "                     ('cloud', PowerTransformer(method=transf_type, standardize=True), ['cloud']),\n",
    "                     ('grd_temprt', PowerTransformer(method=transf_type, standardize=True), ['grd_temprt']),\n",
    "                     ('wnd_dir', PowerTransformer(method=transf_type, standardize=True), ['wnd_dir']),\n",
    "                     ('dewpnt', PowerTransformer(method=transf_type, standardize=True), ['dewpnt']),\n",
    "                     ('steampressr', PowerTransformer(method=transf_type, standardize=True), ['steampressr']),\n",
    "                     ('temprt', PowerTransformer(method=transf_type, standardize=True), ['temprt']),\n",
    "                     ('mincloud', PowerTransformer(method=transf_type, standardize=True), ['mincloud']),\n",
    "                     ('rain', PowerTransformer(method=transf_type, standardize=True), ['rain']),\n",
    "                     ('pressr', PowerTransformer(method=transf_type, standardize=True), ['pressr']),\n",
    "                     ('seapressr', PowerTransformer(method=transf_type, standardize=True), ['seapressr']),\n",
    "                     ('snow', PowerTransformer(method=transf_type, standardize=True), ['snow'])\n",
    "                    ])\n",
    "    \n",
    "    transformed_data = column_trans.fit_transform(dataset)\n",
    "    transformed_df = pd.DataFrame(transformed_data, columns=dataset.columns)\n",
    "    pd.concat([transformed_df], axis = 1)\n",
    "                    \n",
    "    return transformed_df\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch\n",
    "from pandas import read_csv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer \n",
    "#from feature_engine import variable_transformers as vt\n",
    "from scipy.stats import yeojohnson\n",
    "\n",
    "#############################################\n",
    "# 태양광 전력\n",
    "#############################################\n",
    "def get_pow():\n",
    "\n",
    "    # pow 파일 load\n",
    "    dir_path    = data_dir+\"/pow_24/UR00000126_csv\"\n",
    "    file_list   = os.listdir(dir_path)\n",
    "    print(len(file_list))\n",
    "    hrPow  = []    \n",
    "\n",
    "    # pow측정값 에러가 큰 일자 제거\n",
    "    for filename in file_list:\n",
    "        if (filename[:-4] not in err_date_list):\n",
    "            if ((filename[:-4]>=date_start) & (filename<date_end)):\n",
    "                filedata = pd.read_csv(dir_path+'/'+filename).values[:,0]\n",
    "                hrPow.append(filedata)\n",
    "                \n",
    "    #낮시간 추출 (5~20시)\n",
    "    pow_dataset = pd.DataFrame(hrPow)\n",
    "    pow_dataset =pow_dataset.iloc[:,powhr_start:powhr_end+1]\n",
    "    #pow_dataset.to_csv(\"C:/Users/VISLAB_PHY/Desktop/WORKSPACE/Origin/data/pow_hr.csv\",mode='w',index=False)\n",
    "\n",
    "    # 결측값 보간, reshape\n",
    "    pow_dataset = pow_dataset.interpolate(method='linear')\n",
    "    pow_dataset = pow_dataset.values.reshape(-1,1)\n",
    "    pow_dataset = pd.DataFrame(pow_dataset)\n",
    "    pow_dataset.columns = ['pow']\n",
    "    pow_dataset.to_csv(data_dir+\"/pow.csv\",mode='w',index=False)\n",
    "\n",
    "    \n",
    "    # scale\n",
    "    sc_pow = MinMaxScaler(feature_range = (0, 1))\n",
    "    scaled_pow = sc_pow.fit_transform(pow_dataset.values)\n",
    "    df_pow = pd.DataFrame(scaled_pow, columns=pow_dataset.columns, index=list(pow_dataset.index.values))\n",
    "    \n",
    "    return df_pow, sc_pow\n",
    "\n",
    "#############################################\n",
    "# 종관기상관측\n",
    "#############################################\n",
    "def get_weather():\n",
    "    # pow 파일 load\n",
    "    file_list   = os.listdir(data_dir)\n",
    "    print(len(file_list))\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if fnmatch.fnmatch(filename, 'OBS_ASOS_TIM_*.csv'):\n",
    "            print(filename)\n",
    "\n",
    "            # load csv data\n",
    "            dataset = read_csv(data_dir+'/'+filename, encoding='CP949')\n",
    "            dataset.drop(['지점','지점명'], axis=1, inplace=True)\n",
    "            dataset.drop(['기온 QC플래그','강수량 QC플래그','풍속 QC플래그','풍향 QC플래그','습도 QC플래그'], axis=1, inplace=True)\n",
    "            dataset.drop(['현지기압 QC플래그','해면기압 QC플래그','일조 QC플래그','지면온도 QC플래그'], axis=1, inplace=True)\n",
    "            dataset.drop(['5cm 지중온도(°C)','10cm 지중온도(°C)','20cm 지중온도(°C)','30cm 지중온도(°C)'], axis=1, inplace=True)\n",
    "            dataset.drop(['3시간신적설(cm)','일사(MJ/m2)','운형(운형약어)','지면상태(지면상태코드)','현상번호(국내식)'], axis=1, inplace=True)\n",
    "\n",
    "            # set column name\n",
    "            dataset.columns = ['ymdhms', 'temprt', 'rain', 'wnd_spd', 'wnd_dir', 'humdt','steampressr',\n",
    "                               'dewpnt', 'pressr','seapressr','sunshine','snow','cloud','cloud2','mincloud','visiblt','grd_temprt']\n",
    "\n",
    "            # prioirty sort (피어슨상관계수)\n",
    "            dataset = dataset[['ymdhms','sunshine','humdt','wnd_spd','visiblt','cloud2',\n",
    "                               'cloud','grd_temprt','wnd_dir','dewpnt','steampressr','temprt',\n",
    "                               'mincloud','rain','pressr','seapressr','snow']]\n",
    "\n",
    "\n",
    "            # set NA data (관측값 0이 누적되어 결측된 경우. 0으로 세팅)\n",
    "            dataset['rain'].fillna(0, inplace=True)     #강수량\n",
    "            dataset['sunshine'].fillna(0, inplace=True) #일조\n",
    "            dataset['snow'].fillna(0, inplace=True)     #적설량\n",
    "\n",
    "            #일시 패턴 변환(2019-08-20 5:00 -> 2019082005)\n",
    "            dataset['ymdhms'] = dataset['ymdhms'].str[0:4]+dataset['ymdhms'].str[5:7]+dataset['ymdhms'].str[8:10]+dataset['ymdhms'].str[11:13]\n",
    "            # pow측정값 중 결측값 많은 일자 제거\n",
    "            dataset = dataset[(dataset['ymdhms'].str[0:8]>=date_start) & (dataset['ymdhms'].str[0:8]<date_end)]\n",
    "            for err_date in err_date_list:\n",
    "                idx_err = dataset[dataset['ymdhms'].str.startswith(err_date)].index\n",
    "                dataset = dataset.drop(idx_err)\n",
    "\n",
    "            #낮시간 추출 (5~20시)\n",
    "            dataset = dataset[(dataset['ymdhms'].str[-2:]>=str(powhr_start).rjust(2, '0')) &(dataset['ymdhms'].str[-2:]<=str(powhr_end))]\n",
    "            dataset = dataset.interpolate(method='linear')# 결측값 보간\n",
    "            \n",
    "            # save file (test용)\n",
    "            dataset.to_csv(data_dir+\"/weather.csv\",mode='w',index=False)\n",
    "\n",
    "            # normalization\n",
    "            dataset.drop(['ymdhms'], axis=1, inplace=True)\n",
    "            dataset = dataset.astype('float32')\n",
    "            dataset = dataset.interpolate(method='linear')\n",
    "            \n",
    "            #YEO-JOHNSON transform\n",
    "            yeo_df = yeo_johnson_transform(dataset)\n",
    "            \n",
    "            #insert feature (test)\n",
    "            yeo_df.insert(2, 'temp_press', yeo_df['temprt']-yeo_df['steampressr'], True)\n",
    "            yeo_df.insert(2, 'sunshine_humdt', abs(yeo_df['sunshine'])-(yeo_df['humdt']*(2.1)), True)#0.35\n",
    "            \n",
    "            sc = MinMaxScaler(feature_range = (0, 1))#scale\n",
    "            scaled_weather = sc.fit_transform(yeo_df.values)\n",
    "            weather = pd.DataFrame(scaled_weather, columns=yeo_df.columns, index=list(yeo_df.index.values))\n",
    "            print(\"before : \", weather.shape)\n",
    "            weather = weather.iloc[:, 0:data_dim] #feature size 조절\n",
    "            print(\"after : \", weather.shape)\n",
    "            \n",
    "    return weather\n",
    "\n",
    "\n",
    "#############################################\n",
    "# numpy data 만들기\n",
    "#############################################\n",
    "\n",
    "df_pow, sc_pow   = get_pow()\n",
    "df               = get_weather()\n",
    "\n",
    "# pow + weather + powY\n",
    "df.insert(0, 'pow', df_pow.values, True)\n",
    "df = df.iloc[0:-timesteps, :]\n",
    "df.insert(df.shape[1], 'pow_Y', df_pow.iloc[timesteps:, :].values, True)\n",
    "\n",
    "df.to_csv(data_dir+\"/total.csv\",mode='w',index=False, encoding='CP949')\n",
    "\n",
    "#----------------------------------------------\n",
    "# time step만큼 window 움직여 dataset 생성\n",
    "#----------------------------------------------\n",
    "totalsize = df.shape[0]\n",
    "dataX, dataY = [], []\n",
    "\n",
    "for i in range(0, totalsize-timesteps-24+1, hoursteps):\n",
    "    dataX.append(df.iloc[i:(i + timesteps),0:-1])\n",
    "    dataY.append(df.iloc[i:(i + hoursteps),[0]])\n",
    "\n",
    "print(\"len(dataX) : \", len(dataX), dataX[0].shape)\n",
    "print(\"len(dataY) : \", len(dataY), dataY[0].shape)\n",
    "\n",
    "#----------------------------------------------\n",
    "#  Split train/test \n",
    "#----------------------------------------------\n",
    "\n",
    "train_size = int(len(dataX) * 0.7)\n",
    "val_size   = int(len(dataX) * 0.2)\n",
    "test_size  = len(dataX) - train_size - val_size\n",
    "val_idx = train_size+val_size\n",
    "\n",
    "trainX, valX, testX = np.array(dataX[0:train_size]), np.array(dataX[train_size:val_idx]), np.array(dataX[val_idx:val_idx+test_size])\n",
    "trainY, valY, testY = np.array(dataY[0:train_size]), np.array(dataY[train_size:val_idx]), np.array(dataY[val_idx:val_idx+test_size])\n",
    "\n",
    "print('train X : ', trainX.shape, '\\tY : ', trainY.shape)\n",
    "print('val   X : ', valX.shape,   '\\tY : ', valY.shape)\n",
    "print('test  X : ', testX.shape,  '\\tY : ', testY.shape)\n",
    "\n",
    "np.save(\"npset/\"+season_mod+\"_trainX\",trainX)\n",
    "np.save(\"npset/\"+season_mod+\"_trainY\",trainY)\n",
    "np.save(\"npset/\"+season_mod+\"_valX\",valX)\n",
    "np.save(\"npset/\"+season_mod+\"_valY\",valY)\n",
    "np.save(\"npset/\"+season_mod+\"_testX\",testX)\n",
    "np.save(\"npset/\"+season_mod+\"_testY\",testY)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(RepeatVector(hoursteps))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 65 samples\n",
      "Epoch 1/300\n",
      "228/228 [==============================] - 1s 4ms/step - loss: 0.1358 - val_loss: 0.0410\n",
      "Epoch 2/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.0359\n",
      "Epoch 3/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 4/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0375 - val_loss: 0.0331\n",
      "Epoch 5/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.0452\n",
      "Epoch 6/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0315\n",
      "Epoch 7/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.0953\n",
      "Epoch 8/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0307\n",
      "Epoch 9/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0354\n",
      "Epoch 10/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0285 - val_loss: 0.0222\n",
      "Epoch 11/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0475 - val_loss: 0.0342\n",
      "Epoch 12/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0317 - val_loss: 0.0273\n",
      "Epoch 13/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0239\n",
      "Epoch 14/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0235 - val_loss: 0.0460\n",
      "Epoch 15/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0272 - val_loss: 0.0204\n",
      "Epoch 16/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0219\n",
      "Epoch 17/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0396\n",
      "Epoch 18/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0260 - val_loss: 0.0458\n",
      "Epoch 19/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0526\n",
      "Epoch 20/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0197\n",
      "Epoch 21/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0227\n",
      "Epoch 22/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0241\n",
      "Epoch 23/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0159\n",
      "Epoch 24/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0355\n",
      "Epoch 25/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0287\n",
      "Epoch 26/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0392\n",
      "Epoch 27/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0202\n",
      "Epoch 28/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0196\n",
      "Epoch 29/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0178\n",
      "Epoch 30/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0182\n",
      "Epoch 31/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0421\n",
      "Epoch 32/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0192\n",
      "Epoch 33/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0183\n",
      "Epoch 34/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0272\n",
      "Epoch 35/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0177\n",
      "Epoch 36/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 37/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0160\n",
      "Epoch 38/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0230\n",
      "Epoch 39/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0216\n",
      "Epoch 40/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 41/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0180\n",
      "Epoch 42/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0087\n",
      "Epoch 43/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 44/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 45/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 46/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0262\n",
      "Epoch 47/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0079\n",
      "Epoch 48/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 49/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0124\n",
      "Epoch 50/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 51/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0088\n",
      "Epoch 52/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 53/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 54/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 55/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0185\n",
      "Epoch 56/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0196\n",
      "Epoch 57/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 58/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0124\n",
      "Epoch 59/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0080\n",
      "Epoch 60/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0187\n",
      "Epoch 61/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0155\n",
      "Epoch 62/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0165\n",
      "Epoch 63/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0192\n",
      "Epoch 64/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 65/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 66/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 67/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 68/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 69/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0166\n",
      "Epoch 70/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 71/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0212\n",
      "Epoch 72/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0068\n",
      "Epoch 73/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 74/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 75/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 76/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 77/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 78/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 79/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0124\n",
      "Epoch 80/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 82/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0174\n",
      "Epoch 83/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0071\n",
      "Epoch 84/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 85/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0073\n",
      "Epoch 86/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 87/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 88/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 89/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 90/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 91/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0193\n",
      "Epoch 92/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 93/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0121\n",
      "Epoch 94/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 95/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0147\n",
      "Epoch 96/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 97/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0157\n",
      "Epoch 98/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 99/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 100/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 101/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 102/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 103/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 104/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 105/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0084\n",
      "Epoch 106/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 107/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 108/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0154\n",
      "Epoch 109/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 110/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 111/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 112/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 113/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 114/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 115/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0093\n",
      "Epoch 116/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 117/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 118/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 119/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0246\n",
      "Epoch 120/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 121/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 122/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 123/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 124/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 125/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 126/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 127/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 128/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 129/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 130/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0067\n",
      "Epoch 131/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 132/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 133/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 134/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0084\n",
      "Epoch 135/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0133\n",
      "Epoch 136/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 137/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0073\n",
      "Epoch 138/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 139/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 140/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0073\n",
      "Epoch 141/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 142/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 143/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 144/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 145/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 146/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 147/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 148/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 149/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 150/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0076\n",
      "Epoch 151/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0067\n",
      "Epoch 152/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 153/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 154/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 155/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 156/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 157/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 158/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 159/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 160/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 161/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0085\n",
      "Epoch 162/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 163/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 164/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 165/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 166/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 167/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0154\n",
      "Epoch 168/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 169/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 170/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 171/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 172/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 173/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0128\n",
      "Epoch 174/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 175/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 176/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 177/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 178/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0118\n",
      "Epoch 179/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 180/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 181/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 182/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 183/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 184/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 185/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 186/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 187/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 188/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 189/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 190/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 191/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 192/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 193/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 194/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 195/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 196/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0076\n",
      "Epoch 197/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 198/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 199/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 200/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 201/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 202/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 203/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 204/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 205/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 206/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 207/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 208/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0083\n",
      "Epoch 209/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 210/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 211/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 212/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 213/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0206\n",
      "Epoch 214/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 215/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 216/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 217/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 218/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 219/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 220/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 221/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 222/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 223/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 224/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 225/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 226/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 227/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 228/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 229/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 230/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 231/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 232/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 233/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 234/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 235/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 236/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 237/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 238/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 240/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 241/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 242/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 243/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 244/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 245/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 246/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0070\n",
      "Epoch 247/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 248/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 249/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 250/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 251/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 252/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 253/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 254/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 255/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 256/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 257/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 258/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 259/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 260/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 261/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 262/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 263/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 264/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 265/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 266/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 267/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 268/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0069\n",
      "Epoch 269/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 270/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 271/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 272/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 273/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 274/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 275/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 276/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 277/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 278/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 279/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 280/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 281/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 282/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 283/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 284/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 285/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 286/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 287/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 288/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0088\n",
      "Epoch 289/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 290/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 291/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 292/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 293/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 294/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 295/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 296/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 297/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 298/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 299/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 300/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 65 samples\n",
      "Epoch 1/300\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 2/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 3/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 4/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 5/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 6/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 7/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 8/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 9/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 10/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 11/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 12/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 13/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 14/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 15/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 16/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 17/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 18/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 19/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 20/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 21/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 22/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 23/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 24/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 25/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 26/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 27/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0073\n",
      "Epoch 28/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 29/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 30/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 31/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 32/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 33/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 34/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 35/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 36/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 37/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 38/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 39/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 40/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 41/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 42/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 43/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 44/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 45/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 46/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 47/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 48/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 49/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 50/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 51/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0153\n",
      "Epoch 52/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 53/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0032\n",
      "Epoch 54/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 55/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 56/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 57/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 58/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 59/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 60/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 61/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 62/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 63/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 64/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 65/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 66/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 67/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 68/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 69/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 70/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 71/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 72/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 73/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 74/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 75/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 76/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 77/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 78/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 79/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 80/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 82/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 83/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 84/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 85/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 86/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 87/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 88/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 89/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 90/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 91/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 92/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 93/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 94/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 95/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 96/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.7007e-04 - val_loss: 0.0032\n",
      "Epoch 97/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 98/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 99/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 100/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 101/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 102/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 103/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 104/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 105/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 106/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 107/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 108/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 109/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 110/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 111/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 112/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 113/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 114/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 115/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 116/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 117/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 118/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 119/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 120/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 121/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 122/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 123/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 124/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 125/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 126/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 127/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 128/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 129/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 130/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 131/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 132/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 133/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 134/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 135/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 136/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 137/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 138/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.1882e-04 - val_loss: 0.0034\n",
      "Epoch 139/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 140/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 141/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 142/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 143/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 144/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 145/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 146/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0137\n",
      "Epoch 147/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 148/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.2632e-04 - val_loss: 0.0030\n",
      "Epoch 149/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 150/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 151/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 152/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 153/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 154/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 155/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 156/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 157/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.9706e-04 - val_loss: 0.0032\n",
      "Epoch 158/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 159/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 160/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 161/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.9674e-04 - val_loss: 0.0028\n",
      "Epoch 162/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 163/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 164/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 165/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 166/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 167/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.4583e-04 - val_loss: 0.0034\n",
      "Epoch 168/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 169/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 170/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 171/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 172/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.7480e-04 - val_loss: 0.0039\n",
      "Epoch 173/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 174/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 175/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 176/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 177/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.4545e-04 - val_loss: 0.0034\n",
      "Epoch 178/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 179/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 180/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 181/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 182/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 183/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 184/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.3507e-04 - val_loss: 0.0049\n",
      "Epoch 185/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 186/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 187/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 188/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 189/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.6491e-04 - val_loss: 0.0029\n",
      "Epoch 190/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.4059e-04 - val_loss: 0.0025\n",
      "Epoch 191/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 192/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 193/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 194/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 195/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 196/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 197/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.3942e-04 - val_loss: 0.0034\n",
      "Epoch 198/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 199/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 200/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 201/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 202/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 203/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.9549e-04 - val_loss: 0.0027\n",
      "Epoch 204/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 205/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 206/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 207/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 208/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.0244e-04 - val_loss: 0.0025\n",
      "Epoch 209/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 210/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 211/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 212/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 213/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 214/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.5981e-04 - val_loss: 0.0042\n",
      "Epoch 215/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 216/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 217/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 218/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.7915e-04 - val_loss: 0.0036\n",
      "Epoch 219/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.8225e-04 - val_loss: 0.0063\n",
      "Epoch 220/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 221/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 222/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 223/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 224/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 225/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.4070e-04 - val_loss: 0.0030\n",
      "Epoch 226/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.8684e-04 - val_loss: 0.0033\n",
      "Epoch 227/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.9092e-04 - val_loss: 0.0031\n",
      "Epoch 228/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.4457e-04 - val_loss: 0.0030\n",
      "Epoch 229/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 230/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 231/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 232/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.7939e-04 - val_loss: 0.0034\n",
      "Epoch 233/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.8769e-04 - val_loss: 0.0035\n",
      "Epoch 234/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 235/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.4221e-04 - val_loss: 0.0041\n",
      "Epoch 236/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 237/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 238/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 240/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 241/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.7203e-04 - val_loss: 0.0034\n",
      "Epoch 242/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 243/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.5380e-04 - val_loss: 0.0030\n",
      "Epoch 244/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.9649e-04 - val_loss: 0.0034\n",
      "Epoch 245/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.7668e-04 - val_loss: 0.0043\n",
      "Epoch 246/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 247/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 248/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 249/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.7183e-04 - val_loss: 0.0030\n",
      "Epoch 250/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.2115e-04 - val_loss: 0.0031\n",
      "Epoch 251/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.3309e-04 - val_loss: 0.0033\n",
      "Epoch 252/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 253/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 254/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 255/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 256/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 257/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.0277e-04 - val_loss: 0.0032\n",
      "Epoch 258/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.5311e-04 - val_loss: 0.0040\n",
      "Epoch 259/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 260/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 261/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 262/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 263/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.5191e-04 - val_loss: 0.0042\n",
      "Epoch 264/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 265/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 266/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 267/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.1606e-04 - val_loss: 0.0038\n",
      "Epoch 268/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 269/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.5853e-04 - val_loss: 0.0030\n",
      "Epoch 270/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.2137e-04 - val_loss: 0.0041\n",
      "Epoch 271/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0104\n",
      "Epoch 272/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 273/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.0303e-04 - val_loss: 0.0031\n",
      "Epoch 274/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.4098e-04 - val_loss: 0.0030\n",
      "Epoch 275/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.9534e-04 - val_loss: 0.0037\n",
      "Epoch 276/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 277/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 278/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 279/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0035\n",
      "Epoch 280/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.2609e-04 - val_loss: 0.0039\n",
      "Epoch 281/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.8302e-04 - val_loss: 0.0031\n",
      "Epoch 282/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.6883e-04 - val_loss: 0.0029\n",
      "Epoch 283/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.2237e-04 - val_loss: 0.0036\n",
      "Epoch 284/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 285/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 286/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 287/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.0960e-04 - val_loss: 0.0035\n",
      "Epoch 288/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.2081e-04 - val_loss: 0.0037\n",
      "Epoch 289/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 290/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 291/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0035\n",
      "Epoch 292/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.5528e-04 - val_loss: 0.0039\n",
      "Epoch 293/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.8932e-04 - val_loss: 0.0031\n",
      "Epoch 294/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8036e-04 - val_loss: 0.0041\n",
      "Epoch 295/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 296/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.5986e-04 - val_loss: 0.0035\n",
      "Epoch 297/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 298/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 299/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.1947e-04 - val_loss: 0.0042\n",
      "Epoch 300/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.4560e-04 - val_loss: 0.0037\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 65 samples\n",
      "Epoch 1/300\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 2/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 3/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.1129e-04 - val_loss: 0.0035\n",
      "Epoch 4/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.8310e-04 - val_loss: 0.0033\n",
      "Epoch 5/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.9788e-04 - val_loss: 0.0032\n",
      "Epoch 6/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.9981e-04 - val_loss: 0.0033\n",
      "Epoch 7/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.0885e-04 - val_loss: 0.0034\n",
      "Epoch 8/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 9/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 10/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8537e-04 - val_loss: 0.0041\n",
      "Epoch 11/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 12/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.3671e-04 - val_loss: 0.0030\n",
      "Epoch 13/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 14/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 15/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.0433e-04 - val_loss: 0.0030\n",
      "Epoch 16/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1200e-04 - val_loss: 0.0032\n",
      "Epoch 17/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 18/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 19/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 20/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8850e-04 - val_loss: 0.0034\n",
      "Epoch 21/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.2594e-04 - val_loss: 0.0031\n",
      "Epoch 22/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1245e-04 - val_loss: 0.0036\n",
      "Epoch 23/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.6810e-04 - val_loss: 0.0049\n",
      "Epoch 24/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 25/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.7818e-04 - val_loss: 0.0035\n",
      "Epoch 26/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 27/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 28/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.4156e-04 - val_loss: 0.0033\n",
      "Epoch 29/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.6179e-04 - val_loss: 0.0032\n",
      "Epoch 30/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.2224e-04 - val_loss: 0.0052\n",
      "Epoch 31/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 32/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 33/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8912e-04 - val_loss: 0.0036\n",
      "Epoch 34/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8878e-04 - val_loss: 0.0040\n",
      "Epoch 35/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.9466e-04 - val_loss: 0.0054\n",
      "Epoch 36/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.9003e-04 - val_loss: 0.0041\n",
      "Epoch 37/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 38/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 39/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 40/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.0713e-04 - val_loss: 0.0043\n",
      "Epoch 41/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.1000e-04 - val_loss: 0.0038\n",
      "Epoch 42/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.0267e-04 - val_loss: 0.0034\n",
      "Epoch 43/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.5359e-04 - val_loss: 0.0032\n",
      "Epoch 44/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 45/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.9486e-04 - val_loss: 0.0033\n",
      "Epoch 46/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1597e-04 - val_loss: 0.0033\n",
      "Epoch 47/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.3457e-04 - val_loss: 0.0037\n",
      "Epoch 48/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.3876e-04 - val_loss: 0.0065\n",
      "Epoch 49/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 50/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.8901e-04 - val_loss: 0.0039\n",
      "Epoch 51/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.0254e-04 - val_loss: 0.0039\n",
      "Epoch 52/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.3482e-04 - val_loss: 0.0045\n",
      "Epoch 53/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 54/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 55/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8293e-04 - val_loss: 0.0043\n",
      "Epoch 56/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.9919e-04 - val_loss: 0.0037\n",
      "Epoch 57/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.2485e-04 - val_loss: 0.0034\n",
      "Epoch 58/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.9089e-04 - val_loss: 0.0032\n",
      "Epoch 59/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 60/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.5998e-04 - val_loss: 0.0032\n",
      "Epoch 61/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 62/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 63/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.7772e-04 - val_loss: 0.0031\n",
      "Epoch 64/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.5572e-04 - val_loss: 0.0030\n",
      "Epoch 65/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.5866e-04 - val_loss: 0.0032\n",
      "Epoch 66/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.7907e-04 - val_loss: 0.0030\n",
      "Epoch 67/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.9006e-04 - val_loss: 0.0032\n",
      "Epoch 68/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.2401e-04 - val_loss: 0.0031\n",
      "Epoch 69/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0033\n",
      "Epoch 70/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0031\n",
      "Epoch 71/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 72/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.1259e-04 - val_loss: 0.0035\n",
      "Epoch 73/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.9151e-04 - val_loss: 0.0073\n",
      "Epoch 74/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 75/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.0765e-04 - val_loss: 0.0041\n",
      "Epoch 76/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.6708e-04 - val_loss: 0.0046\n",
      "Epoch 77/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.9097e-04 - val_loss: 0.0044\n",
      "Epoch 78/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.1491e-04 - val_loss: 0.0039\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 1ms/step - loss: 7.7576e-04 - val_loss: 0.0053\n",
      "Epoch 80/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.3915e-04 - val_loss: 0.0054\n",
      "Epoch 81/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 82/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 83/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.8054e-04 - val_loss: 0.0032\n",
      "Epoch 84/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.3520e-04 - val_loss: 0.0026\n",
      "Epoch 85/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0034\n",
      "Epoch 86/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.2471e-04 - val_loss: 0.0035\n",
      "Epoch 87/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.0643e-04 - val_loss: 0.0055\n",
      "Epoch 88/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 89/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.8934e-04 - val_loss: 0.0037\n",
      "Epoch 90/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.4344e-04 - val_loss: 0.0045\n",
      "Epoch 91/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.9438e-04 - val_loss: 0.0031\n",
      "Epoch 92/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.6275e-04 - val_loss: 0.0036\n",
      "Epoch 93/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 94/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.3709e-04 - val_loss: 0.0032\n",
      "Epoch 95/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.8666e-04 - val_loss: 0.0035\n",
      "Epoch 96/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.5691e-04 - val_loss: 0.0031\n",
      "Epoch 97/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.0181e-04 - val_loss: 0.0032\n",
      "Epoch 98/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.7803e-04 - val_loss: 0.0035\n",
      "Epoch 99/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 100/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 101/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.8662e-04 - val_loss: 0.0032\n",
      "Epoch 102/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.5333e-04 - val_loss: 0.0032\n",
      "Epoch 103/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.9806e-04 - val_loss: 0.0035\n",
      "Epoch 104/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.8657e-04 - val_loss: 0.0036\n",
      "Epoch 105/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.0811e-04 - val_loss: 0.0034\n",
      "Epoch 106/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.9468e-04 - val_loss: 0.0043\n",
      "Epoch 107/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.9235e-04 - val_loss: 0.0063\n",
      "Epoch 108/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 109/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.9992e-04 - val_loss: 0.0040\n",
      "Epoch 110/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.3399e-04 - val_loss: 0.0045\n",
      "Epoch 111/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.9873e-04 - val_loss: 0.0043\n",
      "Epoch 112/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1706e-04 - val_loss: 0.0036\n",
      "Epoch 113/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 114/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.9649e-04 - val_loss: 0.0034\n",
      "Epoch 115/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.5481e-04 - val_loss: 0.0032\n",
      "Epoch 116/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.2994e-04 - val_loss: 0.0038\n",
      "Epoch 117/300\n",
      "228/228 [==============================] - ETA: 0s - loss: 5.2700e-0 - 0s 1ms/step - loss: 5.1618e-04 - val_loss: 0.0033\n",
      "Epoch 118/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.7037e-04 - val_loss: 0.0038\n",
      "Epoch 119/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 120/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.4406e-04 - val_loss: 0.0029\n",
      "Epoch 121/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.4441e-04 - val_loss: 0.0033\n",
      "Epoch 122/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.2035e-04 - val_loss: 0.0035\n",
      "Epoch 123/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 124/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 125/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.5182e-04 - val_loss: 0.0031\n",
      "Epoch 126/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.6013e-04 - val_loss: 0.0037\n",
      "Epoch 127/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.9535e-04 - val_loss: 0.0030\n",
      "Epoch 128/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.9097e-04 - val_loss: 0.0035\n",
      "Epoch 129/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0786e-04 - val_loss: 0.0033\n",
      "Epoch 130/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.3405e-04 - val_loss: 0.0043\n",
      "Epoch 131/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 132/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8262e-04 - val_loss: 0.0040\n",
      "Epoch 133/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.6492e-04 - val_loss: 0.0040\n",
      "Epoch 134/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.1734e-04 - val_loss: 0.0048\n",
      "Epoch 135/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 136/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 137/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.6406e-04 - val_loss: 0.0033\n",
      "Epoch 138/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.7044e-04 - val_loss: 0.0031\n",
      "Epoch 139/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.3877e-04 - val_loss: 0.0034\n",
      "Epoch 140/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.3256e-04 - val_loss: 0.0035\n",
      "Epoch 141/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.5782e-04 - val_loss: 0.0034\n",
      "Epoch 142/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.0573e-04 - val_loss: 0.0032\n",
      "Epoch 143/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 144/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.9501e-04 - val_loss: 0.0033\n",
      "Epoch 145/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.1570e-04 - val_loss: 0.0033\n",
      "Epoch 146/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.8605e-04 - val_loss: 0.0032\n",
      "Epoch 147/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.0417e-04 - val_loss: 0.0030\n",
      "Epoch 148/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.9213e-04 - val_loss: 0.0031\n",
      "Epoch 149/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.1868e-04 - val_loss: 0.0034\n",
      "Epoch 150/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.3561e-04 - val_loss: 0.0034\n",
      "Epoch 151/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.0506e-04 - val_loss: 0.0043\n",
      "Epoch 152/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 153/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.3211e-04 - val_loss: 0.0039\n",
      "Epoch 154/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.0326e-04 - val_loss: 0.0052\n",
      "Epoch 155/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 156/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.2115e-04 - val_loss: 0.0040\n",
      "Epoch 157/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.5569e-04 - val_loss: 0.0050\n",
      "Epoch 158/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.2209e-04 - val_loss: 0.0043\n",
      "Epoch 159/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.6539e-04 - val_loss: 0.0043\n",
      "Epoch 160/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1581e-04 - val_loss: 0.0043\n",
      "Epoch 161/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.2059e-04 - val_loss: 0.0040\n",
      "Epoch 162/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.6355e-04 - val_loss: 0.0067\n",
      "Epoch 163/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 164/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.0891e-04 - val_loss: 0.0047\n",
      "Epoch 165/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.1292e-04 - val_loss: 0.0041\n",
      "Epoch 166/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.3736e-04 - val_loss: 0.0036\n",
      "Epoch 167/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0665e-04 - val_loss: 0.0047\n",
      "Epoch 168/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.6756e-04 - val_loss: 0.0045\n",
      "Epoch 169/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.0271e-04 - val_loss: 0.0049\n",
      "Epoch 170/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 171/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.7254e-04 - val_loss: 0.0037\n",
      "Epoch 172/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.6180e-04 - val_loss: 0.0038\n",
      "Epoch 173/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.9882e-04 - val_loss: 0.0045\n",
      "Epoch 174/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 175/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.4792e-04 - val_loss: 0.0038\n",
      "Epoch 176/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.6717e-04 - val_loss: 0.0036\n",
      "Epoch 177/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.7477e-04 - val_loss: 0.0035\n",
      "Epoch 178/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.2526e-04 - val_loss: 0.0035\n",
      "Epoch 179/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.9622e-04 - val_loss: 0.0033\n",
      "Epoch 180/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.6792e-04 - val_loss: 0.0037\n",
      "Epoch 181/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1982e-04 - val_loss: 0.0039\n",
      "Epoch 182/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0417e-04 - val_loss: 0.0034\n",
      "Epoch 183/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.5574e-04 - val_loss: 0.0033\n",
      "Epoch 184/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.6921e-04 - val_loss: 0.0031\n",
      "Epoch 185/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1529e-04 - val_loss: 0.0035\n",
      "Epoch 186/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.8102e-04 - val_loss: 0.0041\n",
      "Epoch 187/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.5557e-04 - val_loss: 0.0037\n",
      "Epoch 188/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.2044e-04 - val_loss: 0.0032\n",
      "Epoch 189/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.8011e-04 - val_loss: 0.0034\n",
      "Epoch 190/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.6310e-04 - val_loss: 0.0034\n",
      "Epoch 191/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.8369e-04 - val_loss: 0.0037\n",
      "Epoch 192/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.6887e-04 - val_loss: 0.0039\n",
      "Epoch 193/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 194/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.0830e-04 - val_loss: 0.0042\n",
      "Epoch 195/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.7490e-04 - val_loss: 0.0037\n",
      "Epoch 196/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 2.7431e-04 - val_loss: 0.0041\n",
      "Epoch 197/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.0854e-04 - val_loss: 0.0049\n",
      "Epoch 198/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.8515e-04 - val_loss: 0.0056\n",
      "Epoch 199/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.3056e-04 - val_loss: 0.0039\n",
      "Epoch 200/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.1746e-04 - val_loss: 0.0037\n",
      "Epoch 201/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.8065e-04 - val_loss: 0.0035\n",
      "Epoch 202/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.7478e-04 - val_loss: 0.0035\n",
      "Epoch 203/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.5851e-04 - val_loss: 0.0050\n",
      "Epoch 204/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.2440e-04 - val_loss: 0.0048\n",
      "Epoch 205/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.3914e-04 - val_loss: 0.0036\n",
      "Epoch 206/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.5913e-04 - val_loss: 0.0037\n",
      "Epoch 207/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.5368e-04 - val_loss: 0.0038\n",
      "Epoch 208/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.4788e-04 - val_loss: 0.0050\n",
      "Epoch 209/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.1394e-04 - val_loss: 0.0052\n",
      "Epoch 210/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.0464e-04 - val_loss: 0.0039\n",
      "Epoch 211/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.5747e-04 - val_loss: 0.0033\n",
      "Epoch 212/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0615e-04 - val_loss: 0.0034\n",
      "Epoch 213/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.7367e-04 - val_loss: 0.0039\n",
      "Epoch 214/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 215/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 216/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.5396e-04 - val_loss: 0.0037\n",
      "Epoch 217/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.7527e-04 - val_loss: 0.0040\n",
      "Epoch 218/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.3826e-04 - val_loss: 0.0050\n",
      "Epoch 219/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.6762e-04 - val_loss: 0.0046\n",
      "Epoch 220/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.2227e-04 - val_loss: 0.0050\n",
      "Epoch 221/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1625e-04 - val_loss: 0.0043\n",
      "Epoch 222/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.9058e-04 - val_loss: 0.0044\n",
      "Epoch 223/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.6590e-04 - val_loss: 0.0050\n",
      "Epoch 224/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.6959e-04 - val_loss: 0.0038\n",
      "Epoch 225/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.7749e-04 - val_loss: 0.0043\n",
      "Epoch 226/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.8622e-04 - val_loss: 0.0050\n",
      "Epoch 227/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.1917e-04 - val_loss: 0.0039\n",
      "Epoch 228/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.6475e-04 - val_loss: 0.0035\n",
      "Epoch 229/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.2604e-04 - val_loss: 0.0033\n",
      "Epoch 230/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.1537e-04 - val_loss: 0.0035\n",
      "Epoch 231/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.4452e-04 - val_loss: 0.0035\n",
      "Epoch 232/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.0277e-04 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.2640e-04 - val_loss: 0.0031\n",
      "Epoch 234/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.0085e-04 - val_loss: 0.0037\n",
      "Epoch 235/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.2751e-04 - val_loss: 0.0043\n",
      "Epoch 236/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.7499e-04 - val_loss: 0.0042\n",
      "Epoch 237/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.3699e-04 - val_loss: 0.0053\n",
      "Epoch 238/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.1956e-04 - val_loss: 0.0043\n",
      "Epoch 239/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.5061e-04 - val_loss: 0.0039\n",
      "Epoch 240/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.6512e-04 - val_loss: 0.0036\n",
      "Epoch 241/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.6767e-04 - val_loss: 0.0034\n",
      "Epoch 242/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.8423e-04 - val_loss: 0.0033\n",
      "Epoch 243/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.7915e-04 - val_loss: 0.0035\n",
      "Epoch 244/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.7627e-04 - val_loss: 0.0038\n",
      "Epoch 245/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.7299e-04 - val_loss: 0.0036\n",
      "Epoch 246/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.0799e-04 - val_loss: 0.0036\n",
      "Epoch 247/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.2092e-04 - val_loss: 0.0031\n",
      "Epoch 248/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.5095e-04 - val_loss: 0.0034\n",
      "Epoch 249/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.1248e-04 - val_loss: 0.0037\n",
      "Epoch 250/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.2061e-04 - val_loss: 0.0053\n",
      "Epoch 251/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 252/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.4493e-04 - val_loss: 0.0034\n",
      "Epoch 253/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.2051e-04 - val_loss: 0.0040\n",
      "Epoch 254/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.1078e-04 - val_loss: 0.0037\n",
      "Epoch 255/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 2.5279e-04 - val_loss: 0.0036\n",
      "Epoch 256/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.6016e-04 - val_loss: 0.0042\n",
      "Epoch 257/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.6850e-04 - val_loss: 0.0034\n",
      "Epoch 258/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.9860e-04 - val_loss: 0.0032\n",
      "Epoch 259/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.7141e-04 - val_loss: 0.0034\n",
      "Epoch 260/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.3709e-04 - val_loss: 0.0039\n",
      "Epoch 261/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.4159e-04 - val_loss: 0.0040\n",
      "Epoch 262/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.8408e-04 - val_loss: 0.0039\n",
      "Epoch 263/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.8255e-04 - val_loss: 0.0051\n",
      "Epoch 264/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 265/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.0766e-04 - val_loss: 0.0039\n",
      "Epoch 266/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 2.2975e-04 - val_loss: 0.0042\n",
      "Epoch 267/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0208e-04 - val_loss: 0.0053\n",
      "Epoch 268/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.5059e-04 - val_loss: 0.0047\n",
      "Epoch 269/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.5581e-04 - val_loss: 0.0042\n",
      "Epoch 270/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.2879e-04 - val_loss: 0.0037\n",
      "Epoch 271/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.1550e-04 - val_loss: 0.0036\n",
      "Epoch 272/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.6275e-04 - val_loss: 0.0034\n",
      "Epoch 273/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.1416e-04 - val_loss: 0.0035\n",
      "Epoch 274/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.3841e-04 - val_loss: 0.0035\n",
      "Epoch 275/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.3936e-04 - val_loss: 0.0038\n",
      "Epoch 276/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.3240e-04 - val_loss: 0.0033\n",
      "Epoch 277/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0166e-04 - val_loss: 0.0034\n",
      "Epoch 278/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.7190e-04 - val_loss: 0.0035\n",
      "Epoch 279/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.2037e-04 - val_loss: 0.0031\n",
      "Epoch 280/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.4675e-04 - val_loss: 0.0035\n",
      "Epoch 281/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0128e-04 - val_loss: 0.0038\n",
      "Epoch 282/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.7784e-04 - val_loss: 0.0039\n",
      "Epoch 283/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 9.2475e-04 - val_loss: 0.0054\n",
      "Epoch 284/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.4552e-04 - val_loss: 0.0038\n",
      "Epoch 285/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.7200e-04 - val_loss: 0.0039\n",
      "Epoch 286/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.4651e-04 - val_loss: 0.0049\n",
      "Epoch 287/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 6.8919e-04 - val_loss: 0.0046\n",
      "Epoch 288/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.8110e-04 - val_loss: 0.0041\n",
      "Epoch 289/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.6509e-04 - val_loss: 0.0054\n",
      "Epoch 290/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.5931e-04 - val_loss: 0.0047\n",
      "Epoch 291/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.7421e-04 - val_loss: 0.0041\n",
      "Epoch 292/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 2.6510e-04 - val_loss: 0.0043\n",
      "Epoch 293/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.9907e-04 - val_loss: 0.0041\n",
      "Epoch 294/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 7.6617e-04 - val_loss: 0.0035\n",
      "Epoch 295/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.5117e-04 - val_loss: 0.0036\n",
      "Epoch 296/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 2.9374e-04 - val_loss: 0.0036\n",
      "Epoch 297/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 5.6136e-04 - val_loss: 0.0044\n",
      "Epoch 298/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 3.5887e-04 - val_loss: 0.0042\n",
      "Epoch 299/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 4.0946e-04 - val_loss: 0.0052\n",
      "Epoch 300/300\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 8.5298e-04 - val_loss: 0.0055\n",
      "34/34 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "n_model = 3;\n",
    "for i in range(n_model):#0,5):#\n",
    "\n",
    "    #keras.optimizers.RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer=RMSProp()\n",
    "                  #optimizer=RMSProp(learning_rate=0.001)\n",
    "                  #optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True), \n",
    "                  #metrics=['acc'])\n",
    "                 )\n",
    "\n",
    "    hist = model.fit(trainX, \n",
    "                     trainY, \n",
    "                     epochs=300, \n",
    "                     batch_size=64,\n",
    "                     validation_data=(valX, valY))\n",
    "\n",
    "\n",
    "    results = model.evaluate(testX, testY)\n",
    "    #model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "    model.save('model/model_'+season_mod+'_'+str(i)+'.h5')# # of feature=3,5,7,9,?,12,14,16,18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test :  (34, 48, 8)\n",
      "y_test :  (34, 16, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vislab_phy\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ dataset ]\n",
      " \n",
      "16.0 / 71.33 / 79.67 / 78.67 / 30.33 /  \n",
      "53.67 / 75.0 / 40.33 / 86.33 / 78.67 /  \n",
      "55.67 / 61.0 / 82.33 / 39.0 / 40.67 /  \n",
      "77.0 / 28.33 / 77.33 / 78.0 / 48.0 /  \n",
      "21.67 / 59.33 / 75.0 / 43.0 / 29.0 /  \n",
      "20.33 / 83.67 / 88.67 / 58.67 / 53.33 /  \n",
      "25.0 / 63.0 / 70.33 / 67.33 / \n",
      "----------------------------------------------\n",
      "mean(acc rate): 57.51960784313726\n",
      "----------------------------------------------\n",
      "[ model ]\n",
      "55.03\n",
      "62.18\n",
      "55.35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#get test data\n",
    "X_test = np.load(\"npset/\"+season_mod+\"_testX.npy\")\n",
    "y_test = np.load(\"npset/\"+season_mod+\"_testY.npy\")\n",
    "\n",
    "#get pow scale form\n",
    "#powdata, scaler = libs_yeon.get_pow()\n",
    "\n",
    "print(\"X_test : \", X_test.shape)\n",
    "print(\"y_test : \", y_test.shape)\n",
    "\n",
    "n_dataset   = y_test.shape[0]\n",
    "acc_list    = []\n",
    "acc_model   = []\n",
    "model       = []\n",
    "\n",
    "for i in range(n_model):\n",
    "    model.append(load_model('model/model_'+season_mod+'_'+str(i)+'.h5'))\n",
    "    acc_model.append(0)\n",
    "    \n",
    "print(\"[ dataset ]\")\n",
    "for i in range(n_dataset):\n",
    "    #if(i in [0,5,13,14,24,25]): continue;\n",
    "    y = sc_pow.inverse_transform(y_test[i:i+1,:,0])\n",
    "\n",
    "    for m in range(n_model):\n",
    "        #print(\"(model\",m+1,\")\\t\",end=\"\")\n",
    "\n",
    "        pred = model[m].predict([X_test[i:i+1]])\n",
    "        pred[pred<0] = 0\n",
    "        pred = pred[:,:,0]\n",
    "        pred = sc_pow.inverse_transform(pred)\n",
    "        pred = np.sum(pred)\n",
    "\n",
    "        target      = round(np.sum(y), 2)\n",
    "        error       = round(np.abs(target-pred), 2)\n",
    "        error_rate  = np.min([round(error/target, 2),1])\n",
    "        acc_rate    = round((1.0-error_rate)*100, 2)\n",
    "        acc_list.append(acc_rate)\n",
    "        acc_model[m] += acc_rate\n",
    "                 \n",
    "        #print(\"   pred: \",pred,\" | target: \",target,\" | error: \",error,\" | err rate: \",error_rate,\" | acc: \",acc_rate,sep=\"\")\n",
    "        \n",
    "    #print(\"acc rate: \",np.mean(acc_list[-n_model:]),sep='')\n",
    "    if(i%5==0): print(\" \")\n",
    "    print(round(np.mean(acc_list[-n_model:]), 2), \" / \",sep='', end='')\n",
    "print(\"\\n----------------------------------------------\")\n",
    "print(\"mean(acc rate): \",np.mean(acc_list),sep='')\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"[ model ]\")\n",
    "for i in range(n_model):\n",
    "    acc_model[i] = round(acc_model[i]/(n_dataset),2)\n",
    "    print(acc_model[i])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
