{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "softmax_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e27b9bgj1Z29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5]]\n",
        "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0]]\n",
        "\n",
        "x = tf.placeholder(\"float\", [None, 4])\n",
        "y = tf.placeholder(\"float\", [None, 3])\n",
        "\n",
        "w = tf.Variable(tf.random_normal([4, 3]), name = 'weight')\n",
        "b = tf.Variable(tf.random_normal([3]), name = 'bias')\n",
        "\n",
        "hypothesis = tf.nn.softmax(tf.matmul(x, w) + b)\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis = 1))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# train\n",
        "for i in range(1001):\n",
        "    sess.run(train, feed_dict = {x: x_data, y: y_data})\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(i, sess.run(cost, feed_dict = {x: x_data, y: y_data}))\n",
        "\n",
        "\n",
        "# test\n",
        "data = sess.run(hypothesis, feed_dict = {x: [[1, 5, 7, 8]]})\n",
        "print(data, sess.run(tf.arg_max(data, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}