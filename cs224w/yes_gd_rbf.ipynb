{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5bdaa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class RBF(nn.Module):\n",
    "    def __init__(self, timelag):\n",
    "        super(RBF, self).__init__()\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch.cuda.manual_seed(0)\n",
    "        self.cause_clt = self.init_clt()\n",
    "        self.cause_std = self.init_std()\n",
    "        self.timelag = timelag\n",
    "        self.init_weight_target = nn.Parameter(torch.rand(self.timelag, device=device))\n",
    "        self.b = nn.Parameter(torch.rand(1, device = device))\n",
    "        \n",
    "    def init_clt(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def init_std(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "    \n",
    "    def rbf(self, x, cluster, std):\n",
    "        return torch.exp(-(x - cluster) * (x - cluster) / 2 * (std * std))\n",
    "    \n",
    "    def rbf_gradient(self, x, clt, std):\n",
    "        return (-2 * (x - clt) / (std * std)) * (torch.exp(-(x - clt) * (x - clt) / 2 * (std * std)))\n",
    "    \n",
    "    def rbf_num_grad(self, x):\n",
    "        \n",
    "        rbf_grad_list = []\n",
    "        for j in range(x - 2):\n",
    "            rbf_grad_list.append(self.rbf(j + 2, self.cause_clt, self.cause_std) - self.rbf(j, self.cause_clt, self.cause_std))\n",
    "          \n",
    "        return rbf_grad_list\n",
    "    \n",
    "    def rbf_grad(self, x):\n",
    "        \n",
    "        # 1~ x.shape[0]-2th gradient list\n",
    "        \n",
    "        rbf_grad_list = []\n",
    "\n",
    "        for j in range(x - 2):\n",
    "            rbf_grad_list.append(self.rbf_gradient(j + 1, self.cause_clt, self.cause_std))\n",
    "        \n",
    "        return rbf_grad_list\n",
    "    \n",
    "    \n",
    "    def forward(self, t):\n",
    "        for i in range(t):\n",
    "            if i == 0:\n",
    "                a = self.rbf(i, self.cause_clt, self.cause_std)\n",
    "            else:\n",
    "                a = torch.cat([a, self.rbf(i, self.cause_clt, self.cause_std)], dim=0)\n",
    "        \n",
    "        pred = sum(a.T * self.init_weight_target) + self.b\n",
    "                \n",
    "        return a, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a35f0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def restore_parameters(model, best_model):\n",
    "    '''Move parameter values from best_model to model.'''\n",
    "    for params, best_params in zip(model.parameters(), best_model.parameters()):\n",
    "        params.data = best_params\n",
    "        \n",
    "def train_rbf(model,X ,Y, lr, epochs, lookback=5,device = device):\n",
    "\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loss_list = []\n",
    "\n",
    "    best_it = None\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss_ = 0\n",
    "        a_list = []\n",
    "        pred_list = []\n",
    "        for i in range(len(X)):\n",
    "            # pred loss\n",
    "            a, pred = model(len(X[i]))\n",
    "            a_list.append(a)\n",
    "            pred_list.append(pred)\n",
    "            loss_ += loss_fn(pred, Y[i])\n",
    "\n",
    "            # rbf_num_list = model.rbf_num_grad(len(Y))\n",
    "            # rbf_fn_grad = model.rbf_grad(len(Y))\n",
    "\n",
    "            # loss_grad = sum([loss_fn(rbf_fn_grad[j], rbf_num_list[j]) for j in range(len(rbf_num_list))])\n",
    "            # if epoch % 100 == 0:\n",
    "        print(\"epoch {} loss {} :\".format(epoch, loss_ / len(Y)))\n",
    "        print(\"------------------------------------------------------\")\n",
    "        print()\n",
    "        \n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        mean_loss = loss_ / len(Y)\n",
    "        train_loss_list.append(mean_loss)\n",
    "        \n",
    "        \n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_it = epoch\n",
    "            best_model = deepcopy(model)\n",
    "            \n",
    "        elif (epoch - best_it) == lookback:\n",
    "            if verbose:\n",
    "                print('Stopping early')\n",
    "            break\n",
    "\n",
    "    restore_parameters(model, best_model)\n",
    "\n",
    "    return train_loss_list , model, pred_list, a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0224d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/chanyoung/Desktop/Neural-GC-master/lorenz_96_10_10_1000.csv')\n",
    "X2d = df[['a','b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41c90c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, cause, target, timelag, device = device):\n",
    "    input_cause = []\n",
    "    input_target = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(X) - (timelag + 1)):\n",
    "        input_cause.append(X[cause].values[i: i + timelag])\n",
    "        input_target.append(X[target].values[i: i + timelag])\n",
    "        Y.append([X[target][i + timelag + 1]])\n",
    "\n",
    "    return torch.tensor(input_cause, device=device).float(), torch.tensor(input_target,device=device).float(), torch.tensor(Y, device=device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3a1ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cause, input_target, Y = data_split(X2d, 'a', 'a', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd70af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weight_target = nn.Parameter(torch.rand(10, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4e00114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.9345, 0.8207, 0.0164, 0.1889, 0.9616, 0.0436, 0.4849, 0.7817, 0.4673,\n",
       "        0.3371], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_weight_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6c4af59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735484899999999"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8207 * 0.8207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1dbf789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6222], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(init_weight_target.T * init_weight_target) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5e4e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nn.Parameter(torch.rand(1, device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6aab4d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "989"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b2e8ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.3990], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9722], device='cuda:0', requires_grad=True)\n",
      "epoch 0 loss 17.486648559570312 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1 loss 17.396259307861328 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2 loss 17.31011199951172 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3 loss 17.228439331054688 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4 loss 17.151487350463867 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5 loss 17.079526901245117 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 6 loss 17.01278305053711 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 7 loss 16.95144271850586 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 8 loss 16.89580535888672 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 9 loss 16.84593963623047 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 10 loss 16.801986694335938 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 11 loss 16.76403045654297 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 12 loss 16.732057571411133 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 13 loss 16.706012725830078 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 14 loss 16.685667037963867 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 15 loss 16.67075538635254 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 16 loss 16.660890579223633 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 17 loss 16.655519485473633 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 18 loss 16.65399932861328 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 19 loss 16.655559539794922 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 20 loss 16.659387588500977 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 21 loss 16.66462516784668 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 22 loss 16.670469284057617 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 23 loss 16.676101684570312 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 24 loss 16.680992126464844 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 25 loss 16.68465232849121 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 26 loss 16.686826705932617 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 27 loss 16.687490463256836 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 28 loss 16.68669319152832 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 29 loss 16.684646606445312 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 30 loss 16.68162727355957 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 31 loss 16.67796516418457 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 32 loss 16.673959732055664 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 33 loss 16.66992950439453 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 34 loss 16.666091918945312 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 35 loss 16.662675857543945 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 36 loss 16.65974998474121 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 37 loss 16.657455444335938 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 38 loss 16.655786514282227 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 39 loss 16.654680252075195 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 40 loss 16.65412139892578 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 41 loss 16.65399742126465 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 42 loss 16.654207229614258 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 43 loss 16.65463638305664 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 44 loss 16.655197143554688 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 45 loss 16.655803680419922 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 46 loss 16.656354904174805 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 47 loss 16.656827926635742 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 48 loss 16.657154083251953 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 49 loss 16.657325744628906 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 50 loss 16.657358169555664 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 51 loss 16.6572265625 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 52 loss 16.656982421875 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 53 loss 16.656646728515625 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 54 loss 16.656248092651367 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 55 loss 16.65581512451172 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 56 loss 16.6553955078125 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 57 loss 16.65500259399414 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 58 loss 16.654664993286133 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 59 loss 16.654394149780273 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 60 loss 16.654186248779297 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 61 loss 16.654056549072266 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 62 loss 16.65399742126465 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 63 loss 16.654001235961914 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 64 loss 16.65402603149414 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 65 loss 16.654094696044922 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 66 loss 16.654170989990234 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 67 loss 16.65424156188965 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 68 loss 16.65433120727539 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 69 loss 16.65436553955078 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 70 loss 16.654388427734375 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 71 loss 16.654399871826172 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 72 loss 16.654380798339844 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 73 loss 16.65434455871582 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 74 loss 16.654294967651367 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 75 loss 16.654239654541016 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 76 loss 16.654190063476562 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 77 loss 16.65412139892578 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 78 loss 16.654077529907227 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 79 loss 16.654037475585938 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 80 loss 16.654008865356445 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 81 loss 16.654003143310547 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 82 loss 16.65399169921875 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 83 loss 16.653993606567383 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 84 loss 16.654006958007812 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 85 loss 16.65401268005371 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 86 loss 16.65401268005371 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 87 loss 16.654041290283203 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 88 loss 16.654027938842773 :\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89 loss 16.6540584564209 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 90 loss 16.654043197631836 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 91 loss 16.654033660888672 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 92 loss 16.65404510498047 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 93 loss 16.654033660888672 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 94 loss 16.654024124145508 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 95 loss 16.65402603149414 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 96 loss 16.65401840209961 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 97 loss 16.654008865356445 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 98 loss 16.65398597717285 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 99 loss 16.65399742126465 :\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-351addd8e995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_clt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_rbf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_cause\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_clt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "model = RBF(10)\n",
    "print(model.cause_clt)\n",
    "print(model.cause_std)\n",
    "loss, best_model, pred = train_rbf(model, input_cause,Y, 0.01, 100, device)\n",
    "print(best_model.cause_clt)\n",
    "print(best_model.cause_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d547292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pred[:19].cpu().detach().numpy())\n",
    "plt.plot(a[:19].cpu().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c941a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
