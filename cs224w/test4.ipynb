{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a64083ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class RBFlayer(nn.Module):\n",
    "    def __init__(self, timelag):\n",
    "        super(RBFlayer, self).__init__()\n",
    "\n",
    "        self.timelag = timelag\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch.cuda.manual_seed(0)\n",
    "\n",
    "        self.init_weight_cause = nn.Parameter(torch.rand(self.timelag, device=device))\n",
    "        self.init_weight_target = nn.Parameter(torch.rand(self.timelag, device=device))\n",
    "        self.cause_clt  = self.init_clt()\n",
    "        self.cause_std = self.init_clt()\n",
    "        self.target_clt = nn.Parameter(torch.rand(1,device=device))\n",
    "        self.target_std = nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def init_clt(self):\n",
    "        return nn.Parameter(torch.rand(1,device=device))\n",
    "\n",
    "    def init_std(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def rbf(self, x, cluster, std):\n",
    "        return torch.exp(-(x - cluster) * (x - cluster) / 2*(std * std))\n",
    "\n",
    "    def forward(self, cause, target):\n",
    "        \n",
    "        for i in range(len(cause)):\n",
    "            if i == 0:\n",
    "                a = self.rbf(cause[i], self.cause_clt, self.cause_std)\n",
    "            else:\n",
    "                a = torch.cat([a,self.rbf(cause[i], self.cause_clt, self.cause_std)],dim = 0)\n",
    "        cause = self.init_weight_cause * a\n",
    "        \n",
    "        for j in range(len(target)):\n",
    "            if j == 0:\n",
    "                b = self.rbf(target[j], self.target_clt, self.target_std)\n",
    "            else:\n",
    "                b = torch.cat([b,self.rbf(target[j], self.target_clt, self.target_std)],dim = 0)\n",
    "        target = self.init_weight_target * b\n",
    "        \n",
    "        return cause, target\n",
    "\n",
    "\n",
    "class RBFnet(nn.Module):\n",
    "    def __init__(self, input_size , output_size, timelag):\n",
    "        super(RBFnet,self).__init__()\n",
    "    \n",
    "        self.input_size = input_size      # number of data\n",
    "        self.output_size = output_size\n",
    "        self.timelag = timelag\n",
    "\n",
    "        self.linear = nn.ModuleList([nn.Linear(self.timelag*2,1) for _ in range(self.input_size)])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.networks = nn.ModuleList([RBFlayer(self.timelag) for _ in range(self.input_size)])\n",
    "\n",
    "    def cause_target(self, cause, target):\n",
    "        x = torch.cat((cause, target), 0)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def GC(self, threshold=True):\n",
    "        '''\n",
    "        Extract learned Granger causality.\n",
    "        Args:\n",
    "          threshold: return norm of weights, or whether norm is nonzero.\n",
    "        Returns:\n",
    "          GC: (p x p) matrix. Entry (i, j) indicates whether variable j is\n",
    "            Granger causal of variable i.\n",
    "        '''\n",
    "        GC = [torch.norm(net.init_weight_cause, dim=0)\n",
    "              for net in self.networks]\n",
    "        GC = torch.stack(GC)\n",
    "        if threshold:\n",
    "            return (GC > 0).int()\n",
    "        else:\n",
    "            return GC\n",
    "\n",
    "\n",
    "    def forward(self, causes, targets):\n",
    "        out_list = []\n",
    "        for i in range(self.input_size):\n",
    "            cause, target = self.networks[i](causes[i], targets[i])\n",
    "            cause, target = self.relu(cause), self.relu(target)\n",
    "            pred = torch.cat((cause, target),0)\n",
    "            pred = self.linear[i](pred)\n",
    "            out_list.append(pred)\n",
    "\n",
    "        return out_list\n",
    "\n",
    "\n",
    "def restore_parameters(model, best_model):\n",
    "    '''Move parameter values from best_model to model.'''\n",
    "    for params, best_params in zip(model.parameters(), best_model.parameters()):\n",
    "        params.data = best_params\n",
    "\n",
    "\n",
    "def train_rbf(model, input_causes, input_targets, Y, lr, epochs, lookback=5,device = device):\n",
    "    # input_causes, input_targets : X\n",
    "    # Y : Y\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loss_list = []\n",
    "\n",
    "    best_it = None\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pred = model(input_causes, input_targets)\n",
    "        loss = sum([loss_fn(pred[i], Y[i]) for i in range(len(Y))])\n",
    "        print(\"epoch {} loss {} :\".format(epoch, loss / len(Y)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        mean_loss = loss / len(Y)\n",
    "\n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_it = epoch\n",
    "            best_model = deepcopy(model)\n",
    "        elif (epoch - best_it) == lookback:\n",
    "            if verbose:\n",
    "                print('Stopping early')\n",
    "            break\n",
    "\n",
    "    restore_parameters(model, best_model)\n",
    "\n",
    "    return train_loss_list, model\n",
    "\n",
    "\n",
    "\n",
    "def data_split(X, cause, target, timelag, device = device):\n",
    "    input_cause = []\n",
    "    input_target = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(X) - (timelag + 1)):\n",
    "        input_cause.append(X[cause].values[i: i + timelag])\n",
    "        input_target.append(X[target].values[i: i + timelag])\n",
    "        Y.append([X[target][i + timelag + 1]])\n",
    "\n",
    "    return torch.tensor(input_cause, device=device).float(), torch.tensor(input_target,device=device).float(), torch.tensor(Y, device=device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11f7e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/chanyoung/Desktop/Neural-GC-master/lorenz_96_10_10_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c27a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2d = df[['a','b']]\n",
    "torch.manual_seed(1234)\n",
    "input_cause, input_target, Y = data_split(X2d, 'a', 'b', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67110d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.3990, 0.5167, 0.0249, 0.9401, 0.9459, 0.7967, 0.4150, 0.8203, 0.2290,\n",
      "        0.9096], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7874], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4503], device='cuda:0', requires_grad=True)\n",
      "epoch 0 loss 27.376123428344727 :\n",
      "epoch 1 loss 26.882343292236328 :\n",
      "epoch 2 loss 26.395124435424805 :\n",
      "epoch 3 loss 25.912689208984375 :\n",
      "epoch 4 loss 25.43282699584961 :\n",
      "epoch 5 loss 24.953168869018555 :\n",
      "epoch 6 loss 24.471799850463867 :\n",
      "epoch 7 loss 23.987049102783203 :\n",
      "epoch 8 loss 23.497392654418945 :\n",
      "epoch 9 loss 23.00132179260254 :\n",
      "epoch 10 loss 22.49742889404297 :\n",
      "epoch 11 loss 21.9847412109375 :\n",
      "epoch 12 loss 21.46206283569336 :\n",
      "epoch 13 loss 20.92828369140625 :\n",
      "epoch 14 loss 20.38227653503418 :\n",
      "epoch 15 loss 19.823266983032227 :\n",
      "epoch 16 loss 19.250286102294922 :\n",
      "epoch 17 loss 18.662784576416016 :\n",
      "epoch 18 loss 18.060420989990234 :\n",
      "epoch 19 loss 17.44284439086914 :\n",
      "epoch 20 loss 16.80959129333496 :\n",
      "epoch 21 loss 16.16131591796875 :\n",
      "epoch 22 loss 15.498228073120117 :\n",
      "epoch 23 loss 14.821338653564453 :\n",
      "epoch 24 loss 14.132197380065918 :\n",
      "epoch 25 loss 13.432229042053223 :\n",
      "epoch 26 loss 12.723984718322754 :\n",
      "epoch 27 loss 12.010040283203125 :\n",
      "epoch 28 loss 11.293968200683594 :\n",
      "epoch 29 loss 10.579324722290039 :\n",
      "epoch 30 loss 9.869810104370117 :\n",
      "epoch 31 loss 9.16958236694336 :\n",
      "epoch 32 loss 8.4823637008667 :\n",
      "epoch 33 loss 7.811844825744629 :\n",
      "epoch 34 loss 7.161930084228516 :\n",
      "epoch 35 loss 6.536264896392822 :\n",
      "epoch 36 loss 5.938180923461914 :\n",
      "epoch 37 loss 5.369921684265137 :\n",
      "epoch 38 loss 4.833494663238525 :\n",
      "epoch 39 loss 4.3297648429870605 :\n",
      "epoch 40 loss 3.858898639678955 :\n",
      "epoch 41 loss 3.420989751815796 :\n",
      "epoch 42 loss 3.015878438949585 :\n",
      "epoch 43 loss 2.644045829772949 :\n",
      "epoch 44 loss 2.305083990097046 :\n",
      "epoch 45 loss 1.9990383386611938 :\n",
      "epoch 46 loss 1.7252572774887085 :\n",
      "epoch 47 loss 1.4825209379196167 :\n",
      "epoch 48 loss 1.269797921180725 :\n",
      "epoch 49 loss 1.0858856439590454 :\n",
      "epoch 50 loss 0.9292822480201721 :\n",
      "epoch 51 loss 0.797905445098877 :\n",
      "epoch 52 loss 0.6894655227661133 :\n",
      "epoch 53 loss 0.6006191372871399 :\n",
      "epoch 54 loss 0.527972400188446 :\n",
      "epoch 55 loss 0.46831798553466797 :\n",
      "epoch 56 loss 0.41906481981277466 :\n",
      "epoch 57 loss 0.37801671028137207 :\n",
      "epoch 58 loss 0.3433832824230194 :\n",
      "epoch 59 loss 0.3136092722415924 :\n",
      "epoch 60 loss 0.2870140075683594 :\n",
      "epoch 61 loss 0.2620784044265747 :\n",
      "epoch 62 loss 0.23718072474002838 :\n",
      "epoch 63 loss 0.21196624636650085 :\n",
      "epoch 64 loss 0.18661417067050934 :\n",
      "epoch 65 loss 0.16205506026744843 :\n",
      "epoch 66 loss 0.13911789655685425 :\n",
      "epoch 67 loss 0.11840634047985077 :\n",
      "epoch 68 loss 0.10029561072587967 :\n",
      "epoch 69 loss 0.08503223210573196 :\n",
      "epoch 70 loss 0.07269413769245148 :\n",
      "epoch 71 loss 0.06303328275680542 :\n",
      "epoch 72 loss 0.05563478171825409 :\n",
      "epoch 73 loss 0.04991430416703224 :\n",
      "epoch 74 loss 0.04541456326842308 :\n",
      "epoch 75 loss 0.04170113056898117 :\n",
      "epoch 76 loss 0.03849666193127632 :\n",
      "epoch 77 loss 0.03559400513768196 :\n",
      "epoch 78 loss 0.032821573317050934 :\n",
      "epoch 79 loss 0.030183857306838036 :\n",
      "epoch 80 loss 0.02757597155869007 :\n",
      "epoch 81 loss 0.025010516867041588 :\n",
      "epoch 82 loss 0.022532761096954346 :\n",
      "epoch 83 loss 0.02017594501376152 :\n",
      "epoch 84 loss 0.017957082018256187 :\n",
      "epoch 85 loss 0.015926703810691833 :\n",
      "epoch 86 loss 0.014101048931479454 :\n",
      "epoch 87 loss 0.012505666352808475 :\n",
      "epoch 88 loss 0.011122310534119606 :\n",
      "epoch 89 loss 0.009934775531291962 :\n",
      "epoch 90 loss 0.008933150209486485 :\n",
      "epoch 91 loss 0.008103955537080765 :\n",
      "epoch 92 loss 0.00741967698559165 :\n",
      "epoch 93 loss 0.006823929492384195 :\n",
      "epoch 94 loss 0.006307430099695921 :\n",
      "epoch 95 loss 0.0058227949775755405 :\n",
      "epoch 96 loss 0.005371193867176771 :\n",
      "epoch 97 loss 0.004927285481244326 :\n",
      "epoch 98 loss 0.004489690065383911 :\n",
      "epoch 99 loss 0.004067548550665379 :\n",
      "epoch 100 loss 0.0036364763509482145 :\n",
      "epoch 101 loss 0.0032285351771861315 :\n",
      "epoch 102 loss 0.0028375661931931973 :\n",
      "epoch 103 loss 0.0024856773670762777 :\n",
      "epoch 104 loss 0.0021639394108206034 :\n",
      "epoch 105 loss 0.0018898933194577694 :\n",
      "epoch 106 loss 0.0016496176831424236 :\n",
      "epoch 107 loss 0.0014572489308193326 :\n",
      "epoch 108 loss 0.001295055728405714 :\n",
      "epoch 109 loss 0.0011682508047670126 :\n",
      "epoch 110 loss 0.0010678793769329786 :\n",
      "epoch 111 loss 0.0009838154073804617 :\n",
      "epoch 112 loss 0.0009150693658739328 :\n",
      "epoch 113 loss 0.000846927403472364 :\n",
      "epoch 114 loss 0.0007851240807212889 :\n",
      "epoch 115 loss 0.0007255994132719934 :\n",
      "epoch 116 loss 0.0006642609951086342 :\n",
      "epoch 117 loss 0.0006074903649277985 :\n",
      "epoch 118 loss 0.0005486240261234343 :\n",
      "epoch 119 loss 0.0004924422246403992 :\n",
      "Parameter containing:\n",
      "tensor([ 0.4455,  0.3550, -0.0112,  0.9704,  0.7504,  1.0321,  0.1894,  1.2510,\n",
      "        -0.0189,  1.3516], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3759], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0286], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = RBFnet(input_cause.size()[0], 1, input_cause.size()[1])\n",
    "print(model.networks[1].init_weight_cause)\n",
    "print(model.networks[1].cause_std)\n",
    "print(model.networks[1].target_std)\n",
    "loss, best_model = train_rbf(model, input_cause, input_target, Y, 0.01, 120, device)\n",
    "print(best_model.networks[1].init_weight_cause)\n",
    "print(best_model.networks[1].cause_std)\n",
    "print(model.networks[1].target_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8e23f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([989, 10])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cause.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a20a66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0 = np.zeros((989,10))\n",
    "from scipy.stats import f_oneway\n",
    "list_ = []\n",
    "for i in range(989):\n",
    "    a = best_model.networks[i].init_weight_cause.detach().cpu().numpy()\n",
    "    list_.append(a)\n",
    "p_value = f_oneway(list_,h_0).pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93bef53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+000, 0.00000000e+000, 1.88810894e-060, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       3.56721508e-269, 0.00000000e+000])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "009a1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_gradient(x, cluster, std):\n",
    "    return (-2 * (x - cluster) / (std*std)) *(torch.exp(-(x - cluster) * (x - cluster) / 2*(std * std)))\n",
    "\n",
    "def rbf(x, cluster, std):\n",
    "    return torch.exp(-(x - cluster) * (x - cluster) / 2*(std * std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b596044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf gradient : tensor([-3.0483], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.1652], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-0.0068], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0524], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-1.0919e-06], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0001], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-1.7484e-06], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-2.8808e-07], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-4.9685e-06], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-5.8298e-05], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-0.0035], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.1223], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-2.1771], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0085], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([1.1066], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([0.2232], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "next network\n",
      "\n",
      "rbf gradient : tensor([-4.4805], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0890], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-0.3234], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0178], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-0.3731], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0041], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-0.5121], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0153], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-3.6696], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.1179], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-15.4917], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0618], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([22.8359], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([0.0726], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([22.8219], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([0.2131], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "next network\n",
      "\n",
      "rbf gradient : tensor([-5.0877e-05], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-7.3702e-05], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-6.9759e-06], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-0.0002], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0004], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-0.0285], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.1247], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([-2.6625], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([-0.0137], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([2.2731], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([0.2147], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([2.3385], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([0.2462], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "rbf gradient : tensor([4.6307], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "rbf_num_grad : tensor([0.2729], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------------------------------------\n",
      "next network\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(3):\n",
    "    clt = best_model.networks[j].cause_clt\n",
    "    std = best_model.networks[j].cause_std\n",
    "    for i in range(len(input_cause[j]) - 2):\n",
    "        rbf_grad = rbf_gradient(input_cause[j][i+1], clt, std)\n",
    "        rbf_num_grad = (rbf(input_cause[j][i+2],clt,std) - rbf(input_cause[j][i], clt, std)) / (input_cause[j][i+2] - input_cause[j][i]) \n",
    "        print(\"rbf gradient :\",rbf_grad)\n",
    "        print(\"rbf_num_grad :\", rbf_num_grad)\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "    print('next network')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a10996c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dfbb96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cdd2321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.ones(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc57a084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27c6b7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0990,  2.3833,  6.1237,  ...,  0.7887, -3.0315, -3.0010],\n",
       "        [ 2.3833,  6.1237,  8.7908,  ..., -3.0315, -3.0010, -1.9771],\n",
       "        [ 6.1237,  8.7908,  8.6702,  ..., -3.0010, -1.9771, -1.6429],\n",
       "        ...,\n",
       "        [ 2.5767,  3.8119,  5.3918,  ...,  1.1669, -0.7102, -2.3594],\n",
       "        [ 3.8119,  5.3918,  6.0065,  ..., -0.7102, -2.3594, -2.1374],\n",
       "        [ 5.3918,  6.0065,  5.1861,  ..., -2.3594, -2.1374, -0.8038]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a25e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
