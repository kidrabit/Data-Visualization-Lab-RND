{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc8ca723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class RBFlayer(nn.Module):\n",
    "    def __init__(self, timelag):\n",
    "        super(RBFlayer, self).__init__()\n",
    "\n",
    "        self.timelag = timelag\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch.cuda.manual_seed(0)\n",
    "\n",
    "        self.init_weight_cause = nn.Parameter(torch.rand(self.timelag, device=device))\n",
    "        self.init_weight_target = nn.Parameter(torch.rand(self.timelag, device=device))\n",
    "        self.cause_clt = self.init_clt()\n",
    "        self.cause_std = self.init_clt()\n",
    "        self.target_clt = nn.Parameter(torch.rand(1, device=device))\n",
    "        self.target_std = nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def init_clt(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def init_std(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def rbf(self, x, cluster, std):\n",
    "        return torch.exp(-(x - cluster) * (x - cluster) / 2 * (std * std))\n",
    "\n",
    "    '''\n",
    "    def rbf_grad(self, x, cluster, std):\n",
    "        return (-2 * (x - cluster) / (std * std)) * (torch.exp(-(x - cluster) * (x - cluster) / 2 * (std * std)))\n",
    "    \n",
    "    def rbf_grad_num(self, x, x2, cluster, std):\n",
    "        return (self.rbf(x2,cluster,std) - self.rbf(x, clt, std)) / (x2- x)\n",
    "    \n",
    "    def rbf_grad_cause_list(self, X):\n",
    "        return [self.rbf_grad(X[i+1], self.cause_clt, self.cause_std) for i in range(len(X) - 2)]\n",
    "\n",
    "    def rbf_grad_target_list(self, X):\n",
    "        return [self.rbf_grad(X[i+1], self.target_clt, self.target_std) for i in range(len(X) - 2)]\n",
    "\n",
    "    def rbf_grad_target_num(self, X):\n",
    "        return\n",
    "    '''\n",
    "    def forward(self, cause, target):\n",
    "\n",
    "        for i in range(len(cause)):\n",
    "            if i == 0:\n",
    "                a = self.rbf(cause[i], self.cause_clt, self.cause_std)\n",
    "            else:\n",
    "                a = torch.cat([a, self.rbf(cause[i], self.cause_clt, self.cause_std)], dim=0)\n",
    "        cause = self.init_weight_cause * a\n",
    "\n",
    "        for j in range(len(target)):\n",
    "            if j == 0:\n",
    "                b = self.rbf(target[j], self.target_clt, self.target_std)\n",
    "            else:\n",
    "                b = torch.cat([b, self.rbf(target[j], self.target_clt, self.target_std)], dim=0)\n",
    "        target = self.init_weight_target * b\n",
    "\n",
    "        return cause, target\n",
    "\n",
    "\n",
    "class RBFnet(nn.Module):\n",
    "    def __init__(self, input_size , output_size, timelag):\n",
    "        super(RBFnet,self).__init__()\n",
    "\n",
    "        self.input_size = input_size      # number of data\n",
    "        self.output_size = output_size\n",
    "        self.timelag = timelag\n",
    "\n",
    "        self.linear = nn.ModuleList([nn.Linear(self.timelag*2,1) for _ in range(self.input_size)])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.networks = nn.ModuleList([RBFlayer(self.timelag) for _ in range(self.input_size)])\n",
    "\n",
    "    def cause_target(self, cause, target):\n",
    "        x = torch.cat((cause, target), 0)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def GC(self, threshold=True):\n",
    "        '''\n",
    "        Extract learned Granger causality.\n",
    "        Args:\n",
    "          threshold: return norm of weights, or whether norm is nonzero.\n",
    "        Returns:\n",
    "          GC: (p x p) matrix. Entry (i, j) indicates whether variable j is\n",
    "            Granger causal of variable i.\n",
    "        '''\n",
    "        GC = [torch.norm(net.init_weight_cause, dim=0)\n",
    "              for net in self.networks]\n",
    "        GC = torch.stack(GC)\n",
    "        if threshold:\n",
    "            return (GC > 0).int()\n",
    "        else:\n",
    "            return GC\n",
    "\n",
    "\n",
    "    def forward(self, causes, targets):\n",
    "        out_list = []\n",
    "        for i in range(self.input_size):\n",
    "            cause, target = self.networks[i](causes[i], targets[i])\n",
    "            cause, target = self.relu(cause), self.relu(target)\n",
    "            pred = torch.cat((cause, target),0)\n",
    "            pred = self.linear[i](pred)\n",
    "            out_list.append(pred)\n",
    "\n",
    "        return out_list\n",
    "\n",
    "\n",
    "def restore_parameters(model, best_model):\n",
    "    '''Move parameter values from best_model to model.'''\n",
    "    for params, best_params in zip(model.parameters(), best_model.parameters()):\n",
    "        params.data = best_params\n",
    "\n",
    "def rbf_p(x, clt, std):\n",
    "    return (-2 * (x - clt) / (std * std)) * (torch.exp(-(x - clt) * (x - clt) / 2 * (std * std)))\n",
    "\n",
    "def rbf_fn(x, cluster, std):\n",
    "    return torch.exp(-(x - cluster) * (x - cluster) / 2*(std * std))\n",
    "\n",
    "\n",
    "def rbf_grad_cause(model, input):\n",
    "\n",
    "    rbf_grad_list = []\n",
    "    for i in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[i].cause_clt\n",
    "        std = model.networks[i].cause_std\n",
    "\n",
    "        for j in range(input.shape[1] - 2):\n",
    "            list_.append(rbf_p(input[i][j + 1], clt, std))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "\n",
    "def rbf_grad_target(model, input):\n",
    "\n",
    "    rbf_grad_list = []\n",
    "    for i in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[i].target_clt\n",
    "        std = model.networks[i].target_std\n",
    "\n",
    "        for j in range(input.shape[1] - 2):\n",
    "            list_.append(rbf_p(input[i][j + 1], clt, std))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "\n",
    "def rbf_grad_num_cause(input):\n",
    "    rbf_grad_list = []\n",
    "    for j in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[j].cause_clt\n",
    "        std = model.networks[j].cause_std\n",
    "\n",
    "        for i in range(input.shape[1] - 2):\n",
    "            list_.append((rbf_fn(input[j][i+2],clt,std) - rbf_fn(input[j][i], clt, std)) /\n",
    "                                        (input[j][i+2] - input[j][i]))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "def rbf_grad_num_target(input):\n",
    "    rbf_grad_list = []\n",
    "    for j in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[j].target_clt\n",
    "        std = model.networks[j].target_std\n",
    "\n",
    "        for i in range(input.shape[1] - 2):\n",
    "            list_.append((rbf_fn(input[j][i+2],clt,std) - rbf_fn(input[j][i], clt, std)) /\n",
    "                                        (input[j][i+2] - input[j][i]))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "def train_rbf(model, input_causes, input_targets, Y, lr, epochs, lookback=5,device = device):\n",
    "    # input_causes, input_targets : X\n",
    "    # Y : Y\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loss_list = []\n",
    "\n",
    "    best_it = None\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pred = model(input_causes, input_targets)\n",
    "        loss_ = sum([loss_fn(pred[i], Y[i]) for i in range(len(Y))])\n",
    "        loss_cause = loss_fn(rbf_grad_num_cause(input_causes), rbf_grad_cause(model, input_causes))\n",
    "        loss_target = loss_fn(rbf_grad_num_target(input_targets), rbf_grad_target(model, input_targets))\n",
    "\n",
    "        loss = loss_/ len(Y) + loss_cause + loss_target\n",
    "        print(\"epoch {} loss {} :\".format(epoch, loss / len(Y)))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        train_loss_list.append(loss)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_it = epoch\n",
    "            best_model = deepcopy(model)\n",
    "        elif (epoch - best_it) == lookback:\n",
    "            if verbose:\n",
    "                print('Stopping early')\n",
    "            break\n",
    "\n",
    "    restore_parameters(model, best_model)\n",
    "\n",
    "    return train_loss_list , model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b67647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, cause, target, timelag, device = device):\n",
    "    input_cause = []\n",
    "    input_target = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(X) - (timelag + 1)):\n",
    "        input_cause.append(X[cause].values[i: i + timelag])\n",
    "        input_target.append(X[target].values[i: i + timelag])\n",
    "        Y.append([X[target][i + timelag + 1]])\n",
    "\n",
    "    return torch.tensor(input_cause, device=device).float(), torch.tensor(input_target,device=device).float(), torch.tensor(Y, device=device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136cdab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/chanyoung/Desktop/Neural-GC-master/lorenz_96_10_10_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20d545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2d = df[['a','b']]\n",
    "torch.manual_seed(1234)\n",
    "input_cause, input_target, Y = data_split(X2d, 'a', 'b', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f2b2247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.3990, 0.5167, 0.0249, 0.9401, 0.9459, 0.7967, 0.4150, 0.8203, 0.2290,\n",
      "        0.9096], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7874], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4503], device='cuda:0', requires_grad=True)\n",
      "epoch 0 loss 0.09041088819503784 :\n",
      "epoch 1 loss 0.09129206836223602 :\n",
      "epoch 2 loss 0.09430349618196487 :\n",
      "epoch 3 loss 0.09948369860649109 :\n",
      "epoch 4 loss 0.10693389177322388 :\n",
      "epoch 5 loss 0.11684545129537582 :\n",
      "epoch 6 loss 0.1295550912618637 :\n",
      "epoch 7 loss 0.14557567238807678 :\n",
      "epoch 8 loss 0.16562244296073914 :\n",
      "epoch 9 loss 0.1906483769416809 :\n",
      "epoch 10 loss 0.22192206978797913 :\n",
      "epoch 11 loss 0.26114943623542786 :\n",
      "epoch 12 loss 0.3106226921081543 :\n",
      "epoch 13 loss 0.3734202980995178 :\n",
      "epoch 14 loss 0.4537034332752228 :\n",
      "epoch 15 loss 0.5571730732917786 :\n",
      "epoch 16 loss 0.6917473673820496 :\n",
      "epoch 17 loss 0.8685186505317688 :\n",
      "epoch 18 loss 1.103216290473938 :\n",
      "epoch 19 loss 1.4185601472854614 :\n",
      "epoch 20 loss 1.8479543924331665 :\n",
      "epoch 21 loss 2.441265821456909 :\n",
      "epoch 22 loss 3.2740113735198975 :\n",
      "epoch 23 loss 4.462536811828613 :\n",
      "epoch 24 loss 6.190242290496826 :\n",
      "epoch 25 loss 8.753813743591309 :\n",
      "epoch 26 loss 12.645124435424805 :\n",
      "epoch 27 loss 18.6986026763916 :\n",
      "epoch 28 loss 28.371370315551758 :\n",
      "epoch 29 loss 44.3089485168457 :\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f99d8e762489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_rbf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_cause\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_weight_cause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4d142ff16846>\u001b[0m in \u001b[0;36mtrain_rbf\u001b[1;34m(model, input_causes, input_targets, Y, lr, epochs, lookback, device)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_causes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mloss_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mloss_cause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbf_grad_num_cause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_causes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbf_grad_cause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_causes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mloss_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbf_grad_num_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbf_grad_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4d142ff16846>\u001b[0m in \u001b[0;36mrbf_grad_cause\u001b[1;34m(model, input)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[0mlist_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbf_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mrbf_grad_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4d142ff16846>\u001b[0m in \u001b[0;36mrbf_p\u001b[1;34m(x, clt, std)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrbf_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mclt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mclt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mclt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrbf_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RBFnet(input_cause.size()[0], 1, input_cause.size()[1])\n",
    "print(model.networks[1].init_weight_cause)\n",
    "print(model.networks[1].cause_std)\n",
    "print(model.networks[1].target_std)\n",
    "loss, best_model = train_rbf(model, input_cause, input_target, Y, 0.01, 50, device)\n",
    "print(best_model.networks[1].init_weight_cause)\n",
    "print(best_model.networks[1].cause_std)\n",
    "print(model.networks[1].target_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3437be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.3990, 0.5167, 0.0249, 0.9401, 0.9459, 0.7967, 0.4150, 0.8203, 0.2290,\n",
      "        0.9096], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7874], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4503], device='cuda:0', requires_grad=True)\n",
      "epoch 0 loss 25.315834045410156 :\n",
      "epoch 1 loss 24.86098289489746 :\n",
      "epoch 2 loss 24.413551330566406 :\n",
      "epoch 3 loss 23.971946716308594 :\n",
      "epoch 4 loss 23.534242630004883 :\n",
      "epoch 5 loss 23.098466873168945 :\n"
     ]
    }
   ],
   "source": [
    "X2d = df[['a','c']]\n",
    "torch.manual_seed(1234)\n",
    "input_cause2, input_target2, Y = data_split(X2d, 'a', 'c', 10)\n",
    "model2 = RBFnet(input_cause.size()[0], 1, input_cause.size()[1])\n",
    "print(model2.networks[1].init_weight_cause)\n",
    "print(model2.networks[1].cause_std)\n",
    "print(model2.networks[1].target_std)\n",
    "loss2, best_model2 = train_rbf(model2, input_cause2, input_target2, Y, 0.01, 120, device)\n",
    "print(best_model2.networks[1].init_weight_cause)\n",
    "print(best_model2.networks[1].cause_std)\n",
    "print(model2.networks[1].target_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2d = df[['a','c']]\n",
    "torch.manual_seed(1234)\n",
    "input_cause3, input_target3, Y = data_split(X2d, 'a', 'c', 10)\n",
    "model3 = RBFnet(input_cause.size()[0], 1, input_cause.size()[1])\n",
    "print(model3.networks[1].init_weight_cause)\n",
    "print(model3.networks[1].cause_std)\n",
    "print(model3.networks[1].target_std)\n",
    "loss3, best_model3 = train_rbf(model3, input_cause3, input_target3, Y, 0.01, 120, device)\n",
    "print(best_model3.networks[1].init_weight_cause)\n",
    "print(best_model3.networks[1].cause_std)\n",
    "print(model3.networks[1].target_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1695f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
