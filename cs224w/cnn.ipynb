{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d55e502",
   "metadata": {},
   "source": [
    "# CNN\n",
    " - image data를 그대로사용\n",
    " - 각 channel 별로 filter를 통과하여 합산(feature map 추출)\n",
    " - 하나의 filter에는 하나의 feature map이 나온다.\n",
    " - feature map을 actvation function을 통과하여 activation map 추출\n",
    " - activation map을 pooling layer 통과시킨다.\n",
    " - loss를 확인후 filter update\n",
    " - output size : (N - F) / stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7d6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter : convolution layer \n",
    "# stride : filter의 이동거리 stride값이 커질경우 output의 크기가 작아짐\n",
    "# padding :손실을 최소화 하기 위해 사용(ex zero padding)\n",
    "# pooling : convolution 과정을 통해 나온 결과값(feature map)의 dimentionality를 축소 (max pooling, average pooling)\n",
    "# flatten : dense layer를 통과할수 있게 하기위한 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e14cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757719fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6675033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "}\n",
    "# M = pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ead302a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, model_code, in_channel, out_dim, act, use_bn):\n",
    "        super(CNN, self).__init__()\n",
    "        if act == 'relu':\n",
    "            self.act = nn.ReLU()\n",
    "        elif act == 'sigmoid':\n",
    "            self.act = nn.Sigmoid()\n",
    "        elif act == 'tanh':\n",
    "            self.act = TanH()\n",
    "        else:\n",
    "            raise ValueError('Not a valid activation function code')\n",
    "        \n",
    "        self.layers = self.make_layers(model_code, in_channel, use_bn)\n",
    "        self.classifer = nn.Sequential(nn.Linear(512,256), self.act, nn.Linear(256, out_dim))\n",
    "            \n",
    "    def make_layers(self, model_code, in_channel, use_bn):\n",
    "        layers = []\n",
    "        for x in cfg[model_code]:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size = 2, stride = 2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels = in_channel,\n",
    "                                     out_channels = x, \n",
    "                                     kernel_size = 3,\n",
    "                                     stride = 1,\n",
    "                                     padding = 1)]\n",
    "                if use_bn:\n",
    "                    layers += [nn.BatchNorm2d(x)]\n",
    "                layers += [self.act]\n",
    "                in_channel = x\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.size())\n",
    "        x = self.classifer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b83260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimenison_check():\n",
    "    model = CNN(model_code='VGG11',in_channel= 3,out_dim = 10, act = 'relu', use_bn= True)\n",
    "    x = torch.randn(2,3, 32, 32) # 임의의 input\n",
    "    y = model(x)\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d4a0858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 1, 1])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "dimenison_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2ece35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b467cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
