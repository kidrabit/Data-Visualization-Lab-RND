{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f90002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e61c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFlayer(nn.Module):\n",
    "    def __init__(self, timelag):\n",
    "        super(RBFlayer, self).__init__()\n",
    "\n",
    "        self.timelag = timelag\n",
    "        torch.cuda.manual_seed(0)\n",
    "\n",
    "        self.init_weight = nn.Parameter(torch.rand(self.timelag))\n",
    "        self.rbf_clt = self.init_clt()\n",
    "        self.rbf_std = self.init_std()\n",
    "        \n",
    "\n",
    "    def init_clt(self):\n",
    "        return nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def init_std(self):\n",
    "        return nn.Parameter(torch.rand(1))\n",
    "    \n",
    "    def rbf(self, x, cluster, std):\n",
    "        return torch.exp(-(x - cluster) * (x - cluster) / 2 * (std * std))\n",
    "    \n",
    "    def rbf_gradient(self, x, clt, std): # again\n",
    "        return (-1 * (x - clt) * (x - clt) / (std * std)) * (torch.exp(-(x - clt) * (x - clt) / 2 * (std * std)))\n",
    "    \n",
    "    \n",
    "    ## sum \n",
    "    \n",
    "    def forward(self, x):        \n",
    "        for i in range(len(x)):\n",
    "            if i == 0:\n",
    "                a = self.rbf(x[i], self.rbf_clt, self.rbf_std)\n",
    "            else:\n",
    "                a = torch.cat([a, self.rbf(x[i], self.rbf_clt, self.rbf_std)], dim=0)\n",
    "        cause = self.init_weight * a\n",
    "        \n",
    "        \n",
    "        return cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de9d9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_parameters(model, best_model):\n",
    "    '''Move parameter values from best_model to model.'''\n",
    "    for params, best_params in zip(model.parameters(), best_model.parameters()):\n",
    "        params.data = best_params\n",
    "        \n",
    "def train_RBFlayer(model, input_,target, lr, epochs, lookback = 5, device = device):\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    train_loss_list = []\n",
    "    \n",
    "    best_it = None\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    target_list = []\n",
    "    for j in range(len(target) - 2):\n",
    "        target_list.append((target[j+2] - target[j])/2)\n",
    "    \n",
    "    loss_list = []\n",
    "    cause_list = []\n",
    "    for epoch in range(epochs):\n",
    "        cause = model(input_)\n",
    "        cause_list.append(cause)\n",
    "        grad = []\n",
    "        \n",
    "        \n",
    "        for i in range(len(cause) - 2):\n",
    "            grad.append((cause[i+2] - cause[i])/2)\n",
    "        \n",
    "        loss1 = sum([loss_fn(grad[i], target_list[i]) for i in range(len(grad))])\n",
    "        loss2 = sum([loss_fn(cause[i], target[i]) for i in range(len(input_))])\n",
    "        \n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        mean_loss = loss / len(grad)\n",
    "        train_loss_list.append(mean_loss)\n",
    "        \n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_it = epoch\n",
    "            best_model = deepcopy(model)\n",
    "            \n",
    "        elif (epoch - best_it) == lookback:\n",
    "            if verbose:\n",
    "                print('Stopping early')\n",
    "            break\n",
    "    print(\"epoch {} cause loss {} :\".format(epoch, loss / len(input_)))\n",
    "    print('gradient loss :', loss1/len(grad))\n",
    "    print('value loss :', loss2/len(input_))\n",
    "                \n",
    "    best_cause = cause_list[best_it]    \n",
    "    restore_parameters(model, best_model)\n",
    "\n",
    "    return best_model, loss_list, best_cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5142a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, cause, target, timelag, device = device):\n",
    "    input_cause = []\n",
    "    input_target = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(X) - (timelag + 1)):\n",
    "        input_cause.append(X[cause].values[i: i + timelag])\n",
    "        input_target.append(X[target].values[i: i + timelag])\n",
    "        Y.append([X[target][i + timelag + 1]])\n",
    "\n",
    "    return torch.tensor(input_cause, device=device).float(), torch.tensor(input_target,device=device).float(), torch.tensor(Y, device=device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66145b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75055630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./road_gang.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c459c56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1220029700</th>\n",
       "      <th>1220032100</th>\n",
       "      <th>1220033000</th>\n",
       "      <th>1220024600</th>\n",
       "      <th>1220028200</th>\n",
       "      <th>1220025300</th>\n",
       "      <th>1220029200</th>\n",
       "      <th>1220034000</th>\n",
       "      <th>1220034300</th>\n",
       "      <th>1220027500</th>\n",
       "      <th>...</th>\n",
       "      <th>1220026300</th>\n",
       "      <th>1220033400</th>\n",
       "      <th>1220025200</th>\n",
       "      <th>1220033100</th>\n",
       "      <th>1220031800</th>\n",
       "      <th>1220033300</th>\n",
       "      <th>1220031000</th>\n",
       "      <th>1220034600</th>\n",
       "      <th>1220032800</th>\n",
       "      <th>1220026800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.19</td>\n",
       "      <td>29.65</td>\n",
       "      <td>28.08</td>\n",
       "      <td>25.14</td>\n",
       "      <td>20.30</td>\n",
       "      <td>28.74</td>\n",
       "      <td>31.59</td>\n",
       "      <td>32.78</td>\n",
       "      <td>27.48</td>\n",
       "      <td>22.42</td>\n",
       "      <td>...</td>\n",
       "      <td>31.11</td>\n",
       "      <td>31.87</td>\n",
       "      <td>25.61</td>\n",
       "      <td>35.04</td>\n",
       "      <td>36.00</td>\n",
       "      <td>31.82</td>\n",
       "      <td>25.18</td>\n",
       "      <td>24.80</td>\n",
       "      <td>17.00</td>\n",
       "      <td>29.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.96</td>\n",
       "      <td>24.27</td>\n",
       "      <td>26.63</td>\n",
       "      <td>26.65</td>\n",
       "      <td>20.49</td>\n",
       "      <td>26.28</td>\n",
       "      <td>28.80</td>\n",
       "      <td>30.56</td>\n",
       "      <td>26.95</td>\n",
       "      <td>26.38</td>\n",
       "      <td>...</td>\n",
       "      <td>30.26</td>\n",
       "      <td>34.42</td>\n",
       "      <td>26.18</td>\n",
       "      <td>34.95</td>\n",
       "      <td>36.61</td>\n",
       "      <td>30.24</td>\n",
       "      <td>25.07</td>\n",
       "      <td>21.33</td>\n",
       "      <td>26.80</td>\n",
       "      <td>28.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.20</td>\n",
       "      <td>28.07</td>\n",
       "      <td>27.76</td>\n",
       "      <td>24.94</td>\n",
       "      <td>22.35</td>\n",
       "      <td>27.88</td>\n",
       "      <td>32.74</td>\n",
       "      <td>32.22</td>\n",
       "      <td>35.34</td>\n",
       "      <td>24.03</td>\n",
       "      <td>...</td>\n",
       "      <td>33.27</td>\n",
       "      <td>24.70</td>\n",
       "      <td>24.06</td>\n",
       "      <td>31.08</td>\n",
       "      <td>37.30</td>\n",
       "      <td>27.94</td>\n",
       "      <td>24.16</td>\n",
       "      <td>30.84</td>\n",
       "      <td>24.68</td>\n",
       "      <td>31.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.72</td>\n",
       "      <td>23.98</td>\n",
       "      <td>26.34</td>\n",
       "      <td>27.54</td>\n",
       "      <td>24.68</td>\n",
       "      <td>29.85</td>\n",
       "      <td>27.55</td>\n",
       "      <td>28.83</td>\n",
       "      <td>31.98</td>\n",
       "      <td>24.20</td>\n",
       "      <td>...</td>\n",
       "      <td>32.80</td>\n",
       "      <td>30.08</td>\n",
       "      <td>26.93</td>\n",
       "      <td>35.77</td>\n",
       "      <td>34.74</td>\n",
       "      <td>27.34</td>\n",
       "      <td>25.15</td>\n",
       "      <td>27.20</td>\n",
       "      <td>24.02</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.21</td>\n",
       "      <td>24.11</td>\n",
       "      <td>26.63</td>\n",
       "      <td>24.71</td>\n",
       "      <td>19.57</td>\n",
       "      <td>26.93</td>\n",
       "      <td>29.77</td>\n",
       "      <td>30.60</td>\n",
       "      <td>28.39</td>\n",
       "      <td>23.18</td>\n",
       "      <td>...</td>\n",
       "      <td>30.48</td>\n",
       "      <td>26.82</td>\n",
       "      <td>26.36</td>\n",
       "      <td>32.22</td>\n",
       "      <td>38.51</td>\n",
       "      <td>28.47</td>\n",
       "      <td>23.82</td>\n",
       "      <td>30.69</td>\n",
       "      <td>23.19</td>\n",
       "      <td>33.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>25.93</td>\n",
       "      <td>30.45</td>\n",
       "      <td>24.45</td>\n",
       "      <td>33.18</td>\n",
       "      <td>15.57</td>\n",
       "      <td>20.59</td>\n",
       "      <td>30.61</td>\n",
       "      <td>29.28</td>\n",
       "      <td>23.61</td>\n",
       "      <td>30.60</td>\n",
       "      <td>...</td>\n",
       "      <td>19.85</td>\n",
       "      <td>25.20</td>\n",
       "      <td>27.80</td>\n",
       "      <td>31.92</td>\n",
       "      <td>30.67</td>\n",
       "      <td>24.67</td>\n",
       "      <td>29.33</td>\n",
       "      <td>27.84</td>\n",
       "      <td>25.39</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>28.45</td>\n",
       "      <td>27.57</td>\n",
       "      <td>25.38</td>\n",
       "      <td>26.65</td>\n",
       "      <td>14.22</td>\n",
       "      <td>22.52</td>\n",
       "      <td>28.59</td>\n",
       "      <td>31.06</td>\n",
       "      <td>23.44</td>\n",
       "      <td>25.70</td>\n",
       "      <td>...</td>\n",
       "      <td>24.13</td>\n",
       "      <td>22.81</td>\n",
       "      <td>30.25</td>\n",
       "      <td>33.22</td>\n",
       "      <td>30.90</td>\n",
       "      <td>35.58</td>\n",
       "      <td>24.49</td>\n",
       "      <td>20.18</td>\n",
       "      <td>23.27</td>\n",
       "      <td>20.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>25.24</td>\n",
       "      <td>27.17</td>\n",
       "      <td>25.96</td>\n",
       "      <td>30.91</td>\n",
       "      <td>14.31</td>\n",
       "      <td>22.32</td>\n",
       "      <td>33.68</td>\n",
       "      <td>27.55</td>\n",
       "      <td>24.82</td>\n",
       "      <td>30.14</td>\n",
       "      <td>...</td>\n",
       "      <td>22.21</td>\n",
       "      <td>23.94</td>\n",
       "      <td>30.70</td>\n",
       "      <td>37.34</td>\n",
       "      <td>36.29</td>\n",
       "      <td>26.00</td>\n",
       "      <td>27.74</td>\n",
       "      <td>24.46</td>\n",
       "      <td>27.52</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>28.05</td>\n",
       "      <td>27.64</td>\n",
       "      <td>26.57</td>\n",
       "      <td>27.84</td>\n",
       "      <td>14.21</td>\n",
       "      <td>19.66</td>\n",
       "      <td>34.09</td>\n",
       "      <td>38.60</td>\n",
       "      <td>23.98</td>\n",
       "      <td>32.08</td>\n",
       "      <td>...</td>\n",
       "      <td>24.17</td>\n",
       "      <td>20.92</td>\n",
       "      <td>29.39</td>\n",
       "      <td>31.57</td>\n",
       "      <td>32.62</td>\n",
       "      <td>27.73</td>\n",
       "      <td>31.33</td>\n",
       "      <td>30.03</td>\n",
       "      <td>22.63</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>26.72</td>\n",
       "      <td>25.60</td>\n",
       "      <td>25.77</td>\n",
       "      <td>29.72</td>\n",
       "      <td>16.04</td>\n",
       "      <td>22.76</td>\n",
       "      <td>32.24</td>\n",
       "      <td>29.45</td>\n",
       "      <td>23.94</td>\n",
       "      <td>30.57</td>\n",
       "      <td>...</td>\n",
       "      <td>18.84</td>\n",
       "      <td>24.23</td>\n",
       "      <td>31.18</td>\n",
       "      <td>35.69</td>\n",
       "      <td>34.26</td>\n",
       "      <td>32.76</td>\n",
       "      <td>24.97</td>\n",
       "      <td>27.84</td>\n",
       "      <td>24.15</td>\n",
       "      <td>19.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1220029700  1220032100  1220033000  1220024600  1220028200  1220025300  \\\n",
       "0          25.19       29.65       28.08       25.14       20.30       28.74   \n",
       "1          26.96       24.27       26.63       26.65       20.49       26.28   \n",
       "2          26.20       28.07       27.76       24.94       22.35       27.88   \n",
       "3          26.72       23.98       26.34       27.54       24.68       29.85   \n",
       "4          27.21       24.11       26.63       24.71       19.57       26.93   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2875       25.93       30.45       24.45       33.18       15.57       20.59   \n",
       "2876       28.45       27.57       25.38       26.65       14.22       22.52   \n",
       "2877       25.24       27.17       25.96       30.91       14.31       22.32   \n",
       "2878       28.05       27.64       26.57       27.84       14.21       19.66   \n",
       "2879       26.72       25.60       25.77       29.72       16.04       22.76   \n",
       "\n",
       "      1220029200  1220034000  1220034300  1220027500  ...  1220026300  \\\n",
       "0          31.59       32.78       27.48       22.42  ...       31.11   \n",
       "1          28.80       30.56       26.95       26.38  ...       30.26   \n",
       "2          32.74       32.22       35.34       24.03  ...       33.27   \n",
       "3          27.55       28.83       31.98       24.20  ...       32.80   \n",
       "4          29.77       30.60       28.39       23.18  ...       30.48   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2875       30.61       29.28       23.61       30.60  ...       19.85   \n",
       "2876       28.59       31.06       23.44       25.70  ...       24.13   \n",
       "2877       33.68       27.55       24.82       30.14  ...       22.21   \n",
       "2878       34.09       38.60       23.98       32.08  ...       24.17   \n",
       "2879       32.24       29.45       23.94       30.57  ...       18.84   \n",
       "\n",
       "      1220033400  1220025200  1220033100  1220031800  1220033300  1220031000  \\\n",
       "0          31.87       25.61       35.04       36.00       31.82       25.18   \n",
       "1          34.42       26.18       34.95       36.61       30.24       25.07   \n",
       "2          24.70       24.06       31.08       37.30       27.94       24.16   \n",
       "3          30.08       26.93       35.77       34.74       27.34       25.15   \n",
       "4          26.82       26.36       32.22       38.51       28.47       23.82   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2875       25.20       27.80       31.92       30.67       24.67       29.33   \n",
       "2876       22.81       30.25       33.22       30.90       35.58       24.49   \n",
       "2877       23.94       30.70       37.34       36.29       26.00       27.74   \n",
       "2878       20.92       29.39       31.57       32.62       27.73       31.33   \n",
       "2879       24.23       31.18       35.69       34.26       32.76       24.97   \n",
       "\n",
       "      1220034600  1220032800  1220026800  \n",
       "0          24.80       17.00       29.09  \n",
       "1          21.33       26.80       28.95  \n",
       "2          30.84       24.68       31.14  \n",
       "3          27.20       24.02       33.40  \n",
       "4          30.69       23.19       33.97  \n",
       "...          ...         ...         ...  \n",
       "2875       27.84       25.39       19.88  \n",
       "2876       20.18       23.27       20.13  \n",
       "2877       24.46       27.52       21.00  \n",
       "2878       30.03       22.63       20.20  \n",
       "2879       27.84       24.15       19.11  \n",
       "\n",
       "[2880 rows x 57 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659e1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[['1220029700','1220032100']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f44b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9195e932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee8e2478b0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a['1220029700'][100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901de3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2d = df[['1220029700','1220032100']]\n",
    "torch.manual_seed(1234)\n",
    "input_cause, input_target, Y = data_split(X2d, '1220029700', '1220032100', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15bcced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cause1 = input_cause[:5]\n",
    "input_cause2 = input_cause[100:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce00fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 time series\n",
      "epoch 999 cause loss 897.6409301757812 :\n",
      "gradient loss : tensor(5.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(892.4648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 126.11852669715881\n",
      "-------------------------------------------------------------------------------------------\n",
      "1 번째 time series\n",
      "epoch 999 cause loss 898.5419311523438 :\n",
      "gradient loss : tensor(5.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(893.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 124.28551745414734\n",
      "-------------------------------------------------------------------------------------------\n",
      "2 번째 time series\n",
      "epoch 999 cause loss 397.0220642089844 :\n",
      "gradient loss : tensor(4.8400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(392.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 125.76394867897034\n",
      "-------------------------------------------------------------------------------------------\n",
      "3 번째 time series\n",
      "epoch 999 cause loss 899.8443603515625 :\n",
      "gradient loss : tensor(5.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(894.6584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 124.44138765335083\n",
      "-------------------------------------------------------------------------------------------\n",
      "4 번째 time series\n",
      "epoch 999 cause loss 898.9635620117188 :\n",
      "gradient loss : tensor(5.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(893.7689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 128.49188089370728\n",
      "-------------------------------------------------------------------------------------------\n",
      "5 번째 time series\n",
      "epoch 999 cause loss 898.1273803710938 :\n",
      "gradient loss : tensor(5.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(892.9136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 129.6882164478302\n",
      "-------------------------------------------------------------------------------------------\n",
      "6 번째 time series\n",
      "epoch 999 cause loss 402.6731872558594 :\n",
      "gradient loss : tensor(4.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(398.0357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 127.83323049545288\n",
      "-------------------------------------------------------------------------------------------\n",
      "7 번째 time series\n",
      "epoch 999 cause loss 901.4574584960938 :\n",
      "gradient loss : tensor(5.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(896.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 124.51479411125183\n",
      "-------------------------------------------------------------------------------------------\n",
      "8 번째 time series\n",
      "epoch 999 cause loss 407.4468994140625 :\n",
      "gradient loss : tensor(4.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(402.5882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 125.48717045783997\n",
      "-------------------------------------------------------------------------------------------\n",
      "9 번째 time series\n",
      "epoch 999 cause loss 405.29144287109375 :\n",
      "gradient loss : tensor(5.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(400.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 126.52266883850098\n",
      "-------------------------------------------------------------------------------------------\n",
      "10 번째 time series\n",
      "epoch 999 cause loss 900.3256225585938 :\n",
      "gradient loss : tensor(5.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(894.9646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 126.85782170295715\n",
      "-------------------------------------------------------------------------------------------\n",
      "11 번째 time series\n",
      "epoch 999 cause loss 415.89752197265625 :\n",
      "gradient loss : tensor(5.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(410.8414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 124.7884430885315\n",
      "-------------------------------------------------------------------------------------------\n",
      "12 번째 time series\n",
      "epoch 999 cause loss 414.1788330078125 :\n",
      "gradient loss : tensor(5.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(409.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 127.30886125564575\n",
      "-------------------------------------------------------------------------------------------\n",
      "13 번째 time series\n",
      "epoch 999 cause loss 410.0755310058594 :\n",
      "gradient loss : tensor(5.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(405.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 125.34728384017944\n",
      "-------------------------------------------------------------------------------------------\n",
      "14 번째 time series\n",
      "epoch 999 cause loss 419.1458740234375 :\n",
      "gradient loss : tensor(5.0282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(414.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 121.74823379516602\n",
      "-------------------------------------------------------------------------------------------\n",
      "15 번째 time series\n",
      "epoch 999 cause loss 400.21502685546875 :\n",
      "gradient loss : tensor(5.0645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(395.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 125.22427773475647\n",
      "-------------------------------------------------------------------------------------------\n",
      "16 번째 time series\n",
      "epoch 999 cause loss 903.7337036132812 :\n",
      "gradient loss : tensor(5.5492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(898.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 124.19763135910034\n",
      "-------------------------------------------------------------------------------------------\n",
      "17 번째 time series\n",
      "epoch 999 cause loss 402.8470153808594 :\n",
      "gradient loss : tensor(5.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(397.7976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 126.4628095626831\n",
      "-------------------------------------------------------------------------------------------\n",
      "18 번째 time series\n",
      "epoch 999 cause loss 905.917724609375 :\n",
      "gradient loss : tensor(5.5789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(900.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 124.20469379425049\n",
      "-------------------------------------------------------------------------------------------\n",
      "19 번째 time series\n",
      "epoch 999 cause loss 902.4227905273438 :\n",
      "gradient loss : tensor(5.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(896.9484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 122.2342312335968\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cause_list = []\n",
    "for i in range(len(input_cause1)):\n",
    "    print(i,\"번째 time series\")\n",
    "    start = time.time()\n",
    "    model = RBFlayer(100)\n",
    "    best_model, loss_list, best_cause = train_RBFlayer(model, input_cause1[i], 0.01, 1000, device)\n",
    "    cause_list.append(best_cause.cpu().detach().numpy())\n",
    "    print(\"time :\", time.time() - start)\n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    \n",
    "import pickle\n",
    "\n",
    "filePath = './gang_grad1_epcoh1000.txt'\n",
    "with open(filePath, 'wb') as lf:\n",
    "    pickle.dump(cause_list, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2abfb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = input_cause1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ef95b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 time series\n",
      "epoch 999 cause loss 393.1730651855469 :\n",
      "gradient loss : tensor(4.7079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(388.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 121.4890387058258\n",
      "-------------------------------------------------------------------------------------------\n",
      "1 번째 time series\n",
      "epoch 999 cause loss 412.5904235839844 :\n",
      "gradient loss : tensor(4.7348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(407.9503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 120.42959809303284\n",
      "-------------------------------------------------------------------------------------------\n",
      "2 번째 time series\n",
      "epoch 999 cause loss 411.2395324707031 :\n",
      "gradient loss : tensor(4.7801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(406.5550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 121.28943657875061\n",
      "-------------------------------------------------------------------------------------------\n",
      "3 번째 time series\n",
      "epoch 999 cause loss 395.3108825683594 :\n",
      "gradient loss : tensor(4.7511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(390.6548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 116.78555655479431\n",
      "-------------------------------------------------------------------------------------------\n",
      "4 번째 time series\n",
      "epoch 999 cause loss 417.4981689453125 :\n",
      "gradient loss : tensor(4.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(412.7094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 115.43859243392944\n",
      "-------------------------------------------------------------------------------------------\n",
      "5 번째 time series\n",
      "epoch 999 cause loss 416.3038330078125 :\n",
      "gradient loss : tensor(4.7776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(411.6218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 114.35277605056763\n",
      "-------------------------------------------------------------------------------------------\n",
      "6 번째 time series\n",
      "epoch 999 cause loss 413.26287841796875 :\n",
      "gradient loss : tensor(4.7438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(408.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 122.28389358520508\n",
      "-------------------------------------------------------------------------------------------\n",
      "7 번째 time series\n",
      "epoch 999 cause loss 418.00836181640625 :\n",
      "gradient loss : tensor(4.8406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(413.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 121.72394275665283\n",
      "-------------------------------------------------------------------------------------------\n",
      "8 번째 time series\n",
      "epoch 999 cause loss 405.84222412109375 :\n",
      "gradient loss : tensor(4.8713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(401.0683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 121.24082732200623\n",
      "-------------------------------------------------------------------------------------------\n",
      "9 번째 time series\n",
      "epoch 999 cause loss 379.96142578125 :\n",
      "gradient loss : tensor(5.0317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(375.0304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 122.23102474212646\n",
      "-------------------------------------------------------------------------------------------\n",
      "10 번째 time series\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-37b99b4e3c03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRBFlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_cause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_RBFlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_cause1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcause_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_cause\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"time :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-5e56fd5ff41f>\u001b[0m in \u001b[0;36mtrain_RBFlayer\u001b[1;34m(model, input_, target, lr, epochs, lookback, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mcause_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mcause_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-69b3e80a974d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbf_clt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbf_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbf_clt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbf_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mcause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-69b3e80a974d>\u001b[0m in \u001b[0;36mrbf\u001b[1;34m(self, x, cluster, std)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrbf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrbf_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cause_list = []\n",
    "for i in range(len(input_cause1)):\n",
    "    print(i,\"번째 time series\")\n",
    "    start = time.time()\n",
    "    model = RBFlayer(100)\n",
    "    best_model, loss_list, best_cause = train_RBFlayer(model, target[i],input_cause1[i], 0.01, 1000, device)\n",
    "    cause_list.append(best_cause.cpu().detach().numpy())\n",
    "    print(\"time :\", time.time() - start)\n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    \n",
    "import pickle\n",
    "\n",
    "filePath = './gang_scale_grad1_epcoh1000.txt'\n",
    "with open(filePath, 'wb') as lf:\n",
    "    pickle.dump(cause_list, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aa7f2f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 time series\n",
      "epoch 999 cause loss 779.6001586914062 :\n",
      "gradient loss : tensor(5.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(774.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 122.56511044502258\n",
      "-------------------------------------------------------------------------------------------\n",
      "1 번째 time series\n",
      "epoch 999 cause loss 782.0703735351562 :\n",
      "gradient loss : tensor(5.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(776.8850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 122.61654448509216\n",
      "-------------------------------------------------------------------------------------------\n",
      "2 번째 time series\n",
      "epoch 999 cause loss 776.5667724609375 :\n",
      "gradient loss : tensor(5.0854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "value loss : tensor(771.5831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "time : 121.75101661682129\n",
      "-------------------------------------------------------------------------------------------\n",
      "3 번째 time series\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b58c4343d6fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRBFlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_cause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_RBFlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_cause1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcause_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_cause\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"time :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-5e56fd5ff41f>\u001b[0m in \u001b[0;36mtrain_RBFlayer\u001b[1;34m(model, input_, target, lr, epochs, lookback, device)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cause_list = []\n",
    "for i in range(len(input_cause1)):\n",
    "    print(i,\"번째 time series\")\n",
    "    start = time.time()\n",
    "    model = RBFlayer(100)\n",
    "    best_model, loss_list, best_cause = train_RBFlayer(model, target[i],input_cause1[i], 0.001, 1000, device)\n",
    "    cause_list.append(best_cause.cpu().detach().numpy())\n",
    "    print(\"time :\", time.time() - start)\n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    \n",
    "import pickle\n",
    "\n",
    "filePath = './gang_scale_grad1_epcoh1000.txt'\n",
    "with open(filePath, 'wb') as lf:\n",
    "    pickle.dump(cause_list, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb440137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
