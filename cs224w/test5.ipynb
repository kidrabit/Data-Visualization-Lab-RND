{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7537764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class RBFlayer(nn.Module):\n",
    "    def __init__(self, timelag):\n",
    "        super(RBFlayer, self).__init__()\n",
    "\n",
    "        self.timelag = timelag\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch.cuda.manual_seed(0)\n",
    "\n",
    "        self.init_weight_cause = nn.Parameter(torch.rand(self.timelag, device=device))\n",
    "        self.init_weight_target = nn.Parameter(torch.rand(self.timelag, device=device))\n",
    "        self.cause_clt = self.init_clt()\n",
    "        self.cause_std = self.init_clt()\n",
    "        self.target_clt = nn.Parameter(torch.rand(1, device=device))\n",
    "        self.target_std = nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def init_clt(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def init_std(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def rbf(self, x, cluster, std):\n",
    "        return torch.exp(-(x - cluster) * (x - cluster) / 2 * (std * std))\n",
    "\n",
    "\n",
    "    def forward(self, cause, target):\n",
    "\n",
    "        for i in range(len(cause)):\n",
    "            if i == 0:\n",
    "                a = self.rbf(cause[i], self.cause_clt, self.cause_std)\n",
    "            else:\n",
    "                a = torch.cat([a, self.rbf(cause[i], self.cause_clt, self.cause_std)], dim=0)\n",
    "        cause = self.init_weight_cause * a\n",
    "\n",
    "        for j in range(len(target)):\n",
    "            if j == 0:\n",
    "                b = self.rbf(target[j], self.target_clt, self.target_std)\n",
    "            else:\n",
    "                b = torch.cat([b, self.rbf(target[j], self.target_clt, self.target_std)], dim=0)\n",
    "        target = self.init_weight_target * b\n",
    "\n",
    "        return cause, target\n",
    "\n",
    "\n",
    "class RBFnet(nn.Module):\n",
    "    def __init__(self, input_size , output_size, timelag):\n",
    "        super(RBFnet,self).__init__()\n",
    "\n",
    "        self.input_size = input_size      # number of data\n",
    "        self.output_size = output_size\n",
    "        self.timelag = timelag\n",
    "\n",
    "        self.linear = nn.ModuleList([nn.Linear(self.timelag*2,1) for _ in range(self.input_size)])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.networks = nn.ModuleList([RBFlayer(self.timelag) for _ in range(self.input_size)])\n",
    "\n",
    "    def cause_target(self, cause, target):\n",
    "        x = torch.cat((cause, target), 0)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def GC(self, threshold=True):\n",
    "        '''\n",
    "        Extract learned Granger causality.\n",
    "        Args:\n",
    "          threshold: return norm of weights, or whether norm is nonzero.\n",
    "        Returns:\n",
    "          GC: (p x p) matrix. Entry (i, j) indicates whether variable j is\n",
    "            Granger causal of variable i.\n",
    "        '''\n",
    "        GC = [torch.norm(net.init_weight_cause, dim=0)\n",
    "              for net in self.networks]\n",
    "        GC = torch.stack(GC)\n",
    "        if threshold:\n",
    "            return (GC > 0).int()\n",
    "        else:\n",
    "            return GC\n",
    "\n",
    "\n",
    "    def forward(self, causes, targets):\n",
    "        out_list = []\n",
    "        for i in range(self.input_size):\n",
    "            cause, target = self.networks[i](causes[i], targets[i])\n",
    "            cause, target = self.relu(cause), self.relu(target)\n",
    "            pred = torch.cat((cause, target),0)\n",
    "            pred = self.linear[i](pred)\n",
    "            out_list.append(pred)\n",
    "\n",
    "        return out_list\n",
    "\n",
    "\n",
    "def restore_parameters(model, best_model):\n",
    "    '''Move parameter values from best_model to model.'''\n",
    "    for params, best_params in zip(model.parameters(), best_model.parameters()):\n",
    "        params.data = best_params\n",
    "\n",
    "def rbf_p(x, clt, std):\n",
    "    return (-2 * (x - clt) / (std * std)) * (torch.exp(-(x - clt) * (x - clt) / 2 * (std * std)))\n",
    "\n",
    "def rbf_fn(x, cluster, std):\n",
    "    return torch.exp(-(x - cluster) * (x - cluster) / 2*(std * std))\n",
    "\n",
    "def rbf_grad_cause(model, input):\n",
    "\n",
    "    rbf_grad_list = []\n",
    "    for i in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[i].cause_clt\n",
    "        std = model.networks[i].cause_std\n",
    "\n",
    "        for j in range(input.shape[1] - 2):\n",
    "            list_.append(rbf_p(input[i][j + 1], clt, std))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "\n",
    "def rbf_grad_target(model, input):\n",
    "\n",
    "    rbf_grad_list = []\n",
    "    for i in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[i].target_clt\n",
    "        std = model.networks[i].target_std\n",
    "\n",
    "        for j in range(input.shape[1] - 2):\n",
    "            list_.append(rbf_p(input[i][j + 1], clt, std))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "\n",
    "def rbf_grad_num_cause(input):\n",
    "    rbf_grad_list = []\n",
    "    for j in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[j].cause_clt\n",
    "        std = model.networks[j].cause_std\n",
    "\n",
    "        for i in range(input.shape[1] - 2):\n",
    "            list_.append((rbf_fn(input[j][i+2],clt,std) - rbf_fn(input[j][i], clt, std)) /\n",
    "                                        (input[j][i+2] - input[j][i]))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "def rbf_grad_num_target(input):\n",
    "    rbf_grad_list = []\n",
    "    for j in range(input.shape[0]):\n",
    "        list_ = []\n",
    "        clt = model.networks[j].target_clt\n",
    "        std = model.networks[j].target_std\n",
    "\n",
    "        for i in range(input.shape[1] - 2):\n",
    "            list_.append((rbf_fn(input[j][i+2],clt,std) - rbf_fn(input[j][i], clt, std)) /\n",
    "                                        (input[j][i+2] - input[j][i]))\n",
    "\n",
    "        rbf_grad_list.append(list_)\n",
    "\n",
    "    return torch.Tensor(rbf_grad_list)\n",
    "\n",
    "def train_rbf(model, input_causes, input_targets, Y, lr, epochs, lookback=5,device = device):\n",
    "    # input_causes, input_targets : X\n",
    "    # Y : Y\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loss_list = []\n",
    "\n",
    "    best_it = None\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pred = model(input_causes, input_targets)\n",
    "        loss_ = sum([loss_fn(pred[i], Y[i]) for i in range(len(Y))])\n",
    "        loss_cause = loss_fn(rbf_grad_num_cause(input_causes), rbf_grad_cause(model, input_causes))\n",
    "        loss_target = loss_fn(rbf_grad_num_target(input_targets), rbf_grad_target(model, input_targets))\n",
    "        print(\"saaaa\",type(loss_cause))\n",
    "        print(\"saaae\",type(loss_))\n",
    "        loss = loss_ + loss_cause + loss_target\n",
    "        print(\"epoch {} loss {} :\".format(epoch, loss / len(Y)))\n",
    "\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_cause.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_target.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.zero_grad()\n",
    "\n",
    "\n",
    "        mean_loss = loss / len(Y)\n",
    "        train_loss_list.append(mean_loss)\n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_it = epoch\n",
    "            best_model = deepcopy(model)\n",
    "        elif (epoch - best_it) == lookback:\n",
    "            if verbose:\n",
    "                print('Stopping early')\n",
    "            break\n",
    "\n",
    "    restore_parameters(model, best_model)\n",
    "\n",
    "    return train_loss_list , model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c6406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, cause, target, timelag, device = device):\n",
    "    input_cause = []\n",
    "    input_target = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(X) - (timelag + 1)):\n",
    "        input_cause.append(X[cause].values[i: i + timelag])\n",
    "        input_target.append(X[target].values[i: i + timelag])\n",
    "        Y.append([X[target][i + timelag + 1]])\n",
    "\n",
    "    return torch.tensor(input_cause, device=device).float(), torch.tensor(input_target,device=device).float(), torch.tensor(Y, device=device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19140c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/chanyoung/Desktop/Neural-GC-master/lorenz_96_10_10_1000.csv')\n",
    "X2d = df[['a','b']]\n",
    "torch.manual_seed(1234)\n",
    "input_cause, input_target, Y = data_split(X2d, 'a', 'b', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04646bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.3990, 0.5167, 0.0249, 0.9401, 0.9459, 0.7967, 0.4150, 0.8203, 0.2290,\n",
      "        0.9096], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7874], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4503], device='cuda:0', requires_grad=True)\n",
      "saaaa <class 'torch.Tensor'>\n",
      "saaae <class 'torch.Tensor'>\n",
      "epoch 0 loss 27.549482345581055 :\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f99d8e762489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_rbf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_cause\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_weight_cause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-0f6b1f24cfe5>\u001b[0m in \u001b[0;36mtrain_rbf\u001b[1;34m(model, input_causes, input_targets, Y, lr, epochs, lookback, device)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mloss_cause\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "model = RBFnet(input_cause.size()[0], 1, input_cause.size()[1])\n",
    "print(model.networks[1].init_weight_cause)\n",
    "print(model.networks[1].cause_std)\n",
    "print(model.networks[1].target_std)\n",
    "loss, best_model = train_rbf(model, input_cause, input_target, Y, 0.01, 50, device)\n",
    "print(best_model.networks[1].init_weight_cause)\n",
    "print(best_model.networks[1].cause_std)\n",
    "print(model.networks[1].target_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8403b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
