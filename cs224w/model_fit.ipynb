{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9164949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2597c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFlayer(nn.Module):\n",
    "    def __init__(self, timelag):\n",
    "        super(RBFlayer, self).__init__()\n",
    "\n",
    "        self.timelag = timelag\n",
    "\n",
    "        # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch.cuda.manual_seed(0)\n",
    "\n",
    "        self.init_weight = nn.Parameter(torch.rand(self.timelag))\n",
    "        self.rbf_clt = self.init_clt()\n",
    "        self.rbf_std = self.init_std()\n",
    "        \n",
    "        self.b = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def init_clt(self):\n",
    "        return nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def init_std(self):\n",
    "        return nn.Parameter(torch.rand(1))\n",
    "    \n",
    "    def rbf(self, x, cluster, std):\n",
    "        return torch.exp(-(x - cluster) * (x - cluster) / 2 * (std * std))\n",
    "    \n",
    "    def rbf_gradient(self, x, clt, std):\n",
    "        return (-1 * (x - clt) * (x - clt) / (std * std)) * (torch.exp(-(x - clt) * (x - clt) / 2 * (std * std)))\n",
    "    \n",
    "    \n",
    "    def forward(self, x):        \n",
    "        for i in range(len(x)):\n",
    "            if i == 0:\n",
    "                a = self.rbf(x[i], self.rbf_clt, self.rbf_std)\n",
    "            else:\n",
    "                a = torch.cat([a, self.rbf(x[i], self.rbf_clt, self.rbf_std)], dim=0)\n",
    "        cause = self.init_weight * a\n",
    "        \n",
    "        \n",
    "        return cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6898c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_parameters(model, best_model):\n",
    "    '''Move parameter values from best_model to model.'''\n",
    "    for params, best_params in zip(model.parameters(), best_model.parameters()):\n",
    "        params.data = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f16a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RBFlayer(model, input_, lr, epochs, lookback = 5, device = device):\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    train_loss_list = []\n",
    "    \n",
    "    best_it = None\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    target = []\n",
    "    for j in range(len(input_) - 2):\n",
    "        target.append((input_[j+2] - input_[j])/2)\n",
    "    \n",
    "    loss_list = []\n",
    "    cause_list = []\n",
    "    for epoch in range(epochs):\n",
    "        cause = model(input_)\n",
    "        cause_list.append(cause)\n",
    "        grad = []\n",
    "        \n",
    "        \n",
    "        for i in range(len(cause) - 2):\n",
    "            grad.append((cause[i+2] - cause[i])/2)\n",
    "        \n",
    "        loss = sum([loss_fn(grad[i], target[i]) for i in range(len(grad))])\n",
    "\n",
    "        '''\n",
    "        print(\"epoch {} cause loss {} :\".format(epoch, loss / len(input_)))\n",
    "        print(\"------------------------------------------------------\")\n",
    "        print()\n",
    "        '''\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        mean_loss = loss / len(grad)\n",
    "        train_loss_list.append(mean_loss)\n",
    "        \n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_it = epoch\n",
    "            best_model = deepcopy(model)\n",
    "            \n",
    "        elif (epoch - best_it) == lookback:\n",
    "            if verbose:\n",
    "                print('Stopping early')\n",
    "            break\n",
    "    print(\"epoch {} cause loss {} :\".format(epoch, loss / len(input_)))\n",
    "                \n",
    "    best_cause = cause_list[best_it]    \n",
    "    restore_parameters(model, best_model)\n",
    "\n",
    "    return best_model, loss_list, best_cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6da675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, cause, target, timelag, device = device):\n",
    "    input_cause = []\n",
    "    input_target = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(X) - (timelag + 1)):\n",
    "        input_cause.append(X[cause].values[i: i + timelag])\n",
    "        input_target.append(X[target].values[i: i + timelag])\n",
    "        Y.append([X[target][i + timelag + 1]])\n",
    "\n",
    "    return torch.tensor(input_cause, device=device).float(), torch.tensor(input_target,device=device).float(), torch.tensor(Y, device=device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba0fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/chanyoung/Desktop/Neural-GC-master/lorenz_96_10_10_1000.csv')\n",
    "X2d = df[['a','b']]\n",
    "torch.manual_seed(1234)\n",
    "input_cause, input_target, Y = data_split(X2d, 'a', 'b', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db9682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cause = input_cause[:20]\n",
    "input_cause.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a63fb81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 time series\n",
      "epoch 999 cause loss 0.061188917607069016 :\n",
      "time : 115.37664747238159\n",
      "-------------------------------------------------------------------------------------------\n",
      "1 번째 time series\n",
      "epoch 999 cause loss 0.027772853150963783 :\n",
      "time : 113.19796395301819\n",
      "-------------------------------------------------------------------------------------------\n",
      "2 번째 time series\n",
      "epoch 999 cause loss 0.03972911089658737 :\n",
      "time : 112.32275438308716\n",
      "-------------------------------------------------------------------------------------------\n",
      "3 번째 time series\n",
      "epoch 999 cause loss 0.020239241421222687 :\n",
      "time : 125.69012117385864\n",
      "-------------------------------------------------------------------------------------------\n",
      "4 번째 time series\n",
      "epoch 999 cause loss 0.026726502925157547 :\n",
      "time : 121.11877536773682\n",
      "-------------------------------------------------------------------------------------------\n",
      "5 번째 time series\n",
      "epoch 999 cause loss 0.019136741757392883 :\n",
      "time : 122.63941359519958\n",
      "-------------------------------------------------------------------------------------------\n",
      "6 번째 time series\n",
      "epoch 999 cause loss 0.020756499841809273 :\n",
      "time : 119.84219884872437\n",
      "-------------------------------------------------------------------------------------------\n",
      "7 번째 time series\n",
      "epoch 999 cause loss 0.0224470067769289 :\n",
      "time : 117.54341340065002\n",
      "-------------------------------------------------------------------------------------------\n",
      "8 번째 time series\n",
      "epoch 999 cause loss 0.02200801856815815 :\n",
      "time : 126.01212239265442\n",
      "-------------------------------------------------------------------------------------------\n",
      "9 번째 time series\n",
      "epoch 999 cause loss 0.02082950808107853 :\n",
      "time : 114.11800217628479\n",
      "-------------------------------------------------------------------------------------------\n",
      "10 번째 time series\n",
      "epoch 999 cause loss 0.022384969517588615 :\n",
      "time : 105.46935319900513\n",
      "-------------------------------------------------------------------------------------------\n",
      "11 번째 time series\n",
      "epoch 999 cause loss 0.025395827367901802 :\n",
      "time : 105.0822639465332\n",
      "-------------------------------------------------------------------------------------------\n",
      "12 번째 time series\n",
      "epoch 999 cause loss 0.05391679331660271 :\n",
      "time : 106.428631067276\n",
      "-------------------------------------------------------------------------------------------\n",
      "13 번째 time series\n",
      "epoch 999 cause loss 0.03933682665228844 :\n",
      "time : 106.06211972236633\n",
      "-------------------------------------------------------------------------------------------\n",
      "14 번째 time series\n",
      "epoch 999 cause loss 0.041354626417160034 :\n",
      "time : 105.00539445877075\n",
      "-------------------------------------------------------------------------------------------\n",
      "15 번째 time series\n",
      "epoch 999 cause loss 0.05817947909235954 :\n",
      "time : 105.43878149986267\n",
      "-------------------------------------------------------------------------------------------\n",
      "16 번째 time series\n",
      "epoch 999 cause loss 0.05104535073041916 :\n",
      "time : 106.9005765914917\n",
      "-------------------------------------------------------------------------------------------\n",
      "17 번째 time series\n",
      "epoch 999 cause loss 0.020178742706775665 :\n",
      "time : 107.5692822933197\n",
      "-------------------------------------------------------------------------------------------\n",
      "18 번째 time series\n",
      "epoch 999 cause loss 0.02973908744752407 :\n",
      "time : 105.06698679924011\n",
      "-------------------------------------------------------------------------------------------\n",
      "19 번째 time series\n",
      "epoch 999 cause loss 0.043936703354120255 :\n",
      "time : 107.7673511505127\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cause_list = []\n",
    "for i in range(len(input_cause)):\n",
    "    print(i,\"번째 time series\")\n",
    "    start = time.time()\n",
    "    model = RBFlayer(100)\n",
    "    best_model, loss_list, best_cause = train_RBFlayer(model, input_cause[i], 0.01, 1000, device)\n",
    "    cause_list.append(best_cause.cpu().detach().numpy())\n",
    "    print(\"time :\", time.time() - start)\n",
    "    print('-------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8272fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filePath = './test3_epcoh1000.txt'\n",
    "with open(filePath, 'wb') as lf:\n",
    "    pickle.dump(cause_list, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc33f30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 time series\n",
      "epoch 1999 cause loss 0.0011501103872433305 :\n",
      "------------------------------------------------------\n",
      "1 번째 time series\n",
      "epoch 1999 cause loss 0.0015078928554430604 :\n",
      "------------------------------------------------------\n",
      "2 번째 time series\n",
      "epoch 1999 cause loss 0.0011376310139894485 :\n",
      "------------------------------------------------------\n",
      "3 번째 time series\n",
      "epoch 1999 cause loss 0.0007262340513989329 :\n",
      "------------------------------------------------------\n",
      "4 번째 time series\n",
      "epoch 1999 cause loss 0.00048040205729193985 :\n",
      "------------------------------------------------------\n",
      "5 번째 time series\n",
      "epoch 1999 cause loss 0.0007808118825778365 :\n",
      "------------------------------------------------------\n",
      "6 번째 time series\n",
      "epoch 1999 cause loss 0.0013475314481183887 :\n",
      "------------------------------------------------------\n",
      "7 번째 time series\n",
      "epoch 1999 cause loss 0.0007810455863364041 :\n",
      "------------------------------------------------------\n",
      "8 번째 time series\n",
      "epoch 1999 cause loss 0.0007879502372816205 :\n",
      "------------------------------------------------------\n",
      "9 번째 time series\n",
      "epoch 1999 cause loss 0.0009522556210868061 :\n",
      "------------------------------------------------------\n",
      "10 번째 time series\n",
      "epoch 1999 cause loss 0.0010364842601120472 :\n",
      "------------------------------------------------------\n",
      "11 번째 time series\n",
      "epoch 1999 cause loss 0.0012568000238388777 :\n",
      "------------------------------------------------------\n",
      "12 번째 time series\n",
      "epoch 1999 cause loss 0.0009491469245404005 :\n",
      "------------------------------------------------------\n",
      "13 번째 time series\n",
      "epoch 1999 cause loss 0.0009201416978612542 :\n",
      "------------------------------------------------------\n",
      "14 번째 time series\n",
      "epoch 1999 cause loss 0.0012560467002913356 :\n",
      "------------------------------------------------------\n",
      "15 번째 time series\n",
      "epoch 1999 cause loss 0.0012719138758257031 :\n",
      "------------------------------------------------------\n",
      "16 번째 time series\n",
      "epoch 1999 cause loss 0.0011787433177232742 :\n",
      "------------------------------------------------------\n",
      "17 번째 time series\n",
      "epoch 1999 cause loss 0.0012259141076356173 :\n",
      "------------------------------------------------------\n",
      "18 번째 time series\n",
      "epoch 1999 cause loss 0.0008154057431966066 :\n",
      "------------------------------------------------------\n",
      "19 번째 time series\n",
      "epoch 1999 cause loss 0.0006745144492015243 :\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cause_list = []\n",
    "for i in range(len(input_cause)):\n",
    "    print(i,\"번째 time series\")\n",
    "    model = RBFlayer(100)\n",
    "    best_model, loss_list, best_cause = train_RBFlayer(model, input_cause[i], 0.01, 2000, device)\n",
    "    cause_list.append(best_cause.cpu().detach().numpy())\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "filePath = './test2_epcoh2000.txt'\n",
    "with open(filePath, 'wb') as lf:\n",
    "    pickle.dump(cause_list, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891afcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
