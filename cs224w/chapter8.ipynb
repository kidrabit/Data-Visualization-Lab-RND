{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Intuition : Map nodes to d-dimensional embeddings such that similar nodes in the graph are emveddied close together\n",
    " - 즉, 임베딩에서의 유사도가 network 내에서의 유사도가 되도록 node를 mapping해야 됨. (network 상에서의 유사도와 encoding은 정의되어야됨.)\n",
    " - ex) $similarity(u,v) = z_v^Tz_u$ (u,v : nodes, $z_v,z_u$ : encoding 된 $u,v$)\n",
    " - Encoder : Map a node to a low-dim vector\n",
    " - similarity function : This define how relationshops in the input network map to relationships in the embedding space\n",
    "\n",
    "### Shallow Encoders\n",
    " - 데이터 변환이 한 layer로 구성되어 있다.\n",
    " - 한계점\n",
    "   - 추정 파라미터의 개수가 network의 점의 개수($O(|V|)$)와 같다.\n",
    "   - node사이의 parameter를 공유하지 않아 모든 node는 유일한 embedding을 가진다.\n",
    "   - Transductive: train 과정에서 보지못한 embedding을 만들수 없다.()\n",
    "   - node feature를 통합하지 못한다.\n",
    "\n",
    "### Deep Graph Encoders\n",
    " - $ENC(v)$ := multiple layers of non-linear transformations of graph structure (encoder)\n",
    " - 이러한 deep encoder들은 chapter7의 node similarity function과 결합가능하다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic of Deep Learning for Graphs\n",
    " - Content \n",
    "   - Local network neighborhoods\n",
    "      - Describe aggregation strategies \n",
    "      - Define computation graphs\n",
    "   - Stacking multiple layers\n",
    "      - Describe the model, parameters, training\n",
    "      - How to fit the model?\n",
    "      - Simple example for unsupervised and supervised training\n",
    " \n",
    " - V : vertex set , A : adjaceney matrix, $X \\in R^{m * |V|}$ : node feayures matrix \n",
    " ### Graph Convolutional Networks\n",
    "   - idea : Node's neighborhood defines a computation graph\n",
    "   - Learn how to propagate information across the graph to compute node features\n",
    "   - Aggregate Neighbors \n",
    "      - idea : 부분 네트워크 이웃들로부터 node embedding을 생성 (각 node마다 연결되어 있는 nodes의 정보를 받음)\n",
    "      - 방법 : 각 node는 서로 다른 신경망 구조를 가져 이것을 통해 이웃 노드들의 정보를 모음\n",
    "      - aggregation을 할때 합,평균등을 사용하면 node의 순서는 중요치 않다.\n",
    "<img src = './1.png' width = 40%>\n",
    "<img src = './2.png' width = 40%>\n",
    "   - training the model : need to define a loss function on the embeddings\n",
    " ### Model Design Overivew\n",
    "   - 1) Define a neighborhood aggregation function\n",
    "   - 2) Define a loss function on the embeddings\n",
    "   - 3) Train on a set of nodes, i.e, a batch of compute graphs\n",
    "   - 4) Generate embeddings for nodes as needed. Even for nodes we never trained on (parameters sheared)\n",
    "   \n",
    " ### Inductive Capability\n",
    "   - The same aggregation parameters are shared for all nodes: the number of model params is sublinear in |V| and we can generalize to unseen nodes\n",
    "   - 즉, 파라미터를 공유하므로 보지않은 노드도 generalize할수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolutional Networks and GraphSAGE\n",
    "  - GraphSAGE : Aggregation 한 것과 자기자신을 임베딩한것을 더하는 것이 아니라 concat한다.\n",
    "  - $h_v^k = act([W_k*AGG({h_u^{k-1},u \\in N(v)}), B_k * h_v^{k-1}])$ (AGG : Generalized aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Attention Networks (GAN)\n",
    "  - Goal : Specify arbitrary importances to different neighbors of each node in the graph\n",
    "  - idea : compute embedding $h_v^k$ of each node in the graph following an attention Strategy:\n",
    "      - Nodes attend over their neighborhoods message \n",
    "      - implicitly specifying different weights to different nodes in a neighborhood\n",
    "  ### Attention Mechanism(이해가 안간다.....)\n",
    "    - attention coefficients e(vu)를 통해서 node u,v사이의 정보 중요도를 계산\n",
    "    - e(vu) : u에서 v로 가는 메세지,정보의 중요도를 나타냄($e_{uv} = a(W_kh_u^{k-1},W_kh_v^{k-1})$)\n",
    "    - Normalize coefficients 를 이용해서 다른 이웃들간 정보량을 계산\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
