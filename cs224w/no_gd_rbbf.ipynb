{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c09a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class RBF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RBF, self).__init__()\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch.cuda.manual_seed(0)\n",
    "        self.cause_clt = self.init_clt()\n",
    "        self.cause_std = self.init_std()       \n",
    "        \n",
    "    def init_clt(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "\n",
    "    def init_std(self):\n",
    "        return nn.Parameter(torch.rand(1, device=device))\n",
    "    \n",
    "    def rbf(self, x, cluster, std):\n",
    "        return -(x - cluster) * (x - cluster) / 2 * (std * std)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        for i in range(t):\n",
    "            if i == 0:\n",
    "                a = self.rbf(i, self.cause_clt, self.cause_std)\n",
    "            else:\n",
    "                a = torch.cat([a, self.rbf(i, self.cause_clt, self.cause_std)], dim=0)\n",
    "                \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77cf7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def restore_parameters(model, best_model):\n",
    "    '''Move parameter values from best_model to model.'''\n",
    "    for params, best_params in zip(model.parameters(), best_model.parameters()):\n",
    "        params.data = best_params\n",
    "        \n",
    "def train_rbf(model, Y, lr, epochs, lookback=5,device = device):\n",
    "\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loss_list = []\n",
    "\n",
    "    best_it = None\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):        \n",
    "        # pred loss\n",
    "        pred = model(len(Y))\n",
    "        loss = sum([loss_fn(pred[i], Y[i]) for i in range(len(Y))])\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch {} loss {} :\".format(epoch, loss / len(Y)))\n",
    "            print(\"------------------------------------------------------\")\n",
    "            print()\n",
    "                      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        mean_loss = loss / len(Y)\n",
    "        train_loss_list.append(mean_loss)\n",
    "        \n",
    "        \n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_it = epoch\n",
    "            best_model = deepcopy(model)\n",
    "            \n",
    "        elif (epoch - best_it) == lookback:\n",
    "            if verbose:\n",
    "                print('Stopping early')\n",
    "            break\n",
    "\n",
    "    restore_parameters(model, best_model)\n",
    "\n",
    "    return train_loss_list , model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9735e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/chanyoung/Desktop/Neural-GC-master/lorenz_96_10_10_1000.csv')\n",
    "a = df['a'].values\n",
    "a = torch.tensor(a, device=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63601073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.3990], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9722], device='cuda:0', requires_grad=True)\n",
      "epoch 0 loss 44475576320.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 100 loss 29498050560.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 200 loss 19997001728.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 300 loss 13874695168.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 400 loss 9840637952.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 500 loss 7123165184.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 600 loss 5253264896.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 700 loss 3940527872.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 800 loss 3001554688.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 900 loss 2318248704.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1000 loss 1813043328.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1100 loss 1434048896.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1200 loss 1145923200.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1300 loss 924200000.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1400 loss 751662464.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1500 loss 616018880.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1600 loss 508376576.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1700 loss 422216160.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1800 loss 352701984.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1900 loss 296205248.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2000 loss 249979840.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2100 loss 211920848.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2200 loss 180404192.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2300 loss 154164864.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2400 loss 132210328.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2500 loss 113755880.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2600 loss 98176232.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2700 loss 84971168.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2800 loss 73736472.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2900 loss 64144616.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3000 loss 55928492.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3100 loss 48869220.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3200 loss 42786412.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3300 loss 37530908.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3400 loss 32978576.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3500 loss 29026052.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3600 loss 25586578.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3700 loss 22587274.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3800 loss 19966644.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3900 loss 17672564.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4000 loss 15660844.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4100 loss 13893813.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4200 loss 12339255.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4300 loss 10969605.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4400 loss 9761184.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4500 loss 8693617.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4600 loss 7749312.5 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4700 loss 6913062.5 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4800 loss 6171673.5 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4900 loss 5513676.5 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5000 loss 4929132.5 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5100 loss 4409340.0 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5200 loss 3946718.5 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5300 loss 3534632.25 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5400 loss 3167267.5 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5500 loss 2839523.75 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5600 loss 2546915.75 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5700 loss 2285494.75 :\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 5800 loss 2051792.875 :\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0fefe0f86edc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_clt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_rbf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_clt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcause_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b86816d2aa74>\u001b[0m in \u001b[0;36mtrain_rbf\u001b[1;34m(model, Y, lr, epochs, lookback, device)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# pred loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b86816d2aa74>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# pred loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2928\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2929\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RBF()\n",
    "print(model.cause_clt)\n",
    "print(model.cause_std)\n",
    "loss, best_model = train_rbf(model, a, 0.001, 10000, device)\n",
    "print(best_model.cause_clt)\n",
    "print(best_model.cause_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb66c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "44475576320\n",
    "29498050560\n",
    "  132210328\n",
    "    2285494"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
