{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a409700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b283f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autokeras.keras_layers import ExpandLastDim\n",
    "from autokeras.keras_layers import CastToFloat32\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D, LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomTranslation, RandomFlip\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcb936",
   "metadata": {},
   "source": [
    "# Make Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d959d193",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculateWeight(tlx):\n",
    "    tlx_weight = {'Mental':[0], \n",
    "                  'Physical':[0], \n",
    "                  'Temporal':[0], \n",
    "                  'Effort':[0],\n",
    "                  'Performance':[0],\n",
    "                  'Frustration':[0],\n",
    "                  'Sum':[0]}\n",
    "    tlx_weight = pd.DataFrame(tlx_weight)\n",
    "    for i in range(len(tlx)):\n",
    "        score = [0,0,0,0,0,0,0]\n",
    "        for col1 in range(1,len(tlx.columns)):\n",
    "            for col2 in range(col1+1, len(tlx.columns)):\n",
    "                if tlx[tlx.columns[col1]][i] > tlx[tlx.columns[col2]][i]:\n",
    "                    score[col1-1]+=1\n",
    "                elif tlx[tlx.columns[col1]][i] < tlx[tlx.columns[col2]][i]:\n",
    "                    score[col2-1]+=1\n",
    "                else :\n",
    "                    score[col1-1]+=0.5\n",
    "                    score[col2-1]+=0.5\n",
    "                    \n",
    "        score[6] = score[0]+score[1]+score[2]+score[3]+score[4]+score[5]\n",
    "        tlx_weight.loc[i]=score\n",
    "    #print(tlx_weight.loc[0])\n",
    "    return tlx_weight\n",
    "\n",
    "def calculate_tlxLevel(tlx, tlx_weight):\n",
    "    result = {'Mental':[0], \n",
    "                  'Physical':[0], \n",
    "                  'Temporal':[0], \n",
    "                  'Effort':[0],\n",
    "                  'Performance':[0],\n",
    "                  'Frustration':[0],\n",
    "                  'Score':[0]}\n",
    "    result = pd.DataFrame(result)\n",
    "    for i in range(len(tlx)):\n",
    "        score = [0,0,0,0,0,0,0]\n",
    "        for col in range(len(tlx_weight.columns)-1):\n",
    "            score[col] = int(tlx[tlx.columns[col+1]].loc[i] * tlx_weight[tlx_weight.columns[col]].loc[i] )\n",
    "        score[6] =int((score[0]+score[1]+score[2]+score[3]+score[4]+score[5] )/ tlx_weight[tlx_weight.columns[6]].loc[i]/10 + 0.5)\n",
    "        if score[6]>10: score[6]=10\n",
    "        if score[6]<0: score[6]=0\n",
    "        result.loc[i]=score\n",
    "    return result['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60cdbc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_data(df, label, end):\n",
    "    col = ['EEG.AF3', 'EEG.F7', 'EEG.F3', 'EEG.FC5', 'EEG.T7',\n",
    "           'EEG.P7', 'EEG.O1', 'EEG.O2', 'EEG.P8', 'EEG.T8', 'EEG.FC6', 'EEG.F4',\n",
    "           'EEG.F8', 'EEG.AF4', 'MarkerValueInt']\n",
    "    col_rename = ['AF3', 'F7', 'F3', 'FC5', 'T7',\n",
    "           'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4',\n",
    "           'F8', 'AF4', 'vis_name']\n",
    "    data_extraction = df[col]\n",
    "    data_extraction.columns = col_rename\n",
    "    rest = data_extraction[data_extraction.vis_name == 0]\n",
    "    survey = data_extraction[data_extraction.vis_name == 100]\n",
    "    \n",
    "    vis = data_extraction[data_extraction.vis_name == 1].reset_index(drop=True)\n",
    "    vis['label'] = label[0]\n",
    "    vis.drop(['vis_name'], axis=1, inplace=True)\n",
    "    \n",
    "    for i in range(2,end):\n",
    "        df = data_extraction[data_extraction.vis_name == i].reset_index(drop=True)\n",
    "        df['label'] = label[i-1]\n",
    "        df.drop(['vis_name'], axis=1, inplace=True)\n",
    "        vis = pd.concat([vis,df], ignore_index=True, axis=0)\n",
    "    return rest, survey, vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7592e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fft_data(df, label, end):\n",
    "    col = ['POW.AF3.Theta', 'POW.AF3.Alpha',\n",
    "       'POW.AF3.BetaL', 'POW.AF3.BetaH', 'POW.AF3.Gamma', 'POW.F7.Theta',\n",
    "       'POW.F7.Alpha', 'POW.F7.BetaL', 'POW.F7.BetaH', 'POW.F7.Gamma',\n",
    "       'POW.F3.Theta', 'POW.F3.Alpha', 'POW.F3.BetaL', 'POW.F3.BetaH',\n",
    "       'POW.F3.Gamma', 'POW.FC5.Theta', 'POW.FC5.Alpha', 'POW.FC5.BetaL',\n",
    "       'POW.FC5.BetaH', 'POW.FC5.Gamma', 'POW.T7.Theta', 'POW.T7.Alpha',\n",
    "       'POW.T7.BetaL', 'POW.T7.BetaH', 'POW.T7.Gamma', 'POW.P7.Theta',\n",
    "       'POW.P7.Alpha', 'POW.P7.BetaL', 'POW.P7.BetaH', 'POW.P7.Gamma',\n",
    "       'POW.O1.Theta', 'POW.O1.Alpha', 'POW.O1.BetaL', 'POW.O1.BetaH',\n",
    "       'POW.O1.Gamma', 'POW.O2.Theta', 'POW.O2.Alpha', 'POW.O2.BetaL',\n",
    "       'POW.O2.BetaH', 'POW.O2.Gamma', 'POW.P8.Theta', 'POW.P8.Alpha',\n",
    "       'POW.P8.BetaL', 'POW.P8.BetaH', 'POW.P8.Gamma', 'POW.T8.Theta',\n",
    "       'POW.T8.Alpha', 'POW.T8.BetaL', 'POW.T8.BetaH', 'POW.T8.Gamma',\n",
    "       'POW.FC6.Theta', 'POW.FC6.Alpha', 'POW.FC6.BetaL', 'POW.FC6.BetaH',\n",
    "       'POW.FC6.Gamma', 'POW.F4.Theta', 'POW.F4.Alpha', 'POW.F4.BetaL',\n",
    "       'POW.F4.BetaH', 'POW.F4.Gamma', 'POW.F8.Theta', 'POW.F8.Alpha',\n",
    "       'POW.F8.BetaL', 'POW.F8.BetaH', 'POW.F8.Gamma', 'POW.AF4.Theta',\n",
    "       'POW.AF4.Alpha', 'POW.AF4.BetaL', 'POW.AF4.BetaH', 'POW.AF4.Gamma', 'MarkerValueInt']\n",
    "    col_rename = ['AF3.Theta', 'AF3.Alpha','AF3.BetaL', 'AF3.BetaH', 'AF3.Gamma', \n",
    "                  'F7.Theta','F7.Alpha', 'F7.BetaL', 'F7.BetaH', 'F7.Gamma',\n",
    "                  'F3.Theta', 'F3.Alpha', 'F3.BetaL', 'F3.BetaH','F3.Gamma', \n",
    "                  'FC5.Theta', 'FC5.Alpha', 'FC5.BetaL','FC5.BetaH', 'FC5.Gamma', \n",
    "                  'T7.Theta', 'T7.Alpha', 'T7.BetaL', 'T7.BetaH', 'T7.Gamma', \n",
    "                  'P7.Theta', 'P7.Alpha', 'P7.BetaL', 'P7.BetaH', 'P7.Gamma',\n",
    "                  'O1.Theta', 'O1.Alpha', 'O1.BetaL', 'O1.BetaH','O1.Gamma',\n",
    "                  'O2.Theta', 'O2.Alpha', 'O2.BetaL','O2.BetaH', 'O2.Gamma',\n",
    "                  'P8.Theta', 'P8.Alpha', 'P8.BetaL', 'P8.BetaH', 'P8.Gamma', \n",
    "                  'T8.Theta','T8.Alpha', 'T8.BetaL', 'T8.BetaH', 'T8.Gamma',\n",
    "                  'FC6.Theta', 'FC6.Alpha', 'FC6.BetaL', 'FC6.BetaH','FC6.Gamma', \n",
    "                  'F4.Theta', 'F4.Alpha', 'F4.BetaL','F4.BetaH', 'F4.Gamma',\n",
    "                  'F8.Theta', 'F8.Alpha','F8.BetaL', 'F8.BetaH', 'F8.Gamma',\n",
    "                  'AF4.Theta', 'AF4.Alpha', 'AF4.BetaL', 'AF4.BetaH', 'AF4.Gamma', 'vis_name']\n",
    "    data_extraction = df[col]\n",
    "    data_extraction.columns = col_rename\n",
    "    rest = data_extraction[data_extraction.vis_name == 0].dropna(axis=0)\n",
    "    survey = data_extraction[data_extraction.vis_name == 100].dropna(axis=0)\n",
    "    \n",
    "    vis = data_extraction[data_extraction.vis_name == 1].reset_index(drop=True).dropna(axis=0)\n",
    "    vis['label'] = label[0]\n",
    "    vis.drop(['vis_name'], axis=1, inplace=True)\n",
    "    \n",
    "    for i in range(2,end):\n",
    "        df = data_extraction[data_extraction.vis_name == i].reset_index(drop=True)\n",
    "        df['label'] = label[i-1]\n",
    "        df.drop(['vis_name'], axis=1, inplace=True)\n",
    "        df = df.dropna(axis=0)\n",
    "        vis = pd.concat([vis,df], ignore_index=True, axis=0)\n",
    "    return rest, survey, vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_theta_alpha(df, labe, end):\n",
    "    col = ['POW.AF3.Theta', 'POW.AF3.Alpha', 'POW.F7.Theta', 'POW.F7.Alpha', \n",
    "           'POW.F3.Theta', 'POW.F3.Alpha', 'POW.FC5.Theta', 'POW.FC5.Alpha', \n",
    "           'POW.T7.Theta', 'POW.T7.Alpha', 'POW.P7.Theta', 'POW.P7.Alpha',\n",
    "           'POW.O1.Theta', 'POW.O1.Alpha', 'POW.O2.Theta', 'POW.O2.Alpha', \n",
    "           'POW.P8.Theta', 'POW.P8.Alpha', 'POW.T8.Theta', 'POW.T8.Alpha',\n",
    "           'POW.FC6.Theta', 'POW.FC6.Alpha',  'POW.F4.Theta', 'POW.F4.Alpha', \n",
    "           'POW.F8.Theta', 'POW.F8.Alpha','POW.AF4.Theta', 'POW.AF4.Alpha','MarkerValueInt']\n",
    "    col_rename = ['AF3.Theta', 'AF3.Alpha', 'F7.Theta','F7.Alpha', \n",
    "                  'F3.Theta', 'F3.Alpha', 'FC5.Theta', 'FC5.Alpha', \n",
    "                  'T7.Theta', 'T7.Alpha', 'P7.Theta', 'P7.Alpha', \n",
    "                  'O1.Theta', 'O1.Alpha', 'O2.Theta', 'O2.Alpha',\n",
    "                  'P8.Theta', 'P8.Alpha', 'T8.Theta','T8.Alpha',\n",
    "                  'FC6.Theta', 'FC6.Alpha', 'F4.Theta', 'F4.Alpha', \n",
    "                  'F8.Theta', 'F8.Alpha', 'AF4.Theta', 'AF4.Alpha','vis_name']\n",
    "    col2 = ['AF3', , 'F7','F3', 'FC5', 'T7', 'P7', 'O1', 'O2',\n",
    "            'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4','vis_name']\n",
    "\n",
    "def split_theta_alpha_data(df, label, end):\n",
    "    col = ['POW.AF3.Theta', 'POW.AF3.Alpha', 'POW.F7.Theta', 'POW.F7.Alpha', \n",
    "           'POW.F3.Theta', 'POW.F3.Alpha', 'POW.FC5.Theta', 'POW.FC5.Alpha', \n",
    "           'POW.T7.Theta', 'POW.T7.Alpha', 'POW.P7.Theta', 'POW.P7.Alpha',\n",
    "           'POW.O1.Theta', 'POW.O1.Alpha', 'POW.O2.Theta', 'POW.O2.Alpha', \n",
    "           'POW.P8.Theta', 'POW.P8.Alpha', 'POW.T8.Theta', 'POW.T8.Alpha',\n",
    "           'POW.FC6.Theta', 'POW.FC6.Alpha',  'POW.F4.Theta', 'POW.F4.Alpha', \n",
    "           'POW.F8.Theta', 'POW.F8.Alpha','POW.AF4.Theta', 'POW.AF4.Alpha','MarkerValueInt']\n",
    "    col_rename = ['AF3.Theta', 'AF3.Alpha', 'F7.Theta','F7.Alpha', \n",
    "                  'F3.Theta', 'F3.Alpha', 'FC5.Theta', 'FC5.Alpha', \n",
    "                  'T7.Theta', 'T7.Alpha', 'P7.Theta', 'P7.Alpha', \n",
    "                  'O1.Theta', 'O1.Alpha', 'O2.Theta', 'O2.Alpha',\n",
    "                  'P8.Theta', 'P8.Alpha', 'T8.Theta','T8.Alpha',\n",
    "                  'FC6.Theta', 'FC6.Alpha', 'F4.Theta', 'F4.Alpha', \n",
    "                  'F8.Theta', 'F8.Alpha', 'AF4.Theta', 'AF4.Alpha','vis_name']\n",
    "    col2 = ['AF3', , 'F7','F3', 'FC5', 'T7', 'P7', 'O1', 'O2',\n",
    "            'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4','vis_name']\n",
    "    data_extraction = df[col]\n",
    "    data_extraction.columns = col_rename\n",
    "    rest = data_extraction[data_extraction.vis_name == 0].dropna(axis=0)\n",
    "    survey = data_extraction[data_extraction.vis_name == 100].dropna(axis=0)\n",
    "    \n",
    "    vis = data_extraction[data_extraction.vis_name == 1].reset_index(drop=True).dropna(axis=0)\n",
    "    vis['label'] = label[0]\n",
    "    vis.drop(['vis_name'], axis=1, inplace=True)\n",
    "    \n",
    "    for i in range(2,end):\n",
    "        df = data_extraction[data_extraction.vis_name == i].reset_index(drop=True)\n",
    "        df['label'] = label[i-1]\n",
    "        df.drop(['vis_name'], axis=1, inplace=True)\n",
    "        df = df.dropna(axis=0)\n",
    "        vis = pd.concat([vis,df], ignore_index=True, axis=0)\n",
    "    return rest, survey, vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83195eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'EEG data/User/'\n",
    "files = os.listdir(src)\n",
    "tlx=[]\n",
    "for f in files:\n",
    "    tlx.append(pd.read_csv(src+f))\n",
    "src = 'EEG data/prepross/'\n",
    "datas = os.listdir(src)\n",
    "workloadLevel = []\n",
    "for t in tlx:\n",
    "    workloadLevel.append(calculate_tlxLevel(t, calculateWeight(t)))\n",
    "eegData=[]\n",
    "for d in datas:\n",
    "    eegData.append(pd.read_csv(src+d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4f62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for eeg, label in zip (eegData, workloadLevel):\n",
    "    if cnt == 0 :\n",
    "        rest, survey, vis = split_data(eeg, label,21)\n",
    "        cnt+=1\n",
    "        continue\n",
    "    elif cnt == 6:\n",
    "        r, s, v = split_data(eeg, label,21)\n",
    "    else:\n",
    "        r, s, v = split_data(eeg, label, 22)\n",
    "    \n",
    "    rest = pd.concat([rest,r], ignore_index=True, axis=0)\n",
    "    survey = pd.concat([survey,s], ignore_index=True, axis=0)\n",
    "    vis = pd.concat([vis,v], ignore_index=True, axis=0)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ea3bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for eeg, label in zip (eegData, workloadLevel):\n",
    "    if cnt == 0 :\n",
    "        rest_fft, survey_fft, vis_fft = split_fft_data(eeg, label,21)\n",
    "        cnt+=1\n",
    "        continue\n",
    "    elif cnt == 6:\n",
    "        r_fft, s_fft, v_fft = split_fft_data(eeg, label,21)\n",
    "    else:\n",
    "        r_fft, s_fft, v_fft = split_fft_data(eeg, label, 22)\n",
    "    \n",
    "    rest_fft = pd.concat([rest_fft,r_fft], ignore_index=True, axis=0)\n",
    "    survey_fft = pd.concat([survey_fft,s_fft], ignore_index=True, axis=0)\n",
    "    vis_fft = pd.concat([vis_fft,v_fft], ignore_index=True, axis=0)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "622252ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3.Theta</th>\n",
       "      <th>AF3.Alpha</th>\n",
       "      <th>AF3.BetaL</th>\n",
       "      <th>AF3.BetaH</th>\n",
       "      <th>AF3.Gamma</th>\n",
       "      <th>F7.Theta</th>\n",
       "      <th>F7.Alpha</th>\n",
       "      <th>F7.BetaL</th>\n",
       "      <th>F7.BetaH</th>\n",
       "      <th>F7.Gamma</th>\n",
       "      <th>...</th>\n",
       "      <th>F8.Alpha</th>\n",
       "      <th>F8.BetaL</th>\n",
       "      <th>F8.BetaH</th>\n",
       "      <th>F8.Gamma</th>\n",
       "      <th>AF4.Theta</th>\n",
       "      <th>AF4.Alpha</th>\n",
       "      <th>AF4.BetaL</th>\n",
       "      <th>AF4.BetaH</th>\n",
       "      <th>AF4.Gamma</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.173274</td>\n",
       "      <td>3.106601</td>\n",
       "      <td>1.099620</td>\n",
       "      <td>1.028382</td>\n",
       "      <td>0.398435</td>\n",
       "      <td>13.847454</td>\n",
       "      <td>4.459079</td>\n",
       "      <td>2.059237</td>\n",
       "      <td>1.885073</td>\n",
       "      <td>0.794723</td>\n",
       "      <td>...</td>\n",
       "      <td>2.298744</td>\n",
       "      <td>1.411010</td>\n",
       "      <td>0.934551</td>\n",
       "      <td>0.511227</td>\n",
       "      <td>7.413913</td>\n",
       "      <td>2.932344</td>\n",
       "      <td>1.782573</td>\n",
       "      <td>1.104984</td>\n",
       "      <td>0.438779</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.970263</td>\n",
       "      <td>3.286717</td>\n",
       "      <td>0.980125</td>\n",
       "      <td>1.106689</td>\n",
       "      <td>0.399811</td>\n",
       "      <td>15.437139</td>\n",
       "      <td>5.031683</td>\n",
       "      <td>2.356469</td>\n",
       "      <td>2.520724</td>\n",
       "      <td>0.832195</td>\n",
       "      <td>...</td>\n",
       "      <td>2.435528</td>\n",
       "      <td>1.795794</td>\n",
       "      <td>1.151114</td>\n",
       "      <td>0.529097</td>\n",
       "      <td>8.105520</td>\n",
       "      <td>3.309745</td>\n",
       "      <td>2.431626</td>\n",
       "      <td>1.475698</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.896807</td>\n",
       "      <td>3.438130</td>\n",
       "      <td>0.962297</td>\n",
       "      <td>1.164912</td>\n",
       "      <td>0.420656</td>\n",
       "      <td>15.781597</td>\n",
       "      <td>5.461060</td>\n",
       "      <td>2.844015</td>\n",
       "      <td>3.333000</td>\n",
       "      <td>0.904789</td>\n",
       "      <td>...</td>\n",
       "      <td>2.668025</td>\n",
       "      <td>2.300908</td>\n",
       "      <td>1.370913</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>8.082989</td>\n",
       "      <td>3.821387</td>\n",
       "      <td>3.237942</td>\n",
       "      <td>1.950380</td>\n",
       "      <td>0.566002</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.761883</td>\n",
       "      <td>3.459307</td>\n",
       "      <td>1.037847</td>\n",
       "      <td>1.206656</td>\n",
       "      <td>0.465319</td>\n",
       "      <td>15.123814</td>\n",
       "      <td>5.583092</td>\n",
       "      <td>3.381478</td>\n",
       "      <td>4.166084</td>\n",
       "      <td>1.007141</td>\n",
       "      <td>...</td>\n",
       "      <td>2.909856</td>\n",
       "      <td>2.793795</td>\n",
       "      <td>1.569230</td>\n",
       "      <td>0.599309</td>\n",
       "      <td>7.542512</td>\n",
       "      <td>4.307007</td>\n",
       "      <td>3.964213</td>\n",
       "      <td>2.427696</td>\n",
       "      <td>0.656156</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.779994</td>\n",
       "      <td>3.326084</td>\n",
       "      <td>1.178284</td>\n",
       "      <td>1.237358</td>\n",
       "      <td>0.524978</td>\n",
       "      <td>13.572821</td>\n",
       "      <td>5.360179</td>\n",
       "      <td>3.808501</td>\n",
       "      <td>4.792826</td>\n",
       "      <td>1.111347</td>\n",
       "      <td>...</td>\n",
       "      <td>3.096153</td>\n",
       "      <td>3.122208</td>\n",
       "      <td>1.724803</td>\n",
       "      <td>0.639429</td>\n",
       "      <td>6.603131</td>\n",
       "      <td>4.609829</td>\n",
       "      <td>4.365841</td>\n",
       "      <td>2.768109</td>\n",
       "      <td>0.730073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108207</th>\n",
       "      <td>16.052397</td>\n",
       "      <td>4.474069</td>\n",
       "      <td>0.948681</td>\n",
       "      <td>0.759617</td>\n",
       "      <td>0.474118</td>\n",
       "      <td>10.951871</td>\n",
       "      <td>2.513503</td>\n",
       "      <td>0.433273</td>\n",
       "      <td>0.292269</td>\n",
       "      <td>0.184488</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237617</td>\n",
       "      <td>0.881767</td>\n",
       "      <td>0.169846</td>\n",
       "      <td>0.135366</td>\n",
       "      <td>15.739989</td>\n",
       "      <td>3.450108</td>\n",
       "      <td>1.418323</td>\n",
       "      <td>0.448079</td>\n",
       "      <td>0.483714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108208</th>\n",
       "      <td>19.973568</td>\n",
       "      <td>5.400219</td>\n",
       "      <td>0.879941</td>\n",
       "      <td>0.789202</td>\n",
       "      <td>0.493196</td>\n",
       "      <td>12.166910</td>\n",
       "      <td>2.480561</td>\n",
       "      <td>0.431624</td>\n",
       "      <td>0.281479</td>\n",
       "      <td>0.176217</td>\n",
       "      <td>...</td>\n",
       "      <td>2.060185</td>\n",
       "      <td>0.678499</td>\n",
       "      <td>0.163792</td>\n",
       "      <td>0.132977</td>\n",
       "      <td>18.980492</td>\n",
       "      <td>3.998825</td>\n",
       "      <td>1.359801</td>\n",
       "      <td>0.512423</td>\n",
       "      <td>0.443753</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108209</th>\n",
       "      <td>21.391216</td>\n",
       "      <td>5.843330</td>\n",
       "      <td>0.768417</td>\n",
       "      <td>0.776957</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>12.406390</td>\n",
       "      <td>2.315039</td>\n",
       "      <td>0.425017</td>\n",
       "      <td>0.273872</td>\n",
       "      <td>0.173656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.845860</td>\n",
       "      <td>0.476338</td>\n",
       "      <td>0.166581</td>\n",
       "      <td>0.139204</td>\n",
       "      <td>20.895807</td>\n",
       "      <td>4.281593</td>\n",
       "      <td>1.181604</td>\n",
       "      <td>0.586123</td>\n",
       "      <td>0.418840</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108210</th>\n",
       "      <td>19.844902</td>\n",
       "      <td>5.645937</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.721887</td>\n",
       "      <td>0.486074</td>\n",
       "      <td>12.232596</td>\n",
       "      <td>2.089117</td>\n",
       "      <td>0.438556</td>\n",
       "      <td>0.281801</td>\n",
       "      <td>0.183639</td>\n",
       "      <td>...</td>\n",
       "      <td>1.706487</td>\n",
       "      <td>0.343786</td>\n",
       "      <td>0.178487</td>\n",
       "      <td>0.154436</td>\n",
       "      <td>20.853188</td>\n",
       "      <td>4.226102</td>\n",
       "      <td>0.942141</td>\n",
       "      <td>0.645811</td>\n",
       "      <td>0.403860</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108211</th>\n",
       "      <td>15.749766</td>\n",
       "      <td>4.836632</td>\n",
       "      <td>0.578267</td>\n",
       "      <td>0.636996</td>\n",
       "      <td>0.461965</td>\n",
       "      <td>12.462680</td>\n",
       "      <td>1.857309</td>\n",
       "      <td>0.482037</td>\n",
       "      <td>0.311765</td>\n",
       "      <td>0.206080</td>\n",
       "      <td>...</td>\n",
       "      <td>1.704823</td>\n",
       "      <td>0.308621</td>\n",
       "      <td>0.195303</td>\n",
       "      <td>0.175078</td>\n",
       "      <td>19.219271</td>\n",
       "      <td>3.859261</td>\n",
       "      <td>0.714809</td>\n",
       "      <td>0.668913</td>\n",
       "      <td>0.387667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108212 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AF3.Theta  AF3.Alpha  AF3.BetaL  AF3.BetaH  AF3.Gamma   F7.Theta  \\\n",
       "0        9.173274   3.106601   1.099620   1.028382   0.398435  13.847454   \n",
       "1       10.970263   3.286717   0.980125   1.106689   0.399811  15.437139   \n",
       "2       11.896807   3.438130   0.962297   1.164912   0.420656  15.781597   \n",
       "3       11.761883   3.459307   1.037847   1.206656   0.465319  15.123814   \n",
       "4       10.779994   3.326084   1.178284   1.237358   0.524978  13.572821   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "108207  16.052397   4.474069   0.948681   0.759617   0.474118  10.951871   \n",
       "108208  19.973568   5.400219   0.879941   0.789202   0.493196  12.166910   \n",
       "108209  21.391216   5.843330   0.768417   0.776957   0.497462  12.406390   \n",
       "108210  19.844902   5.645937   0.656863   0.721887   0.486074  12.232596   \n",
       "108211  15.749766   4.836632   0.578267   0.636996   0.461965  12.462680   \n",
       "\n",
       "        F7.Alpha  F7.BetaL  F7.BetaH  F7.Gamma  ...  F8.Alpha  F8.BetaL  \\\n",
       "0       4.459079  2.059237  1.885073  0.794723  ...  2.298744  1.411010   \n",
       "1       5.031683  2.356469  2.520724  0.832195  ...  2.435528  1.795794   \n",
       "2       5.461060  2.844015  3.333000  0.904789  ...  2.668025  2.300908   \n",
       "3       5.583092  3.381478  4.166084  1.007141  ...  2.909856  2.793795   \n",
       "4       5.360179  3.808501  4.792826  1.111347  ...  3.096153  3.122208   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "108207  2.513503  0.433273  0.292269  0.184488  ...  2.237617  0.881767   \n",
       "108208  2.480561  0.431624  0.281479  0.176217  ...  2.060185  0.678499   \n",
       "108209  2.315039  0.425017  0.273872  0.173656  ...  1.845860  0.476338   \n",
       "108210  2.089117  0.438556  0.281801  0.183639  ...  1.706487  0.343786   \n",
       "108211  1.857309  0.482037  0.311765  0.206080  ...  1.704823  0.308621   \n",
       "\n",
       "        F8.BetaH  F8.Gamma  AF4.Theta  AF4.Alpha  AF4.BetaL  AF4.BetaH  \\\n",
       "0       0.934551  0.511227   7.413913   2.932344   1.782573   1.104984   \n",
       "1       1.151114  0.529097   8.105520   3.309745   2.431626   1.475698   \n",
       "2       1.370913  0.558700   8.082989   3.821387   3.237942   1.950380   \n",
       "3       1.569230  0.599309   7.542512   4.307007   3.964213   2.427696   \n",
       "4       1.724803  0.639429   6.603131   4.609829   4.365841   2.768109   \n",
       "...          ...       ...        ...        ...        ...        ...   \n",
       "108207  0.169846  0.135366  15.739989   3.450108   1.418323   0.448079   \n",
       "108208  0.163792  0.132977  18.980492   3.998825   1.359801   0.512423   \n",
       "108209  0.166581  0.139204  20.895807   4.281593   1.181604   0.586123   \n",
       "108210  0.178487  0.154436  20.853188   4.226102   0.942141   0.645811   \n",
       "108211  0.195303  0.175078  19.219271   3.859261   0.714809   0.668913   \n",
       "\n",
       "        AF4.Gamma  label  \n",
       "0        0.438779      6  \n",
       "1        0.488555      6  \n",
       "2        0.566002      6  \n",
       "3        0.656156      6  \n",
       "4        0.730073      6  \n",
       "...           ...    ...  \n",
       "108207   0.483714      5  \n",
       "108208   0.443753      5  \n",
       "108209   0.418840      5  \n",
       "108210   0.403860      5  \n",
       "108211   0.387667      5  \n",
       "\n",
       "[108212 rows x 71 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baaa88c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1731369, 11)\n"
     ]
    }
   ],
   "source": [
    "label=vis['label']\n",
    "label = to_categorical(label,11)\n",
    "data=vis.drop(['label'],axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(scaled, columns = data.columns, index=data.index)\n",
    "data\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15acd8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108212, 70) (108212, 11)\n"
     ]
    }
   ],
   "source": [
    "label_fft=vis_fft['label']\n",
    "label_fft = to_categorical(label_fft,11)\n",
    "data_fft=vis_fft.drop(['label'],axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data_fft)\n",
    "data_fft = pd.DataFrame(scaled, columns = data_fft.columns, index=data_fft.index)\n",
    "data_fft\n",
    "print(data_fft.shape, label_fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e13c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing_dataset(data, label, window_size):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(0,len(data)//window_size):\n",
    "        data_list.append(np.array(data.iloc[i*window_size:(i+1)*window_size]))\n",
    "        label_list.append(np.array(label.iloc[i*window_size]))\n",
    "    return np.array(data_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38cb9187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 70, 70) (10, 70, 70) (13, 11) (10, 11)\n"
     ]
    }
   ],
   "source": [
    "x, y = windowing_dataset(data,pd.DataFrame(label),10)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.6, \n",
    "                                                    random_state=True,\n",
    "                                                    stratify = y)\n",
    "\n",
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec0f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def drawResult(history):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "\n",
    "    acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "    acc_ax.set_ylabel('accuracy')\n",
    "    acc_ax.legend(loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def runModel(model, crossentropy, x_train, y_train, x_valid, y_valid):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    model.compile(optimizer='adam', loss= crossentropy, metrics='accuracy')\n",
    "\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        epochs = 200, \n",
    "                        validation_data = (x_valid, y_valid), \n",
    "                        callbacks=[early_stop], verbose=1)\n",
    "    drawResult(history)\n",
    "    return model\n",
    "\n",
    "def eval_model(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    return f1_score(y_test.argmax(axis=1), y_pred.argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c9e6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model2_2_1():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_2_2():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_2_3():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "crossentropy = 'categorical_crossentropy'\n",
    "\n",
    "print(eval_model(runModel(Model2_2_1(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_2_2(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_2_3(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a10617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model2_1_1():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_1_2():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(2,2), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def Model2_1_3():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(14, 14)))\n",
    "    model.add(ExpandLastDim())\n",
    "    model.add(CastToFloat32())\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(1,1), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(4,4), strides=(1,1), activation='relu', padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "crossentropy = 'categorical_crossentropy'\n",
    "\n",
    "print(eval_model(runModel(Model2_1_1(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_1_2(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))\n",
    "print(eval_model(runModel(Model2_1_3(),crossentropy,\n",
    "                          x_train, y_train, x_valid, y_valid), x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf544e8",
   "metadata": {},
   "source": [
    "# AUTO KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3994b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c2919af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10821, 10, 70) (10821, 11)\n",
      "(6492, 10, 70) (4329, 10, 70) (6492, 11) (4329, 11)\n"
     ]
    }
   ],
   "source": [
    "x_fft, y_fft = windowing_dataset(data_fft,pd.DataFrame(label_fft),10)\n",
    "print(x_fft.shape, y_fft.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_fft,y_fft, train_size=0.6, \n",
    "                                                    random_state=True,\n",
    "                                                    stratify = y_fft)\n",
    "\n",
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66ddc034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 12m 36s]\n",
      "val_loss: 1.878928780555725\n",
      "\n",
      "Best val_loss So Far: 1.2487961053848267\n",
      "Total elapsed time: 00h 12m 55s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "image_block_1/b...|efficient         |vanilla           \n",
      "image_block_1/n...|True              |True              \n",
      "image_block_1/a...|True              |False             \n",
      "image_block_1/i...|True              |None              \n",
      "image_block_1/i...|False             |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0.1               |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/e...|True              |None              \n",
      "image_block_1/e...|b7                |None              \n",
      "image_block_1/e...|True              |None              \n",
      "image_block_1/e...|True              |None              \n",
      "classification_...|global_avg        |flatten           \n",
      "classification_...|0                 |0.5               \n",
      "optimizer         |adam              |adam              \n",
      "learning_rate     |2e-05             |0.001             \n",
      "\n",
      "Epoch 1/20\n",
      "Not enough memory, reduce batch size to 16.\n",
      "Epoch 1/20\n",
      "Not enough memory, reduce batch size to 8.\n",
      "Epoch 1/20\n",
      "Not enough memory, reduce batch size to 4.\n",
      "Epoch 1/20\n",
      "   1304/Unknown - 540s 414ms/step - loss: 1.8697 - accuracy: 0.3020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1404/854107226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mclf_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mak\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclf_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpredicted_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\autokeras\\tasks\\image.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         )\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\autokeras\\auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         )\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\autokeras\\engine\\tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         super().search(\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         )\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\autokeras\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         _, history = utils.fit_with_adaptive_batch_size(\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         )\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\autokeras\\utils\\utils.py\u001b[0m in \u001b[0;36mfit_with_adaptive_batch_size\u001b[1;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     history = run_with_adaptive_batch_size(\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\autokeras\\utils\\utils.py\u001b[0m in \u001b[0;36mrun_with_adaptive_batch_size\u001b[1;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResourceExhaustedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\autokeras\\utils\\utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     history = run_with_adaptive_batch_size(\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[0;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials=[3,5,10,20]\n",
    "for trial in trials:\n",
    "    clf_ = ak.ImageClassifier(overwrite=True, max_trials=trial)\n",
    "    clf_.fit(x=x_train, y=y_train, epochs=20)\n",
    "\n",
    "    predicted_y = clf_.predict(x_test)\n",
    "    print(predicted_y)\n",
    "    loss, acc = clf_.evaluate(x_test, y_test)\n",
    "    print(clf_.evaluate(x_test, y_test))\n",
    "    print('Loss: %.3f   Accuracy: %.3f' % (loss,acc))\n",
    "\n",
    "    model = clf_.export_model()\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True)\n",
    "    tmp = int(acc*100)\n",
    "    print(tmp)\n",
    "    model.save('model/'+'_ACC_'+str(tmp)+'_try_'+str(trial)+'_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fb8fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64927, 70) (43285, 70) (64927, 11) (43285, 11)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_fft,label_fft, train_size=0.6, \n",
    "                                                    random_state=True,\n",
    "                                                    stratify = label_fft)\n",
    "\n",
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63656540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AF3.Theta    float64\n",
       "AF3.Alpha    float64\n",
       "AF3.BetaL    float64\n",
       "AF3.BetaH    float64\n",
       "AF3.Gamma    float64\n",
       "              ...   \n",
       "AF4.Theta    float64\n",
       "AF4.Alpha    float64\n",
       "AF4.BetaL    float64\n",
       "AF4.BetaH    float64\n",
       "AF4.Gamma    float64\n",
       "Length: 70, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4f09afa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 07m 21s]\n",
      "val_accuracy: 0.6475808024406433\n",
      "\n",
      "Best val_accuracy So Far: 0.6685701012611389\n",
      "Total elapsed time: 01h 05m 40s\n",
      "Epoch 1/20\n",
      "2029/2029 [==============================] - 20s 9ms/step - loss: 1.4216 - accuracy: 0.4397\n",
      "Epoch 2/20\n",
      "2029/2029 [==============================] - 20s 10ms/step - loss: 1.1745 - accuracy: 0.5235\n",
      "Epoch 3/20\n",
      "2029/2029 [==============================] - 21s 10ms/step - loss: 1.0810 - accuracy: 0.5576\n",
      "Epoch 4/20\n",
      "2029/2029 [==============================] - 19s 10ms/step - loss: 1.0199 - accuracy: 0.5834\n",
      "Epoch 5/20\n",
      "2029/2029 [==============================] - 19s 10ms/step - loss: 0.9674 - accuracy: 0.6051\n",
      "Epoch 6/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.9239 - accuracy: 0.6230\n",
      "Epoch 7/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.8881 - accuracy: 0.6388\n",
      "Epoch 8/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.8551 - accuracy: 0.6534\n",
      "Epoch 9/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.8281 - accuracy: 0.6648\n",
      "Epoch 10/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.7983 - accuracy: 0.6775\n",
      "Epoch 11/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.7759 - accuracy: 0.6875\n",
      "Epoch 12/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.7511 - accuracy: 0.6974\n",
      "Epoch 13/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.7298 - accuracy: 0.7059\n",
      "Epoch 14/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.7071 - accuracy: 0.7161\n",
      "Epoch 15/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.6978 - accuracy: 0.7225\n",
      "Epoch 16/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.6751 - accuracy: 0.7295\n",
      "Epoch 17/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.6614 - accuracy: 0.7369\n",
      "Epoch 18/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.6437 - accuracy: 0.7420\n",
      "Epoch 19/20\n",
      "2029/2029 [==============================] - 19s 9ms/step - loss: 0.6286 - accuracy: 0.7481\n",
      "Epoch 20/20\n",
      "2029/2029 [==============================] - 20s 10ms/step - loss: 0.6134 - accuracy: 0.7545\n",
      "1353/1353 [==============================] - 10s 8ms/step\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "1353/1353 [==============================] - 13s 9ms/step - loss: 0.8530 - accuracy: 0.6918\n",
      "1353/1353 [==============================] - 14s 9ms/step - loss: 0.8530 - accuracy: 0.6918\n",
      "[0.8529524803161621, 0.6917638778686523]\n",
      "Loss: 0.853   Accuracy: 0.692\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 70)]              0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 70)                141       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2272      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11)                363       \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Softm (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 36,088\n",
      "Trainable params: 35,947\n",
      "Non-trainable params: 141\n",
      "_________________________________________________________________\n",
      "69\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Got a model or layer MultiCategoryEncoding with weights [<tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B835B08>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x00000233794D7608>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x0000023391BEF308>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B6C50C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B6C5CC8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B58E8C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B60C6C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002329AEDD5C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002329AEDD288>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B621388>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x00000233A3367188>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B8AA6C8>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1404/1102726406.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'S_ACC_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_try_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2110\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2111\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 2112\u001b[1;33m                     signatures, options, save_traces)\n\u001b[0m\u001b[0;32m   2113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m   def save_weights(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    145\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    146\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 147\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    148\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mmodel_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    634\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[0mweight_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36m_legacy_weights\u001b[1;34m(layer)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;34m'Save or restore weights that is not an instance of `tf.Variable` is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[1;34m'not supported in h5, use `save_format=\\'tf\\'` instead. Got a model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         'or layer {} with weights {}'.format(layer.__class__.__name__, weights))\n\u001b[0m\u001b[0;32m    899\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Got a model or layer MultiCategoryEncoding with weights [<tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B835B08>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x00000233794D7608>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x0000023391BEF308>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B6C50C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B6C5CC8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B58E8C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B60C6C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002329AEDD5C8>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002329AEDD288>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B621388>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x00000233A3367188>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x000002337B8AA6C8>]"
     ]
    }
   ],
   "source": [
    "trials=[20]\n",
    "for trial in trials:\n",
    "    clf_ = ak.StructuredDataClassifier(overwrite=True, max_trials=trial)\n",
    "    clf_.fit(x=x_train, y=y_train, epochs=20)\n",
    "\n",
    "    predicted_y = clf_.predict(x_test)\n",
    "    print(predicted_y)\n",
    "    loss, acc = clf_.evaluate(x_test, y_test)\n",
    "    print(clf_.evaluate(x_test, y_test))\n",
    "    print('Loss: %.3f   Accuracy: %.3f' % (loss,acc))\n",
    "\n",
    "    model = clf_.export_model()\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True)\n",
    "    tmp = int(acc*100)\n",
    "    print(tmp)\n",
    "    model.save('model/'+'S_ACC_'+str(tmp)+'_try_'+str(trial),save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1df16348",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/'+'S_ACC_'+str(tmp)+'_try_'+str(trial),save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b2c5c",
   "metadata": {},
   "source": [
    "1D CNN? / windowing LSTM?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
