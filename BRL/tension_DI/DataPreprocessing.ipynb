{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "2400 800 800\n",
      "features (106, 3)\n",
      "(106, 106)\n",
      "Counter({0.0: 10866, 6100.0: 152, 7500.0: 82, 3000.0: 32, 62562.05078125: 16, 50520.1953125: 16, 38810.4375: 16, 27854.802734375: 16, 19005.525390625: 16, 9000.0: 16, 10000.0: 8})\n",
      "Counter({0.0: 10866, 97500.0: 152, 3848.45: 80, 8245.14480000001: 78, 147500.0: 60})\n",
      "Counter({97500.0: 76, 3848.45: 40, 8245.14480000001: 39, 147500.0: 30})\n",
      "76.0 40.0 39.0 30.0\n",
      "(185, 2) (185, 5)\n",
      "(4000, 185, 6)\n",
      "(2400, 185, 6) (800, 185, 6) (800, 185, 6)\n",
      "10 0 0.0 0.9999999999999999 0.1784306897538798 0.26140132420255613\n",
      "10 1 0.0 1.0 0.41081081081081083 0.49198098391276773\n",
      "10 2 0.0 1.0 0.21621621621621623 0.4116634111277789\n",
      "10 3 0.0 1.0 0.21081081081081082 0.4078843130792104\n",
      "10 4 0.0 1.0 0.16216216216216217 0.36859950532394203\n",
      "10 5 0.0 0.9968870836981987 0.028106870781757005 0.13030301320803117\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import collections\n",
    "from utils import get_cableidx\n",
    "###################\n",
    "n_f=10\n",
    "n_node=106\n",
    "N=4000\n",
    "#split\n",
    "np.random.seed(1)\n",
    "indices = np.random.permutation(N);print(indices[0])\n",
    "n_training=int(N*0.6)\n",
    "n_val=int(N*0.2)\n",
    "n_test=N-n_training-n_val\n",
    "print(n_training,n_val,n_test)\n",
    "training_idx, val_idx,test_idx = indices[:n_training], indices[n_training:n_training+n_val], indices[-n_test:]\n",
    "###################\n",
    "\n",
    "def get_label():\n",
    "    ##### label data\n",
    "    y=pd.read_csv('data/raw_data/area.csv')\n",
    "    label_area=y.values[1:,1:]\n",
    "    #split\n",
    "    l_training, l_val, l_test = label_area[training_idx],label_area[val_idx], label_area[test_idx]\n",
    "    print(l_training.shape,l_val.shape,l_test.shape)\n",
    "    #multi task\n",
    "    def getting_multi(label_data,sf,mode):\n",
    "        c_data=np.argmin(label_data,axis=1)\n",
    "        a_data=np.min(label_data,axis=1)\n",
    "        #c_data=c_data+1\n",
    "        #c_data[a_data>0.999]=0;print('safe',np.sum(c_data==0))\n",
    "        a_data=a_data[:,np.newaxis]\n",
    "\n",
    "        #bce_data = np.zeros((len(c_data), 121))\n",
    "        #bce_data[np.arange(len(c_data)),c_data] = 1\n",
    "\n",
    "        if sf:\n",
    "            np.savez_compressed('data/label_multitask/c_label_'+mode,c_data)\n",
    "            np.savez_compressed('data/label_multitask/a_label_'+mode,a_data)\n",
    "            #np.savez_compressed('data/label_multitask_bce/c_label_'+mode,bce_data)\n",
    "            #np.savez_compressed('data/label_multitask_bce/a_label_'+mode,a_data)\n",
    "        return c_data,a_data,_#,bce_data\n",
    "    #save\n",
    "    save_flag=False#True#\n",
    "    c_training,a_training,bce_training=getting_multi(l_training,sf=save_flag,mode='train')\n",
    "    c_val,a_val,bce_val=getting_multi(l_val,sf=save_flag,mode='val')\n",
    "    c_test,a_test,bce_test=getting_multi(l_test,sf=save_flag,mode='test')\n",
    "\n",
    "def get_mlpdata():\n",
    "    ##### MLP input\n",
    "    in_cable=np.array([1,4,9,11,16,21,24,29,31,36])-1\n",
    "    with open(\"data/efo_signal_list.pkl\", 'rb') as pickle_file:\n",
    "        tension = pickle.load(pickle_file)\n",
    "    tension=np.array(tension);print('whole tension',features.shape)\n",
    "    tension=tension[1:,-1,in_cable]\n",
    "    print('final tension',tension.shape)\n",
    "    #split\n",
    "    t_training, t_val, t_test = tension[training_idx],tension[val_idx], tension[test_idx]\n",
    "    print(t_training.shape,t_val.shape,t_test.shape)\n",
    "    #scaling\n",
    "    sc=MinMaxScaler()\n",
    "    t_training=sc.fit_transform(t_training)\n",
    "    t_val=sc.transform(t_val)\n",
    "    t_test=sc.transform(t_test)\n",
    "    #save\n",
    "    save_flag=False#True#\n",
    "    if save_flag:\n",
    "        data_path='data/data_mlp/'\n",
    "        np.savez_compressed(data_path+'t_train',t_training)\n",
    "        np.savez_compressed(data_path+'t_val',t_val)\n",
    "        np.savez_compressed(data_path+'t_test',t_test)\n",
    "\n",
    "##### GNN input\n",
    "#node featrues - node coordinates (3)\n",
    "node_loc=np.load('data/node_loc.npy')\n",
    "features=node_loc.copy()\n",
    "features=MinMaxScaler().fit_transform(features)\n",
    "print('features',features.shape)\n",
    "\n",
    "save_flag=True#False#\n",
    "if save_flag:\n",
    "    data_path='data/data_mpnn/'\n",
    "    np.savez_compressed(data_path+'f_train',features)\n",
    "\n",
    "#edge features - tension, distance, type (6)\n",
    "with open(\"data/sensor_graph/adj_mx.pkl\", 'rb') as pickle_file:\n",
    "    adj_mx = pickle.load(pickle_file)\n",
    "for i in range(106): adj_mx[i,i]=0\n",
    "print(adj_mx.shape)\n",
    "edge_data=[[i,j] for i,j in zip(np.where(adj_mx==1)[0],np.where(adj_mx==1)[1])];edge_data=np.array(edge_data)\n",
    "edge_data=edge_data[edge_data[:,0]<edge_data[:,1]]\n",
    "\n",
    "#distance\n",
    "with open(\"data/sensor_graph/adj_mx_type_e.pkl\", 'rb') as pickle_file:\n",
    "    edge_de = pickle.load(pickle_file)#sacled [distance, E]\n",
    "edge_d=edge_de[2][0]#;edge_e=edge_de[2][1]\n",
    "print(collections.Counter(edge_d.flatten()))\n",
    "for i in range(106): edge_d[i,i]=0\n",
    "\n",
    "#area\n",
    "with open(\"data/sensor_graph/adj_mx_type_a.pkl\", 'rb') as pickle_file:\n",
    "    edge_a = pickle.load(pickle_file)\n",
    "print(collections.Counter(edge_a.flatten()))\n",
    "for i in range(106): edge_a[i,i]=0\n",
    "\n",
    "#make inputs for graph & edge type\n",
    "edge_a=edge_a[edge_data[:,0],edge_data[:,1]]\n",
    "edge_d=edge_d[edge_data[:,0],edge_data[:,1]]\n",
    "print(collections.Counter(edge_a.flatten()))\n",
    "edge_type1=(edge_a==97500.0).astype('float64')\n",
    "edge_type2=(edge_a==3848.45).astype('float64')\n",
    "edge_type3=(edge_a==8245.14480000001).astype('float64')\n",
    "edge_type4=(edge_a==147500.0).astype('float64')\n",
    "print(np.sum(edge_type1),np.sum(edge_type2),np.sum(edge_type3),np.sum(edge_type4))\n",
    "edge_f=np.stack([edge_d,edge_type1,edge_type2,edge_type3,edge_type4],axis=1)\n",
    "print(edge_data.shape,edge_f.shape)#(149, 106, 6) (149, 40) (185, 2) (185, 2)\n",
    "\n",
    "#########tension data\n",
    "in_cable=np.array([1,4,9,11,16,21,24,29,31,36])-1#list(range(3,40,4))#[3,7,11,15,19,23,27,31,35,39]\n",
    "with open(\"data/efo_signal_list.pkl\", 'rb') as pickle_file:\n",
    "    tension = pickle.load(pickle_file)\n",
    "tension=np.array(tension)#(4001, 4, 40)\n",
    "tension=tension[1:,-1,in_cable] #4000,10\n",
    "node_cable= (get_cableidx()[in_cable,1:])-1\n",
    "edge_t=np.zeros((4000,185,1))\n",
    "for i in range(4000):\n",
    "    for j,(r,c) in enumerate(node_cable): \n",
    "        idx=np.where((edge_data == (r, c)).all(axis=1))\n",
    "        edge_t[i,idx,0]=tension[i,j]\n",
    "edge_f=np.array([edge_f]*4000)\n",
    "edge_f=np.concatenate((edge_f,edge_t),axis=-1);print(edge_f.shape)#distance, E, area, self, tension\n",
    "#indexing\n",
    "e_training, e_val,e_test = edge_f[training_idx],edge_f[val_idx], edge_f[test_idx]\n",
    "print(e_training.shape,e_val.shape,e_test.shape)\n",
    "###scale\n",
    "'''for i in [0,-1]:\n",
    "    m=np.mean(e_training[...,i].flatten());std=np.std(e_training[...,i].flatten())\n",
    "    e_training[...,i]=(e_training[...,i]-m)/std\n",
    "    e_val[...,i]=(e_val[...,i]-m)/std\n",
    "    e_test[...,i]=(e_test[...,i]-m)/std'''\n",
    "sc=MinMaxScaler()\n",
    "e_training[:,:,[0,-1]]=sc.fit_transform(e_training[:,:,[0,-1]].reshape((-1,2))).reshape((-1,185,2))\n",
    "e_val[:,:,[0,-1]]=sc.transform(e_val[:,:,[0,-1]].reshape((-1,2))).reshape((-1,185,2))\n",
    "e_test[:,:,[0,-1]]=sc.transform(e_test[:,:,[0,-1]].reshape((-1,2))).reshape((-1,185,2))\n",
    "for i in range(6): print('10',i,np.min(e_val[...,i]),np.max(e_val[...,i]),np.mean(e_val[...,i]),np.std(e_val[...,i]))\n",
    "#save\n",
    "save_flag=True#False#\n",
    "if save_flag:\n",
    "    data_path='data/data_mpnn/edgetype/'\n",
    "    np.savez_compressed(data_path+'edge_train',e_training)\n",
    "    np.savez_compressed(data_path+'edge_val',e_val)\n",
    "    np.savez_compressed(data_path+'edge_test',e_test)\n",
    "    np.savez_compressed(data_path+'edge_data',edge_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
