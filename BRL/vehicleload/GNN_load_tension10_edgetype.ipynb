{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from dgl import model_zoo,DGLGraph\n",
    "import math\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_mpnn import Meter, set_random_seed, collate, EarlyStopping, load_model,load_brl_dataset,regress,run_a_train_epoch,run_an_eval_epoch\n",
    "import argparse\n",
    "# from sklearn import svm, datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import collections\n",
    "import sys; sys.argv=['']; del sys\n",
    "parser = argparse.ArgumentParser(description='Molecule Regression')\n",
    "parser.add_argument('-m', '--model', type=str,default='MPNN',help='Model to use')#choices=['MPNN', 'SCHNET', 'MGCN', 'AttentiveFP'],\n",
    "#parser.add_argument('-d', '--dataset', type=str, default='bridge',help='Dataset to use')#choices=['Alchemy', 'Aromaticity'],                \n",
    "parser.add_argument('-p', '--pre-trained', action='store_true', default=False, help='Whether to skip training and use a pre-trained model')\n",
    "args = parser.parse_args().__dict__\n",
    "training_setting= {\n",
    "    'random_seed': 0,\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 500,\n",
    "    'node_in_feats': 4,\n",
    "    'edge_in_feats': 6,\n",
    "    'output_dim': 1,\n",
    "    'lr': 0.0001,#0.001,#\n",
    "    'patience': 100,\n",
    "    'metric_name': 'l1',\n",
    "    'weight_decay': 0,\n",
    "    'n_task':41,\n",
    "}\n",
    "args.update(training_setting)\n",
    "args['device'] = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "args['data_path_x']='data/data_mpnn/edgetype/'\n",
    "args['data_path_label']='data/'\n",
    "set_random_seed(args['random_seed'])\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "# torch.cuda.set_device(1)\n",
    "# print(torch.cuda.current_device())\n",
    "\n",
    "train_loader,val_loader,test_loader=load_brl_dataset(args)#for batch_id, batch_data in enumerate(train_loader):bg, labels = batch_data;print(a)\n",
    "if args['pre_trained']:\n",
    "    args['num_epochs'] = 0\n",
    "    model = model_zoo.chem.load_pretrained(args['exp'])\n",
    "else:\n",
    "    model = load_model(args)\n",
    "    if args['model'] in ['SCHNET', 'MGCN']:\n",
    "        model.set_mean_std(train_set.mean, train_set.std, args['device'])\n",
    "    loss_fn =nn.L1Loss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    stopper = EarlyStopping(mode='lower', patience=args['patience'], filename='model_saved/edgetype/early_stop.pth')\n",
    "model.to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args['num_epochs']):\n",
    "    st=time.time()\n",
    "    if epoch==250:\n",
    "        torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()}, 'model_saved/edgetype/1.pth')\n",
    "        for param_group in optimizer.param_groups: print(param_group['lr'])\n",
    "        for param_group in optimizer.param_groups: param_group['lr'] = param_group['lr']*0.1\n",
    "        for param_group in optimizer.param_groups: print(param_group['lr'])\n",
    "    # Train\n",
    "    run_a_train_epoch(args, epoch, model, train_loader, loss_fn, optimizer)\n",
    "    # Validation and early stop\n",
    "    val_score = run_an_eval_epoch(args, model, val_loader)\n",
    "    early_stop = stopper.step(val_score, model,optimizer)\n",
    "    print('epoch {:d}/{:d}, validation {} {:.4f}, best validation {} {:.4f}, time{:.1f}'.format(\n",
    "        epoch + 1, args['num_epochs'], args['metric_name'], val_score,\n",
    "        args['metric_name'], stopper.best_score,time.time()-st))\n",
    "    #if early_stop:break\n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()}, 'model_saved/edgetype/last.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=torch.load('model_saved/edgetype/early_stop.pth') \n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "#eval_meter = Meter()\n",
    "y_p=[];y_t=[]\n",
    "with torch.no_grad():\n",
    "    for batch_id, batch_data in enumerate(test_loader):\n",
    "        bg, labels = batch_data\n",
    "        labels = labels.to(args['device'])  \n",
    "        y_t.append(labels.cpu().detach().numpy())\n",
    "        prediction = regress(args, model, bg)\n",
    "        y_p.append(prediction.cpu().detach().numpy())\n",
    "y_p=np.concatenate(y_p,axis=0).reshape((-1))\n",
    "y_t=np.concatenate(y_t,axis=0).reshape((-1))\n",
    "m=355311.0926130971;std=201425.32593642248\n",
    "pred=y_p*std+m\n",
    "actual=y_t*std+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####results - all\n",
    "y_t=actual.copy();y_p=pred.copy()\n",
    "print(y_t.shape,y_p.shape)#(296,) (296,)\n",
    "import sklearn.metrics as metrics\n",
    "mae = metrics.mean_absolute_error(y_t, y_p)\n",
    "mse = metrics.mean_squared_error(y_t, y_p)\n",
    "rmse=np.sqrt(mse)\n",
    "print('mae', mae, '| rmse:',rmse)\n",
    "print('actual mean', np.mean(y_t),'| pred mean',np.mean(y_p))\n",
    "print(np.corrcoef(y_t.flatten(),y_p.flatten()))\n",
    "print('rmse/range',rmse/(np.max(y_t)-np.min(y_t)))\n",
    "print('mape',np.mean(np.abs(y_t-y_p)/y_t))\n",
    "iqr= np.subtract(*np.percentile(y_t, [75, 25]))\n",
    "print('rmse/iqr',rmse/iqr)\n",
    "print('rmse/mean',rmse/np.mean(y_t))\n",
    "print('actual min max', np.min(y_t),np.max(y_t))\n",
    "print('pred min max', np.min(y_p),np.max(y_p))\n",
    "plt.plot(y_t.flatten(),y_p.flatten(),'.',color='darkblue',alpha=0.8)\n",
    "plt.ylim(17500-50000,700000+50000)#np.min([y_p,y_t]), np.max([y_p,y_t]))\n",
    "plt.xlim(17500-50000,700000+50000)#np.min([y_p,y_t]), np.max([y_p,y_t]))\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.savefig('images/edgetype/test1.png')\n",
    "plt.show()\n",
    "\n",
    "#####results - 100~600\n",
    "idx=np.where(((actual>=(100*1000)) & (actual<=(600*1000))))\n",
    "print(len(idx[0]))\n",
    "y_t=actual[idx[0]]\n",
    "y_p=pred[idx[0]]\n",
    "print(y_t.shape,y_p.shape)#(296,) (296,)\n",
    "import sklearn.metrics as metrics\n",
    "mae = metrics.mean_absolute_error(y_t, y_p)\n",
    "mse = metrics.mean_squared_error(y_t, y_p)\n",
    "rmse=np.sqrt(mse)\n",
    "print('mae', mae, '| rmse:',rmse)\n",
    "print('actual mean', np.mean(y_t),'| pred mean',np.mean(y_p))\n",
    "print(np.corrcoef(y_t.flatten(),y_p.flatten()))\n",
    "print('rmse/range',rmse/(np.max(y_t)-np.min(y_t)))\n",
    "print('mape',np.mean(np.abs(y_t-y_p)/y_t))\n",
    "iqr= np.subtract(*np.percentile(y_t, [75, 25]))\n",
    "print('rmse/iqr',rmse/iqr)\n",
    "print('rmse/mean',rmse/np.mean(y_t))\n",
    "print('actual min max', np.min(y_t),np.max(y_t))\n",
    "print('pred min max', np.min(y_p),np.max(y_p))\n",
    "plt.plot(y_t.flatten(),y_p.flatten(),'.',color='darkblue',alpha=0.8)\n",
    "plt.ylim(17500-50000,700000+50000)#np.min([y_p,y_t]), np.max([y_p,y_t]))\n",
    "plt.xlim(17500-50000,700000+50000)#np.min([y_p,y_t]), np.max([y_p,y_t]))\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.savefig('images/edgetype/test2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
