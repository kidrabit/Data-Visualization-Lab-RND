{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices 8203\n",
      "nf1.shape (12121, 7) x1.shape (12121, 365, 7)\n",
      "input6.shape, (12121, 49)\n",
      "label359.shape, (12121, 2513)\n",
      "features.shape (12121, 2562)\n",
      "(7276, 2562) (2422, 2562) (2423, 2562)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "###################\n",
    "n_f=7+365*7\n",
    "n_node=365\n",
    "###################\n",
    "\n",
    "###node ddata -single\n",
    "if False:#True:#\n",
    "    N=12121\n",
    "    np.random.seed(1)\n",
    "    indices = np.random.permutation(N);print('indices',indices[0])\n",
    "    n_training=int(N*0.6)+4\n",
    "    n_val=int(N*0.2)-2\n",
    "    n_test=N-n_training-n_val\n",
    "    training_idx, val_idx,test_idx = indices[:n_training], indices[n_training:n_training+n_val], indices[-n_test:]\n",
    "    \n",
    "    nf1=np.load('data/nf.npy')#n,7\n",
    "    x1=np.load('data/disp.npy')#n,365,7\n",
    "    print('nf1.shape',nf1.shape,'x1.shape',x1.shape)\n",
    "    \n",
    "    '''#scaling\n",
    "    for i in range(7):\n",
    "        m=np.mean(nf1[...,i].flatten());std=np.std(nf1[...,i].flatten())\n",
    "        nf1[...,i]=(nf1[...,i]-m)/std\n",
    "    for i in range(7):\n",
    "        m=np.mean(x1[...,i].flatten());std=np.std(x1[...,i].flatten())\n",
    "        x1[...,i]=(x1[...,i]-m)/std'''\n",
    "    \n",
    "    #input6\n",
    "    input6=np.concatenate((x1[:,-6:,:].reshape((-1,6*7)),nf1),axis=-1)\n",
    "    print('input6.shape,',input6.shape,)\n",
    "    #label359\n",
    "    label359=x1[:,:-6,:].reshape((-1,359*7))\n",
    "    print('label359.shape,',label359.shape,)\n",
    "    #input 365\n",
    "    features=np.concatenate((x1.reshape((-1,365*7)),nf1),axis=1)\n",
    "    print('features.shape',features.shape)\n",
    "    \n",
    "    #x - split\n",
    "    f_training, f_val, f_test = features[training_idx],features[val_idx], features[test_idx]\n",
    "    input6_training, input6_val, input6_test = input6[training_idx],input6[val_idx], input6[test_idx]\n",
    "    label359_training, label359_val, label359_test = label359[training_idx],label359[val_idx], label359[test_idx]\n",
    "    print(f_training.shape,f_val.shape,f_test.shape)\n",
    "    \n",
    "    \n",
    "    #x - save\n",
    "    save_flag=True#False#\n",
    "    if save_flag:\n",
    "        data_path='data/data_mlp/single/input365/'\n",
    "        np.savez_compressed(data_path+'features_train',f_training)\n",
    "        np.savez_compressed(data_path+'features_val',f_val)\n",
    "        np.savez_compressed(data_path+'features_test',f_test)\n",
    "        data_path='data/data_mlp/single/input6/'\n",
    "        np.savez_compressed(data_path+'features_train',input6_training)\n",
    "        np.savez_compressed(data_path+'features_val',input6_val)\n",
    "        np.savez_compressed(data_path+'features_test',input6_test)\n",
    "        data_path='data/data_mlp/single/label359/'\n",
    "        np.savez_compressed(data_path+'label_train',label359_training)\n",
    "        np.savez_compressed(data_path+'label_val',label359_val)\n",
    "        np.savez_compressed(data_path+'label_test',label359_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###node ddata -multi -. mulst be revised for imputation data -> complete\n",
    "if False:#True:#\n",
    "    N=12121+75000\n",
    "    #split idx\n",
    "    np.random.seed(1)\n",
    "    indices = np.random.permutation(N);print('indices',indices[0])\n",
    "    n_training=int(N*0.6)\n",
    "    n_val=int(N*0.2)\n",
    "    n_test=N-n_training-n_val\n",
    "    training_idx, val_idx,test_idx = indices[:n_training], indices[n_training:n_training+n_val], indices[-n_test:]\n",
    "    \n",
    "    \n",
    "    nf1=np.load('data/nf.npy')\n",
    "    x1=np.load('data/disp.npy')\n",
    "    nf2=np.load('data/nf_multi.npy')\n",
    "    x2=np.load('data/disp_multi.npy')\n",
    "    \n",
    "    #input6\n",
    "    features1=np.concatenate((x1[:,-6:,:].reshape((-1,6*7)),nf1),axis=-1)\n",
    "    features2=np.concatenate((x2[:,-6:,:].reshape((-1,6*7)),nf2),axis=-1)\n",
    "    input6=np.concatenate((features1,features2));print('input6.shape,',input6.shape,);del features1,features2\n",
    "    #label359\n",
    "    features1=x1[:,:-6,:].reshape((-1,359*7))\n",
    "    features2=x2[:,:-6,:].reshape((-1,359*7))\n",
    "    label359=np.concatenate((features1,features2));print('label359.shape,',label359.shape,);del features1,features2\n",
    "    #input 365\n",
    "    features1=np.concatenate((x1.reshape((-1,365*7)),nf1),axis=1)\n",
    "    features2=np.concatenate((x2.reshape((-1,365*7)),nf2),axis=1)\n",
    "    features=np.concatenate((features1,features2));print('features.shape',features.shape);del nf1,features1,nf2,features2\n",
    "    \n",
    "    #x - split\n",
    "    f_training, f_val, f_test = features[training_idx],features[val_idx], features[test_idx]\n",
    "    input6_training, input6_val, input6_test = input6[training_idx],input6[val_idx], input6[test_idx]\n",
    "    label359_training, label359_val, label359_test = label359[training_idx],label359[val_idx], label359[test_idx]\n",
    "    print(f_training.shape,f_val.shape,f_test.shape)\n",
    "    #x - save\n",
    "    save_flag=False#True#\n",
    "    if save_flag:\n",
    "        data_path='data/data_mlp/multi/input365/'\n",
    "        np.savez_compressed(data_path+'features_train',f_training)\n",
    "        np.savez_compressed(data_path+'features_val',f_val)\n",
    "        np.savez_compressed(data_path+'features_test',f_test)\n",
    "        data_path='data/data_mlp/multi/input6/'\n",
    "        np.savez_compressed(data_path+'features_train',input6_training)\n",
    "        np.savez_compressed(data_path+'features_val',input6_val)\n",
    "        np.savez_compressed(data_path+'features_test',input6_test)\n",
    "        data_path='data/data_mlp/multi/label359/'\n",
    "        np.savez_compressed(data_path+'label_train',label359_training)\n",
    "        np.savez_compressed(data_path+'label_val',label359_val)\n",
    "        np.savez_compressed(data_path+'label_test',label359_test)\n",
    "\n",
    "#############################\n",
    "##y - multi\n",
    "if False:#True:#\n",
    "    \n",
    "    N=12121+75000\n",
    "    #split idx\n",
    "    np.random.seed(1)\n",
    "    indices = np.random.permutation(N);print('indices',indices[0])\n",
    "    n_training=int(N*0.6)\n",
    "    n_val=int(N*0.2)\n",
    "    n_test=N-n_training-n_val\n",
    "    training_idx, val_idx,test_idx = indices[:n_training], indices[n_training:n_training+n_val], indices[-n_test:]\n",
    "    \n",
    "    y_area1=np.load('data/data_cablearea.npy');\n",
    "    y_area2=np.load('data/data_cablearea_multi.npy');\n",
    "    label_area=np.concatenate((y_area1,y_area2));print('label_area.shape',label_area.shape); del y_area1,y_area2\n",
    "    ##y - split\n",
    "    l_training, l_val, l_test = label_area[training_idx],label_area[val_idx], label_area[test_idx]\n",
    "    print(l_training.shape,l_val.shape,l_test.shape)\n",
    "    #multi task\n",
    "    def getting_multi(label_data,sf,mode):\n",
    "        bce_data=(label_data<0.999).astype('uint8')\n",
    "        bce_safe=np.sum(bce_data,axis=1)==0\n",
    "        bce_safe=bce_safe.astype('uint8')[:,np.newaxis];print(np.sum(bce_safe))\n",
    "        bce_data=np.concatenate((bce_safe,bce_data),axis=1)\n",
    "        if sf:\n",
    "            np.savez_compressed('data/data_mlp/label_multitask_bce/c_label_'+mode,bce_data)\n",
    "            #np.savez_compressed('data/data_mlp/label_multitask_bce/a_label_'+mode,a_data)\n",
    "        return bce_data\n",
    "\n",
    "    save_flag=False#True#\n",
    "    bce_training=getting_multi(l_training,sf=save_flag,mode='train')\n",
    "    bce_val=getting_multi(l_val,sf=save_flag,mode='val')\n",
    "    bce_test=getting_multi(l_test,sf=save_flag,mode='test')\n",
    "    \n",
    "    save_flag=False#True#\n",
    "    if save_flag:\n",
    "        data_path='data/data_mlp/label/'\n",
    "        np.savez_compressed(data_path+'label_train',l_training)\n",
    "        np.savez_compressed(data_path+'label_val',l_val)\n",
    "        np.savez_compressed(data_path+'label_test',l_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
