{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "/home/shs/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:103: DeprecationWarning: The class is deprecated and will be removed from dgl in v0.5. Import MPNNPredictor from dgllife.model instead.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.contrib.deprecation import deprecated\n",
    "from dgl.nn.pytorch import Set2Set, NNConv\n",
    "from utils import MPNNModel\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from dgl import model_zoo,DGLGraph\n",
    "import math\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_mpnn import Meter, set_random_seed, collate, EarlyStopping, load_model,load_brl_dataset,regress#,run_a_train_epoch,run_an_eval_epoch\n",
    "import argparse\n",
    "# from sklearn import svm, datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import collections\n",
    "import sys; sys.argv=['']; del sys\n",
    "parser = argparse.ArgumentParser(description='Molecule Regression')\n",
    "parser.add_argument('-m', '--model', type=str,default='MPNN',help='Model to use')#choices=['MPNN', 'SCHNET', 'MGCN', 'AttentiveFP'],\n",
    "#parser.add_argument('-d', '--dataset', type=str, default='bridge',help='Dataset to use')#choices=['Alchemy', 'Aromaticity'],                \n",
    "parser.add_argument('-p', '--pre-trained', action='store_true', default=False, help='Whether to skip training and use a pre-trained model')\n",
    "args = parser.parse_args().__dict__\n",
    "training_setting= {\n",
    "    'random_seed': 0,\n",
    "    'batch_size': 64,#\n",
    "    'num_epochs': 600,#900,\n",
    "    'node_in_feats': 7,\n",
    "    'edge_in_feats': 6,\n",
    "    'output_dim': 120,\n",
    "    'lr': 0.0001,#0.001,#\n",
    "    'patience': 300,#20,\n",
    "    'metric_name': 'l1',#'roc_auc',#\n",
    "    'weight_decay': 0,\n",
    "    'n_task':120,\n",
    "}\n",
    "args.update(training_setting)\n",
    "args['device'] = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "args['data_path_x']='data/data_mpnn/'\n",
    "args['data_path_label']='data/label/'\n",
    "set_random_seed(args['random_seed'])\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "train_loader,val_loader,test_loader=load_brl_dataset(args)#for batch_id, batch_data in enumerate(train_loader):bg, labels = batch_data;print(a)\n",
    "model = MPNNModel(node_input_dim=args['node_in_feats'],\n",
    "                  edge_input_dim=args['edge_in_feats'],\n",
    "                 output_dim=args['output_dim'])\n",
    "if args['model'] in ['SCHNET', 'MGCN']:\n",
    "    model.set_mean_std(train_set.mean, train_set.std, args['device'])\n",
    "loss_fn1 =nn.BCEWithLogitsLoss(reduction='sum')#nn.KLDivLoss()#\n",
    "#loss_fn1=nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "stopper = EarlyStopping(mode='lower', patience=args['patience'], filename='model_saved/bce/early_stop.pth')\n",
    "model.to(args['device'])\n",
    "\n",
    "def run_a_train_epoch_custom(args, epoch, model, data_loader,\n",
    "                      loss_criterion1, optimizer):\n",
    "    model.train()\n",
    "    train_meter = Meter()\n",
    "    correct=0\n",
    "    total=0\n",
    "    for batch_id, batch_data in enumerate(data_loader):\n",
    "        bg, labels = batch_data\n",
    "        labels= labels.to(args['device'])\n",
    "        prediction = regress(args, model, bg)\n",
    "        loss = (loss_criterion1(prediction, labels).float()).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_meter.update(prediction, labels)\n",
    "        \n",
    "        _, predicted = torch.min(prediction.data, 1)\n",
    "        total += labels.size(0)\n",
    "        _, labels = torch.min(labels.data, 1)\n",
    "        correct += (predicted == labels).sum().item();del predicted\n",
    "        \n",
    "    total_score_acc=100-100 * correct / total\n",
    "    total_score = np.mean(train_meter.compute_metric(args['metric_name']))\n",
    "    print('epoch {:d}/{:d}, training {} {:.4f} / accuracy(%) {:.4f}'.format(\n",
    "        epoch + 1, args['num_epochs'], args['metric_name'], total_score*1000, total_score_acc)) \n",
    "    #print('epoch {:d}/{:d}, training total_score_acc {:.4f}'.format(epoch + 1, args['num_epochs'], total_score_acc)) \n",
    "    \n",
    "def run_an_eval_epoch_custom(args, model, data_loader):\n",
    "    model.eval()\n",
    "    eval_meter = Meter()\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch_data in enumerate(data_loader):\n",
    "            bg, labels = batch_data\n",
    "            labels = labels.to(args['device'])\n",
    "            prediction = regress(args, model, bg)\n",
    "            eval_meter.update(prediction, labels)\n",
    "            \n",
    "            _, predicted = torch.min(prediction.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            _, labels = torch.min(labels.data, 1)\n",
    "            correct += (predicted == labels).sum().item();del predicted\n",
    "        total_score_acc=100-100 * correct / total\n",
    "        total_score = np.mean(eval_meter.compute_metric(args['metric_name']))\n",
    "    return total_score,total_score_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args['num_epochs']):\n",
    "    st=time.time()\n",
    "    # Train\n",
    "    run_a_train_epoch_custom(args, epoch, model, train_loader, loss_fn1,optimizer)\n",
    "    # Validation and early stop\n",
    "    val_score,val_acc = run_an_eval_epoch_custom(args, model, val_loader)\n",
    "    early_stop = stopper.step(val_acc, model,optimizer)\n",
    "    print('epoch {:d}/{:d}, validation {} {:.4f}, accuracy(%) {:.4f}, best validation {} {:.4f}, time{:.1f}'.format(\n",
    "        epoch + 1, args['num_epochs'], args['metric_name'], \n",
    "        val_score*1000,val_acc,args['metric_name'], stopper.best_score,time.time()-st))\n",
    "    \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()}, 'model_saved/bce/1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=torch.load('model_saved/bce/early_stop.pth') \n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "for param_group in optimizer.param_groups: print(param_group['lr'])\n",
    "for param_group in optimizer.param_groups: param_group['lr'] = param_group['lr']*0.1\n",
    "for param_group in optimizer.param_groups: print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "#eval_meter = Meter()\n",
    "y_p=[];y_t=[]\n",
    "with torch.no_grad():\n",
    "    for batch_id, batch_data in enumerate(test_loader):\n",
    "        bg, labels = batch_data\n",
    "        labels = labels.to(args['device'])  \n",
    "        y_t.append(labels.cpu().detach().numpy())\n",
    "        prediction = regress(args, model, bg)\n",
    "        y_p.append(prediction.cpu().detach().numpy())\n",
    "\n",
    "pred=np.concatenate(y_p,axis=0)\n",
    "actual=np.concatenate(y_t,axis=0)\n",
    "\n",
    "y_p=np.min(pred,axis=1)\n",
    "y_t=np.min(actual,axis=1)\n",
    "l_p=np.argmin(pred,axis=1)\n",
    "l_t=np.argmin(actual,axis=1)\n",
    "print(y_p.shape,y_t.shape)\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "#y_p=p_area;y_t=t_area;\n",
    "mae = metrics.mean_absolute_error(y_t, y_p)\n",
    "mse = metrics.mean_squared_error(y_t, y_p)\n",
    "rmse=np.sqrt(mse)\n",
    "print('mae', mae, '| rmse:',rmse)\n",
    "print('actual mean', np.mean(y_t),'| pred mean',np.mean(y_p))\n",
    "print(np.corrcoef(y_t.flatten(),y_p.flatten()))\n",
    "print('rmse/range',rmse/(np.max(y_t)-np.min(y_t)))\n",
    "print('mape',np.mean(np.abs(y_t-y_p)/y_t))\n",
    "iqr= np.subtract(*np.percentile(y_t, [75, 25]))\n",
    "print('rmse/iqr',rmse/iqr)\n",
    "print('rmse/mean',rmse/np.mean(y_t))\n",
    "print('actual min max', np.min(y_t),np.max(y_t))\n",
    "print('pred min max', np.min(y_p),np.max(y_p))\n",
    "\n",
    "plt.plot(y_t.flatten(),y_p.flatten(),'.',color='darkblue',alpha=0.8)\n",
    "plt.ylim(np.min([y_p,y_t]), np.max([y_p,y_t]))\n",
    "plt.xlim(np.min([y_p,y_t]), np.max([y_p,y_t]))\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "#plt.savefig('results/testset2.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
